{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T), obs=train ) \n",
    "            return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "\n",
    "    \n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 2336314634.109375\n",
      "Elbo loss: 335497992.1171875\n",
      "Elbo loss: 88186257.00390625\n",
      "Elbo loss: 47303800.537109375\n",
      "Elbo loss: 36057065.96875\n",
      "Elbo loss: 32626540.515625\n",
      "Elbo loss: 31529046.171875\n",
      "Elbo loss: 30088244.25\n",
      "Elbo loss: 27043836.09375\n",
      "Elbo loss: 23925259.828125\n",
      "Elbo loss: 21573661.546875\n",
      "Elbo loss: 19923352.796875\n",
      "Elbo loss: 19120000.640625\n",
      "Elbo loss: 18205186.515625\n",
      "Elbo loss: 17605883.859375\n",
      "Elbo loss: 17287293.515625\n",
      "Elbo loss: 16694075.484375\n",
      "Elbo loss: 16594215.015625\n",
      "Elbo loss: 16351819.015625\n",
      "Elbo loss: 16263272.578125\n",
      "Elbo loss: 15928297.859375\n",
      "Elbo loss: 15722939.921875\n",
      "Elbo loss: 15567714.6875\n",
      "Elbo loss: 15421303.71875\n",
      "Elbo loss: 15315426.65625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2336314634.109375,\n",
       " 1891504406.84375,\n",
       " 1541580388.1875,\n",
       " 1278080593.546875,\n",
       " 1044348330.421875,\n",
       " 857057030.40625,\n",
       " 703238010.921875,\n",
       " 582897138.8515625,\n",
       " 480593259.6875,\n",
       " 400234952.96875,\n",
       " 335497992.1171875,\n",
       " 279226896.578125,\n",
       " 235646270.578125,\n",
       " 201481908.36132812,\n",
       " 173939746.76367188,\n",
       " 151126704.34960938,\n",
       " 132999739.81835938,\n",
       " 118129568.57421875,\n",
       " 106375419.33984375,\n",
       " 96390129.375,\n",
       " 88186257.00390625,\n",
       " 81378336.90625,\n",
       " 75930065.2109375,\n",
       " 70438025.33007812,\n",
       " 65844248.7265625,\n",
       " 62455479.556640625,\n",
       " 58810562.779052734,\n",
       " 55688136.95703125,\n",
       " 52644793.8515625,\n",
       " 49810326.36328125,\n",
       " 47303800.537109375,\n",
       " 44933465.35546875,\n",
       " 42958675.328125,\n",
       " 41306958.78515625,\n",
       " 39694746.2890625,\n",
       " 38325722.5390625,\n",
       " 37455367.51171875,\n",
       " 36669173.4765625,\n",
       " 36400280.1015625,\n",
       " 36218159.6171875,\n",
       " 36057065.96875,\n",
       " 35973082.9765625,\n",
       " 35646414.4453125,\n",
       " 35419720.0234375,\n",
       " 34836985.59375,\n",
       " 34383767.0625,\n",
       " 33893274.828125,\n",
       " 33536042.2734375,\n",
       " 33031913.734375,\n",
       " 32834952.140625,\n",
       " 32626540.515625,\n",
       " 32519938.75,\n",
       " 32464942.3125,\n",
       " 32440494.5,\n",
       " 32306707.390625,\n",
       " 32231052.28125,\n",
       " 32075382.859375,\n",
       " 31925101.46875,\n",
       " 31846356.03125,\n",
       " 31604104.21875,\n",
       " 31529046.171875,\n",
       " 31535582.625,\n",
       " 31305506.0625,\n",
       " 31212340.921875,\n",
       " 31120679.6875,\n",
       " 31119293.1875,\n",
       " 30919203.234375,\n",
       " 30693138.671875,\n",
       " 30493321.1875,\n",
       " 30330775.8125,\n",
       " 30088244.25,\n",
       " 29779075.765625,\n",
       " 29416265.359375,\n",
       " 29333973.5,\n",
       " 28872950.890625,\n",
       " 28631580.109375,\n",
       " 28444718.421875,\n",
       " 27960319.046875,\n",
       " 27550783.1875,\n",
       " 27309856.546875,\n",
       " 27043836.09375,\n",
       " 26581187.328125,\n",
       " 26340553.03125,\n",
       " 25983370.234375,\n",
       " 25731273.015625,\n",
       " 25422121.8125,\n",
       " 25197190.09375,\n",
       " 24775058.390625,\n",
       " 24270111.109375,\n",
       " 24007055.984375,\n",
       " 23925259.828125,\n",
       " 23548681.265625,\n",
       " 23389840.78125,\n",
       " 22845439.5625,\n",
       " 22953880.109375,\n",
       " 22609754.203125,\n",
       " 22484280.046875,\n",
       " 22151831.4375,\n",
       " 22053477.484375,\n",
       " 21767388.609375,\n",
       " 21573661.546875,\n",
       " 21306229.40625,\n",
       " 21203742.890625,\n",
       " 21219410.109375,\n",
       " 21240468.234375,\n",
       " 20775728.703125,\n",
       " 20789443.671875,\n",
       " 20535038.890625,\n",
       " 20296283.515625,\n",
       " 20206042.421875,\n",
       " 19923352.796875,\n",
       " 19772723.53125,\n",
       " 19894569.890625,\n",
       " 19871098.546875,\n",
       " 19674954.953125,\n",
       " 19525844.953125,\n",
       " 19731966.3125,\n",
       " 19354003.609375,\n",
       " 19198019.703125,\n",
       " 19213002.265625,\n",
       " 19120000.640625,\n",
       " 18902678.84375,\n",
       " 19027410.265625,\n",
       " 18604511.4375,\n",
       " 18683400.078125,\n",
       " 18817189.609375,\n",
       " 18600657.734375,\n",
       " 18304965.125,\n",
       " 18502751.765625,\n",
       " 18377017.5625,\n",
       " 18205186.515625,\n",
       " 18330182.40625,\n",
       " 18285780.09375,\n",
       " 18192247.5,\n",
       " 18150105.03125,\n",
       " 18049710.671875,\n",
       " 17837856.65625,\n",
       " 17776250.640625,\n",
       " 17890633.921875,\n",
       " 17657239.421875,\n",
       " 17605883.859375,\n",
       " 17531931.953125,\n",
       " 17463538.171875,\n",
       " 17776654.546875,\n",
       " 17536083.40625,\n",
       " 17401501.796875,\n",
       " 17419179.671875,\n",
       " 17062926.96875,\n",
       " 17377759.46875,\n",
       " 17128145.015625,\n",
       " 17287293.515625,\n",
       " 17254033.546875,\n",
       " 17045943.671875,\n",
       " 17109808.859375,\n",
       " 17064371.203125,\n",
       " 17020633.546875,\n",
       " 17108370.578125,\n",
       " 16963875.890625,\n",
       " 16885900.03125,\n",
       " 16849694.1875,\n",
       " 16694075.484375,\n",
       " 16832774.25,\n",
       " 16824999.40625,\n",
       " 16889341.5,\n",
       " 16833176.5625,\n",
       " 16908723.578125,\n",
       " 16552007.875,\n",
       " 16362558.203125,\n",
       " 16457245.875,\n",
       " 16740774.078125,\n",
       " 16594215.015625,\n",
       " 16556738.921875,\n",
       " 16526187.46875,\n",
       " 16386492.34375,\n",
       " 16522318.15625,\n",
       " 16237677.921875,\n",
       " 16460329.4375,\n",
       " 16368048.765625,\n",
       " 16718705.015625,\n",
       " 16447835.96875,\n",
       " 16351819.015625,\n",
       " 16331833.390625,\n",
       " 16275676.703125,\n",
       " 16125548.890625,\n",
       " 16149056.390625,\n",
       " 16421519.0625,\n",
       " 16027720.28125,\n",
       " 16106561.015625,\n",
       " 16169138.3125,\n",
       " 16098144.078125,\n",
       " 16263272.578125,\n",
       " 16083559.546875,\n",
       " 16194288.46875,\n",
       " 16117581.796875,\n",
       " 15838320.1875,\n",
       " 16095656.78125,\n",
       " 15973308.703125,\n",
       " 15779894.578125,\n",
       " 15840390.203125,\n",
       " 15740152.4375,\n",
       " 15928297.859375,\n",
       " 15596708.625,\n",
       " 15779384.5,\n",
       " 15878611.140625,\n",
       " 15884066.5,\n",
       " 15775212.96875,\n",
       " 15766646.90625,\n",
       " 15915173.28125,\n",
       " 15835990.28125,\n",
       " 15717042.09375,\n",
       " 15722939.921875,\n",
       " 15615543.328125,\n",
       " 15823980.4375,\n",
       " 15650668.984375,\n",
       " 15520836.65625,\n",
       " 15683344.65625,\n",
       " 15504315.90625,\n",
       " 15651085.40625,\n",
       " 15805456.625,\n",
       " 15526317.734375,\n",
       " 15567714.6875,\n",
       " 15698188.875,\n",
       " 15527252.046875,\n",
       " 15638334.90625,\n",
       " 15656966.59375,\n",
       " 15590921.90625,\n",
       " 15372410.609375,\n",
       " 15315437.984375,\n",
       " 15526914.78125,\n",
       " 15587966.78125,\n",
       " 15421303.71875,\n",
       " 15271175.140625,\n",
       " 15323928.015625,\n",
       " 15459858.109375,\n",
       " 15113709.53125,\n",
       " 15566974.03125,\n",
       " 15146591.828125,\n",
       " 15311925.546875,\n",
       " 15285778.578125,\n",
       " 15336572.25,\n",
       " 15315426.65625,\n",
       " 15273792.859375,\n",
       " 15472710.875,\n",
       " 15238071.5625,\n",
       " 15213244.4375,\n",
       " 15323780.015625,\n",
       " 15251135.8125,\n",
       " 15270457.75,\n",
       " 15202483.71875,\n",
       " 15395398.796875]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PMF(train=data, dim=100)\n",
    "test.train_SVI(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36516\n",
      "AUC: 0.83883\n",
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " ...\n",
      " [1 0 0 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 1 1 1]\n",
      " ...\n",
      " [1 0 0 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8267106141796051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "low, high = (1,1)\n",
    "test_data = data.copy()\n",
    "test_data[test_data < low] = 0\n",
    "test_data[test_data >= high] = 1\n",
    "preds = test.get_predictions()\n",
    "preds[preds<low] = 0\n",
    "preds[preds>=high] = 1\n",
    "print(test_data.astype(int))\n",
    "print(preds.astype(int))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(), preds.astype(int).flatten(), pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_Bayesian(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.Gamma(self.alpha_u,self.beta_u).expand([self.dim]).to_event(1)) \n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "\n",
    "\n",
    "        with drug_plate:\n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(self.alpha_u, U_beta_prior).to_event(1))\n",
    "        \n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(self.alpha_v, V_beta_prior).to_event(1))    \n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\",self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T), obs= train ) \n",
    "            return Y\n",
    "            \n",
    "    def guide(self, train=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', 5*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.05*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "        # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "            #                  constraint=constraints.positive)\n",
    "        s_alpha = pyro.param('s_alpha', 5*torch.ones(self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.05*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        UA_prior = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "        VA_prior = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(d_alpha, UA_prior).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "       \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(s_alpha, VA_prior).to_event(1))\n",
    "\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.01, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PMF_Bayesian(train=data, dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/pyro/util.py:288: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n",
      "{'UA', 'VA'}\n",
      "  warnings.warn(\n",
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/pyro/util.py:303: UserWarning: Found vars in model but not guide: {'U_beta_prior', 'V_beta_prior'}\n",
      "  warnings.warn(f\"Found vars in model but not guide: {bad_sites}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 107569105.45053673\n",
      "Elbo loss: 108117771.07240677\n",
      "Elbo loss: 108099781.61058807\n",
      "Elbo loss: 109333978.06388092\n",
      "Elbo loss: 107348806.80029678\n",
      "Elbo loss: 108235167.72333145\n",
      "Elbo loss: 108081019.49355316\n",
      "Elbo loss: 107597292.18015099\n",
      "Elbo loss: 107409085.59983253\n",
      "Elbo loss: 107750592.63371086\n",
      "Elbo loss: 107560241.23782921\n",
      "Elbo loss: 110895088.85101128\n",
      "Elbo loss: 107808984.6332531\n",
      "Elbo loss: 108090785.0159092\n",
      "Elbo loss: 107575356.75319672\n",
      "Elbo loss: 107847939.23356247\n",
      "Elbo loss: 107731478.08265495\n",
      "Elbo loss: 107866288.76983261\n",
      "Elbo loss: 107399269.80250168\n",
      "Elbo loss: 107644975.44064903\n",
      "Elbo loss: 107881651.11237144\n",
      "Elbo loss: 107642752.21947479\n",
      "Elbo loss: 107286555.13894844\n",
      "Elbo loss: 107321702.65320206\n",
      "Elbo loss: 107454180.24233627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[107569105.45053673,\n",
       " 108836002.85154915,\n",
       " 109620604.40990448,\n",
       " 109684416.79425621,\n",
       " 107652686.48116493,\n",
       " 107501541.97174454,\n",
       " 112098413.30023956,\n",
       " 107664300.97314644,\n",
       " 108095622.61244202,\n",
       " 107998611.80838585,\n",
       " 108117771.07240677,\n",
       " 108084680.87365913,\n",
       " 108817686.57419968,\n",
       " 108482633.50776672,\n",
       " 107521528.15869522,\n",
       " 107935528.36642456,\n",
       " 109172573.65988731,\n",
       " 108353578.81946754,\n",
       " 108149682.98832703,\n",
       " 107653716.06823349,\n",
       " 108099781.61058807,\n",
       " 110855230.3187294,\n",
       " 107460136.40094757,\n",
       " 108272005.27194595,\n",
       " 107580530.35108757,\n",
       " 107259311.77051544,\n",
       " 108362373.6490593,\n",
       " 108010582.93611717,\n",
       " 108141020.46165085,\n",
       " 108308683.24697304,\n",
       " 109333978.06388092,\n",
       " 107309693.3831749,\n",
       " 109634360.88252449,\n",
       " 109007998.15947151,\n",
       " 108084649.34105301,\n",
       " 107870489.1437912,\n",
       " 109291938.24201584,\n",
       " 107506833.576128,\n",
       " 109226315.65117264,\n",
       " 107445851.02986717,\n",
       " 107348806.80029678,\n",
       " 108128174.55090141,\n",
       " 108246591.02624321,\n",
       " 108613663.20749474,\n",
       " 108006797.64614868,\n",
       " 107719100.98202896,\n",
       " 107483990.1427021,\n",
       " 107785189.68957138,\n",
       " 107809333.29540062,\n",
       " 107636957.03903008,\n",
       " 108235167.72333145,\n",
       " 107259709.70407677,\n",
       " 107453823.95487213,\n",
       " 108034421.69443703,\n",
       " 107578265.81002235,\n",
       " 108130450.10821724,\n",
       " 111244331.74726677,\n",
       " 109310875.64122581,\n",
       " 107744999.75115204,\n",
       " 107416796.87192154,\n",
       " 108081019.49355316,\n",
       " 106925267.40464783,\n",
       " 108197537.44240952,\n",
       " 108449656.37223053,\n",
       " 108526259.28261566,\n",
       " 107662972.69844818,\n",
       " 108323162.96180534,\n",
       " 108777418.98231888,\n",
       " 107821496.93976402,\n",
       " 107828985.1423397,\n",
       " 107597292.18015099,\n",
       " 107931028.11004639,\n",
       " 108124313.65178299,\n",
       " 107648312.58294868,\n",
       " 108066898.14839172,\n",
       " 107682642.23675156,\n",
       " 107702394.44648552,\n",
       " 107625071.70240021,\n",
       " 108834893.22447205,\n",
       " 107615531.02680397,\n",
       " 107409085.59983253,\n",
       " 107937753.41124153,\n",
       " 107598670.54271126,\n",
       " 107705592.42485237,\n",
       " 109671569.62821007,\n",
       " 107458546.71663094,\n",
       " 108187603.35144806,\n",
       " 107538900.9271183,\n",
       " 108165623.77017212,\n",
       " 108011570.5118618,\n",
       " 107750592.63371086,\n",
       " 107452424.12139511,\n",
       " 107644494.3156414,\n",
       " 108806840.31907845,\n",
       " 107690616.50486755,\n",
       " 107342491.94609451,\n",
       " 107580845.10427284,\n",
       " 107867451.06954384,\n",
       " 107275685.12960052,\n",
       " 107911785.3721981,\n",
       " 107560241.23782921,\n",
       " 108384441.26685905,\n",
       " 108619184.74840355,\n",
       " 107665067.55343056,\n",
       " 108385891.08518982,\n",
       " 107529830.59617805,\n",
       " 107704794.97315025,\n",
       " 108041987.06334686,\n",
       " 107268434.69242477,\n",
       " 107882480.6951294,\n",
       " 110895088.85101128,\n",
       " 107932349.17204094,\n",
       " 107749481.88769531,\n",
       " 107499063.08527374,\n",
       " 108125454.2777996,\n",
       " 107941099.13771343,\n",
       " 107791198.76604843,\n",
       " 107017957.84495926,\n",
       " 107506380.05542183,\n",
       " 107248683.6618576,\n",
       " 107808984.6332531,\n",
       " 107514935.88375473,\n",
       " 107865263.99996567,\n",
       " 108545231.76053047,\n",
       " 107871519.43513489,\n",
       " 108182027.32372665,\n",
       " 108561943.29418564,\n",
       " 107842094.69678497,\n",
       " 107908296.44940376,\n",
       " 107537412.98238564,\n",
       " 108090785.0159092,\n",
       " 107366341.52321434,\n",
       " 107582251.43115044,\n",
       " 107394650.44355011,\n",
       " 107748581.69601631,\n",
       " 107649539.90649414,\n",
       " 107653988.48720169,\n",
       " 109684015.03149605,\n",
       " 107759008.53751945,\n",
       " 107346723.80916214,\n",
       " 107575356.75319672,\n",
       " 107826316.37312126,\n",
       " 107702851.41112137,\n",
       " 107525436.2300682,\n",
       " 107656205.92541313,\n",
       " 108285369.94219208,\n",
       " 107903297.80420113,\n",
       " 107481490.58808327,\n",
       " 107243314.36347389,\n",
       " 109023097.33222198,\n",
       " 107847939.23356247,\n",
       " 107865633.10923958,\n",
       " 108029938.18976593,\n",
       " 107482487.99785614,\n",
       " 107318373.30401993,\n",
       " 107392220.45747948,\n",
       " 107519656.17102623,\n",
       " 107598485.65188217,\n",
       " 107778605.71050644,\n",
       " 108344285.68854904,\n",
       " 107731478.08265495,\n",
       " 107675881.77850533,\n",
       " 107561901.28350449,\n",
       " 108334000.58606529,\n",
       " 107500170.71036148,\n",
       " 107393172.78827477,\n",
       " 107628034.47515106,\n",
       " 107724744.30365181,\n",
       " 107649213.21857643,\n",
       " 107634323.80151749,\n",
       " 107866288.76983261,\n",
       " 109203506.65441895,\n",
       " 107654508.33615685,\n",
       " 107647653.96334457,\n",
       " 107392558.63796997,\n",
       " 107947431.57618523,\n",
       " 107373232.26139069,\n",
       " 107579816.63924217,\n",
       " 107704605.25418663,\n",
       " 107233528.36608124,\n",
       " 107399269.80250168,\n",
       " 107275673.38376999,\n",
       " 107346500.50787926,\n",
       " 107184453.26722527,\n",
       " 107745129.92346573,\n",
       " 107579025.14622879,\n",
       " 107844703.45563126,\n",
       " 107736999.51659203,\n",
       " 107420755.38670158,\n",
       " 107894461.30544281,\n",
       " 107644975.44064903,\n",
       " 107247434.28969002,\n",
       " 107893292.63556862,\n",
       " 107668202.44650841,\n",
       " 107821973.00085449,\n",
       " 107302241.69484901,\n",
       " 107553603.71867561,\n",
       " 109835275.19763374,\n",
       " 107588552.42970467,\n",
       " 108791451.40625954,\n",
       " 107881651.11237144,\n",
       " 107517416.88663292,\n",
       " 107127468.59115791,\n",
       " 107621905.24024773,\n",
       " 107330076.87769127,\n",
       " 107908631.99206924,\n",
       " 107311430.89803123,\n",
       " 108959383.05438423,\n",
       " 108086455.92412567,\n",
       " 107642325.89893723,\n",
       " 107642752.21947479,\n",
       " 107655742.7039299,\n",
       " 107726284.64903069,\n",
       " 107480157.82342911,\n",
       " 107852850.30026436,\n",
       " 107269920.08481598,\n",
       " 107923472.16398048,\n",
       " 107985971.73272514,\n",
       " 108106644.33588982,\n",
       " 107305257.61285591,\n",
       " 107286555.13894844,\n",
       " 108215376.4612732,\n",
       " 107767512.07548904,\n",
       " 107403668.70557213,\n",
       " 107738531.69903374,\n",
       " 107286906.36997223,\n",
       " 108855650.40384865,\n",
       " 107458422.86853409,\n",
       " 107436634.12070847,\n",
       " 107555865.15969276,\n",
       " 107321702.65320206,\n",
       " 107497394.02947044,\n",
       " 107708666.3693161,\n",
       " 108300413.81000137,\n",
       " 108262321.69900894,\n",
       " 108308006.06017876,\n",
       " 107437274.52230072,\n",
       " 107942220.86063576,\n",
       " 107358962.846529,\n",
       " 107252721.35480118,\n",
       " 107454180.24233627,\n",
       " 107463986.71178436,\n",
       " 107698398.4076004,\n",
       " 107351306.59625626,\n",
       " 107598667.32827759,\n",
       " 107529039.43589783,\n",
       " 107578912.74052429,\n",
       " 107429060.43449974,\n",
       " 107989981.0018158,\n",
       " 107414644.63280296]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.train_SVI(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_beta_prior: (1000, 1, 1, 10)\n",
      "V_beta_prior: (1000, 1, 1, 10)\n",
      "UA2: (1000, 1, 1127, 10)\n",
      "VA2: (1000, 1, 5237, 10)\n",
      "target: (1000, 1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.89472\n",
      "AUC: 0.50000\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_intercepts(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(0.5))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            sideeffect_intercept = pyro.sample(\"sf_int\", dist.HalfNormal(0.5))\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "       #with u2_plate:\n",
    "           \n",
    "            \n",
    "        with sideeffect_plate, u2_plate: \n",
    "            #Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T  +sideeffect_intercept.T), obs=train ) z[:, np.newaxis] + x\n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T  + (drug_intercept[:, np.newaxis] + sideeffect_intercept.T)), obs=train ) \n",
    "            return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        se_t = pyro.param(\"sef_int\", 0.25*torch.ones(self.m), constraint=constraints.positive)\n",
    "        drug_t = pyro.param(\"drug_int_p\", 0.25*torch.ones(self.n), constraint=constraints.positive)\n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "       # with u2_plate:\n",
    "          #  drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(drug_t).to_event(1))\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            UA_int = pyro.sample(\"UAint\", dist.HalfNormal(drug_t))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "            sideeffect_intercept =  pyro.sample(\"sf_int\", dist.HalfNormal(se_t))\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "\n",
    "    \n",
    "   \n",
    "test = PMF_intercepts(data, 100)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 16507036.471118927\n",
      "Elbo loss: 16882178.70968628\n",
      "Elbo loss: 16316151.067085266\n",
      "Elbo loss: 16288115.850841522\n",
      "Elbo loss: 16257655.711566925\n",
      "Elbo loss: 16270344.331485748\n",
      "Elbo loss: 16342345.294166565\n",
      "Elbo loss: 15919929.547546387\n",
      "Elbo loss: 16114426.330440521\n",
      "Elbo loss: 15449073.024482727\n",
      "Elbo loss: 15926813.614624977\n",
      "Elbo loss: 15586750.751041412\n",
      "Elbo loss: 15827920.701267242\n",
      "Elbo loss: 15714445.02986908\n",
      "Elbo loss: 15497542.100240707\n",
      "Elbo loss: 15426100.48765564\n",
      "Elbo loss: 15437820.758758545\n",
      "Elbo loss: 15585684.149702072\n",
      "Elbo loss: 15870064.738471985\n",
      "Elbo loss: 15594255.186466217\n",
      "Elbo loss: 15578450.936626434\n",
      "Elbo loss: 15589500.542766571\n",
      "Elbo loss: 15133441.503730774\n",
      "Elbo loss: 15588512.186912537\n",
      "Elbo loss: 15487589.70847702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16507036.471118927,\n",
       " 16496506.882324219,\n",
       " 16725043.243679047,\n",
       " 16757541.569824219,\n",
       " 16918150.519577026,\n",
       " 16833062.85477066,\n",
       " 16704408.156257153,\n",
       " 16910661.563728333,\n",
       " 16673162.07164669,\n",
       " 17017526.848858833,\n",
       " 16882178.70968628,\n",
       " 16528738.827140808,\n",
       " 16472368.863552094,\n",
       " 16625404.072410583,\n",
       " 16564866.971096039,\n",
       " 16570515.512786865,\n",
       " 16734607.416477203,\n",
       " 16479054.055652618,\n",
       " 16483060.28685379,\n",
       " 16532277.746879578,\n",
       " 16316151.067085266,\n",
       " 16505781.601371765,\n",
       " 16345559.011214256,\n",
       " 16548068.182533264,\n",
       " 16689426.65473175,\n",
       " 16392662.219470024,\n",
       " 16446702.082932472,\n",
       " 16294120.535728455,\n",
       " 16434014.2137146,\n",
       " 16128583.033908844,\n",
       " 16288115.850841522,\n",
       " 16416165.300584793,\n",
       " 16276428.832092285,\n",
       " 16078770.043344498,\n",
       " 16182646.042268753,\n",
       " 16126891.797328949,\n",
       " 16419918.408088684,\n",
       " 16246004.408210754,\n",
       " 16403620.063171387,\n",
       " 16164927.168022156,\n",
       " 16257655.711566925,\n",
       " 16272669.908325195,\n",
       " 15973345.710792542,\n",
       " 16108965.42982483,\n",
       " 15875432.667793274,\n",
       " 16125924.253845215,\n",
       " 16135030.776966095,\n",
       " 16107974.334237576,\n",
       " 15942221.178153992,\n",
       " 16355228.12330246,\n",
       " 16270344.331485748,\n",
       " 15908247.247271776,\n",
       " 16566857.564457417,\n",
       " 16035639.58191681,\n",
       " 16165265.658138275,\n",
       " 16022235.24751091,\n",
       " 16389654.05859375,\n",
       " 15870910.638858795,\n",
       " 15826703.494167328,\n",
       " 15789247.992897034,\n",
       " 16342345.294166565,\n",
       " 15800009.864595413,\n",
       " 15916690.908027649,\n",
       " 15872281.477426529,\n",
       " 15887774.846412659,\n",
       " 15806945.83843565,\n",
       " 15900864.505126953,\n",
       " 15922861.198984146,\n",
       " 16427988.150596619,\n",
       " 16040998.448371887,\n",
       " 15919929.547546387,\n",
       " 16145212.856880188,\n",
       " 16113568.845108032,\n",
       " 15965631.544433594,\n",
       " 16036502.577526093,\n",
       " 15876524.033576965,\n",
       " 16199060.250073433,\n",
       " 15787710.435646057,\n",
       " 16215290.012413025,\n",
       " 15845512.885177612,\n",
       " 16114426.330440521,\n",
       " 15851728.461212158,\n",
       " 15852956.857584,\n",
       " 15981298.006420135,\n",
       " 15996588.736534119,\n",
       " 15904523.166484833,\n",
       " 15854740.314037323,\n",
       " 15565596.181214333,\n",
       " 15863747.382282257,\n",
       " 15897624.66474533,\n",
       " 15449073.024482727,\n",
       " 15745224.747955322,\n",
       " 15962121.989881516,\n",
       " 16123299.185533524,\n",
       " 15954523.1722641,\n",
       " 16083808.665985107,\n",
       " 15695824.988613129,\n",
       " 15804538.444839478,\n",
       " 15774681.198669434,\n",
       " 15623505.47277069,\n",
       " 15926813.614624977,\n",
       " 15794459.025575638,\n",
       " 16039189.990596771,\n",
       " 15812220.6447258,\n",
       " 15979347.09092331,\n",
       " 15892139.569551468,\n",
       " 15909107.23928833,\n",
       " 15697212.683143616,\n",
       " 15696747.020568848,\n",
       " 16093784.409301758,\n",
       " 15586750.751041412,\n",
       " 15922860.289211273,\n",
       " 15703673.150619507,\n",
       " 15758596.512954712,\n",
       " 15525268.142921448,\n",
       " 15752755.873752594,\n",
       " 15533891.340459824,\n",
       " 15786051.196418762,\n",
       " 15790839.431808472,\n",
       " 15473518.845149994,\n",
       " 15827920.701267242,\n",
       " 15692087.269408703,\n",
       " 15881916.950001717,\n",
       " 15578236.27797699,\n",
       " 15612678.655403137,\n",
       " 15757467.661521912,\n",
       " 15756821.63548088,\n",
       " 15699529.417663574,\n",
       " 15507061.45148468,\n",
       " 15521864.8468256,\n",
       " 15714445.02986908,\n",
       " 15548554.384456635,\n",
       " 15918831.631278992,\n",
       " 15942966.532112122,\n",
       " 15598392.578323364,\n",
       " 15556424.189470291,\n",
       " 15911246.185302734,\n",
       " 15623231.820497513,\n",
       " 15832231.672298431,\n",
       " 15616468.227279663,\n",
       " 15497542.100240707,\n",
       " 15861037.333515167,\n",
       " 15814826.630729675,\n",
       " 15595810.358024597,\n",
       " 15582183.778865814,\n",
       " 15699929.984638214,\n",
       " 15423451.582389832,\n",
       " 15659506.238845825,\n",
       " 15535013.584088326,\n",
       " 15447609.678474426,\n",
       " 15426100.48765564,\n",
       " 15467400.940856934,\n",
       " 15614213.434635162,\n",
       " 15663159.639255524,\n",
       " 15981826.220062256,\n",
       " 15732062.40726471,\n",
       " 15620178.823253632,\n",
       " 15395488.611772537,\n",
       " 15407874.66674614,\n",
       " 15778531.539405823,\n",
       " 15437820.758758545,\n",
       " 15606144.192764282,\n",
       " 15375635.969688416,\n",
       " 15850202.993946075,\n",
       " 15715283.519145966,\n",
       " 15773250.584777832,\n",
       " 15547774.443572998,\n",
       " 15695929.937355042,\n",
       " 15658804.61959076,\n",
       " 15573128.764421463,\n",
       " 15585684.149702072,\n",
       " 16056379.764404297,\n",
       " 15644116.437412262,\n",
       " 15516559.358013153,\n",
       " 15284904.736356735,\n",
       " 15433077.89087677,\n",
       " 15359215.45103836,\n",
       " 15633816.929893494,\n",
       " 15360519.703567505,\n",
       " 15445539.27798462,\n",
       " 15870064.738471985,\n",
       " 15761697.168543339,\n",
       " 15535525.4204216,\n",
       " 15457702.276380539,\n",
       " 15591632.004104614,\n",
       " 15670202.07440567,\n",
       " 15707230.566642761,\n",
       " 15498551.793619156,\n",
       " 15762793.374222755,\n",
       " 15396198.079177856,\n",
       " 15594255.186466217,\n",
       " 15614017.100387573,\n",
       " 15702858.405136585,\n",
       " 15713553.678173065,\n",
       " 15470010.355819702,\n",
       " 15125391.993322372,\n",
       " 15433078.926242828,\n",
       " 15578104.041683197,\n",
       " 15420454.572498322,\n",
       " 15339997.888780117,\n",
       " 15578450.936626434,\n",
       " 15464310.712429047,\n",
       " 15517398.592485428,\n",
       " 15298581.824092865,\n",
       " 15571824.434230804,\n",
       " 15681906.826662064,\n",
       " 15595059.062042236,\n",
       " 15396553.647285461,\n",
       " 15413994.538638115,\n",
       " 15399544.866596222,\n",
       " 15589500.542766571,\n",
       " 15840623.638126373,\n",
       " 15654409.728012085,\n",
       " 15461296.721313477,\n",
       " 15666421.033527374,\n",
       " 15326031.262268066,\n",
       " 15647912.535308838,\n",
       " 15663742.470977783,\n",
       " 15282905.481372833,\n",
       " 15578183.808006287,\n",
       " 15133441.503730774,\n",
       " 15301624.379867554,\n",
       " 15385850.502857208,\n",
       " 15464946.551847458,\n",
       " 15722826.657499313,\n",
       " 15020539.123921394,\n",
       " 15481205.169636726,\n",
       " 15546262.129173279,\n",
       " 15330268.149253845,\n",
       " 15959773.814346313,\n",
       " 15588512.186912537,\n",
       " 15587294.668518066,\n",
       " 15615664.430522919,\n",
       " 15302275.819786072,\n",
       " 15512717.07917881,\n",
       " 15693877.348651886,\n",
       " 15350004.242898941,\n",
       " 15332900.496261597,\n",
       " 15412289.184181213,\n",
       " 15511709.488265991,\n",
       " 15487589.70847702,\n",
       " 15432956.576099396,\n",
       " 15472220.919204712,\n",
       " 15413297.756988525,\n",
       " 15141371.957845688,\n",
       " 15430063.763504028,\n",
       " 15226800.089057922,\n",
       " 15457198.47555542,\n",
       " 15777150.465236664,\n",
       " 15851376.319734573]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.train_SVI(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "drug_int: (1000, 1, 1127)\n",
      "sf_int: (1000, 1, 5237)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36189\n",
      "AUC: 0.84249\n",
      "[[1. 1. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing!!!\n",
    "\n",
    "n,m = data.shape\n",
    "dim=10\n",
    "alpha_u = 4\n",
    "alpha_v=5\n",
    "beta_u=1\n",
    "beta_v=1\n",
    "def model():\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", m, dim= -1) #independent items\n",
    "   \n",
    "\n",
    "        with drug_plate:\n",
    "            \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(alpha_u, beta_u).expand([dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            sideeffect_intercept = pyro.sample(\"sf_int\", dist.HalfNormal(0.5))\n",
    "\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(alpha_v, beta_v).expand([dim]).to_event(1))\n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "        with u2_plate:\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(0.5))\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson( UA@VA.T+sideeffect_intercept.T ) ) \n",
    "            return Y\n",
    "\n",
    "def guide9():\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', 5*torch.ones(n,dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.05*torch.ones(n,dim), constraint=constraints.positive)\n",
    "        # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "        # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "            #                  constraint=constraints.positive)\n",
    "        s_alpha = pyro.param('s_alpha', 5*torch.ones(m,dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.05*torch.ones(m,dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\",n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\",m, dim= -1) #independent items\n",
    "        se_t = pyro.param(\"sef_int\", 0.25*torch.ones(m), constraint=constraints.positive)\n",
    "        drug_t = pyro.param(\"drug_int_p\", 0.25*torch.ones(n), constraint=constraints.positive)\n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "        with u2_plate:\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(drug_t).to_event(1))\n",
    "\n",
    "        \n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "     \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "            sideeffect_intercept =  pyro.sample(\"sf_int\", dist.HalfNormal(se_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Trace Shapes:               \n",
      "           Param Sites:               \n",
      "          Sample Sites:               \n",
      "      drug_latents dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "sideeffect_latents dist           |   \n",
      "                  value      5237 |   \n",
      "               log_prob           |   \n",
      "               UA2 dist      1127 | 10\n",
      "                  value      1127 | 10\n",
      "               log_prob      1127 |   \n",
      "            sf_int dist      5237 |   \n",
      "                  value      5237 |   \n",
      "               log_prob      5237 |   \n",
      "               VA2 dist      5237 | 10\n",
      "                  value      5237 | 10\n",
      "               log_prob      5237 |   \n",
      "          u2_plate dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "          drug_int dist 1127    1 |   \n",
      "                  value 1127    1 |   \n",
      "               log_prob 1127    1 |   \n",
      "            target dist 1127 5237 |   \n",
      "                  value 1127 5237 |   \n",
      "               log_prob 1127 5237 |   \n",
      "          Trace Shapes:                    \n",
      "           Param Sites:                    \n",
      "                d_alpha      1127   10     \n",
      "                 d_beta      1127   10     \n",
      "                s_alpha      5237   10     \n",
      "                 s_beta      5237   10     \n",
      "                sef_int           5237     \n",
      "             drug_int_p           1127     \n",
      "          Sample Sites:                    \n",
      "      drug_latents dist              |     \n",
      "                  value      1127    |     \n",
      "               log_prob              |     \n",
      "sideeffect_latents dist              |     \n",
      "                  value      5237    |     \n",
      "               log_prob              |     \n",
      "          u2_plate dist              |     \n",
      "                  value      1127    |     \n",
      "               log_prob              |     \n",
      "          drug_int dist 1127    1    | 1127\n",
      "                  value 1127    1    | 1127\n",
      "               log_prob 1127    1    |     \n",
      "               UA2 dist      1127    |   10\n",
      "                  value      1127    |   10\n",
      "               log_prob      1127    |     \n",
      "               VA2 dist      5237    |   10\n",
      "                  value      5237    |   10\n",
      "               log_prob      5237    |     \n",
      "            sf_int dist      5237    |     \n",
      "                  value      5237    |     \n",
      "               log_prob      5237    |     \n"
     ]
    }
   ],
   "source": [
    "trace=poutine.trace(model).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())\n",
    "\n",
    "trace=poutine.trace(guide9).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1127, 5237])\n",
      "torch.Size([1127, 5237])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(n,m)\n",
    "print(a.shape)\n",
    "z = torch.ones(n)\n",
    "x = torch.ones(m)\n",
    "b = z[:, np.newaxis] + x\n",
    "print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
