{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    \n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 2336314890.109375\n",
      "Elbo loss: 335497992.1171875\n",
      "Elbo loss: 88186257.00390625\n",
      "Elbo loss: 47303800.537109375\n",
      "Elbo loss: 36057061.96875\n",
      "Elbo loss: 32626538.515625\n",
      "Elbo loss: 31529050.171875\n",
      "Elbo loss: 30088246.25\n",
      "Elbo loss: 27043836.09375\n",
      "Elbo loss: 23925257.828125\n",
      "Elbo loss: 21573661.546875\n",
      "Elbo loss: 19923352.796875\n",
      "Elbo loss: 19119999.640625\n",
      "Elbo loss: 18205184.515625\n",
      "Elbo loss: 17605884.859375\n",
      "Elbo loss: 17287293.515625\n",
      "Elbo loss: 16694075.484375\n",
      "Elbo loss: 16594213.015625\n",
      "Elbo loss: 16351818.015625\n",
      "Elbo loss: 16263270.578125\n",
      "Elbo loss: 15928296.859375\n",
      "Elbo loss: 15722937.921875\n",
      "Elbo loss: 15567714.6875\n",
      "Elbo loss: 15421303.71875\n",
      "Elbo loss: 15315427.65625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2336314890.109375,\n",
       " 1891504406.84375,\n",
       " 1541580516.1875,\n",
       " 1278080721.546875,\n",
       " 1044348458.421875,\n",
       " 857057094.40625,\n",
       " 703237946.921875,\n",
       " 582897138.8515625,\n",
       " 480593163.6875,\n",
       " 400234920.96875,\n",
       " 335497992.1171875,\n",
       " 279226896.578125,\n",
       " 235646286.578125,\n",
       " 201481908.36132812,\n",
       " 173939746.76367188,\n",
       " 151126704.34960938,\n",
       " 132999747.81835938,\n",
       " 118129552.57421875,\n",
       " 106375419.33984375,\n",
       " 96390137.375,\n",
       " 88186257.00390625,\n",
       " 81378328.90625,\n",
       " 75930057.2109375,\n",
       " 70438017.33007812,\n",
       " 65844248.7265625,\n",
       " 62455475.556640625,\n",
       " 58810558.779052734,\n",
       " 55688136.95703125,\n",
       " 52644793.8515625,\n",
       " 49810326.36328125,\n",
       " 47303800.537109375,\n",
       " 44933473.35546875,\n",
       " 42958675.328125,\n",
       " 41306958.78515625,\n",
       " 39694746.2890625,\n",
       " 38325722.5390625,\n",
       " 37455363.51171875,\n",
       " 36669169.4765625,\n",
       " 36400280.1015625,\n",
       " 36218159.6171875,\n",
       " 36057061.96875,\n",
       " 35973082.9765625,\n",
       " 35646416.4453125,\n",
       " 35419718.0234375,\n",
       " 34836985.59375,\n",
       " 34383767.0625,\n",
       " 33893276.828125,\n",
       " 33536044.2734375,\n",
       " 33031919.734375,\n",
       " 32834954.140625,\n",
       " 32626538.515625,\n",
       " 32519942.75,\n",
       " 32464944.3125,\n",
       " 32440496.5,\n",
       " 32306711.390625,\n",
       " 32231050.28125,\n",
       " 32075384.859375,\n",
       " 31925101.46875,\n",
       " 31846354.03125,\n",
       " 31604102.21875,\n",
       " 31529050.171875,\n",
       " 31535582.625,\n",
       " 31305508.0625,\n",
       " 31212338.921875,\n",
       " 31120679.6875,\n",
       " 31119293.1875,\n",
       " 30919203.234375,\n",
       " 30693138.671875,\n",
       " 30493319.1875,\n",
       " 30330775.8125,\n",
       " 30088246.25,\n",
       " 29779073.765625,\n",
       " 29416265.359375,\n",
       " 29333973.5,\n",
       " 28872946.890625,\n",
       " 28631578.109375,\n",
       " 28444716.421875,\n",
       " 27960317.046875,\n",
       " 27550783.1875,\n",
       " 27309854.546875,\n",
       " 27043836.09375,\n",
       " 26581187.328125,\n",
       " 26340549.03125,\n",
       " 25983372.234375,\n",
       " 25731273.015625,\n",
       " 25422123.8125,\n",
       " 25197190.09375,\n",
       " 24775058.390625,\n",
       " 24270111.109375,\n",
       " 24007055.984375,\n",
       " 23925257.828125,\n",
       " 23548681.265625,\n",
       " 23389842.78125,\n",
       " 22845439.5625,\n",
       " 22953880.109375,\n",
       " 22609752.203125,\n",
       " 22484280.046875,\n",
       " 22151831.4375,\n",
       " 22053475.484375,\n",
       " 21767390.609375,\n",
       " 21573661.546875,\n",
       " 21306229.40625,\n",
       " 21203744.890625,\n",
       " 21219412.109375,\n",
       " 21240468.234375,\n",
       " 20775728.703125,\n",
       " 20789445.671875,\n",
       " 20535038.890625,\n",
       " 20296281.515625,\n",
       " 20206042.421875,\n",
       " 19923352.796875,\n",
       " 19772723.53125,\n",
       " 19894569.890625,\n",
       " 19871096.546875,\n",
       " 19674954.953125,\n",
       " 19525844.953125,\n",
       " 19731966.3125,\n",
       " 19354003.609375,\n",
       " 19198019.703125,\n",
       " 19213001.265625,\n",
       " 19119999.640625,\n",
       " 18902679.84375,\n",
       " 19027410.265625,\n",
       " 18604512.4375,\n",
       " 18683401.078125,\n",
       " 18817188.609375,\n",
       " 18600656.734375,\n",
       " 18304965.125,\n",
       " 18502751.765625,\n",
       " 18377016.5625,\n",
       " 18205184.515625,\n",
       " 18330182.40625,\n",
       " 18285779.09375,\n",
       " 18192249.5,\n",
       " 18150105.03125,\n",
       " 18049711.671875,\n",
       " 17837854.65625,\n",
       " 17776250.640625,\n",
       " 17890635.921875,\n",
       " 17657237.421875,\n",
       " 17605884.859375,\n",
       " 17531931.953125,\n",
       " 17463538.171875,\n",
       " 17776654.546875,\n",
       " 17536083.40625,\n",
       " 17401499.796875,\n",
       " 17419179.671875,\n",
       " 17062927.96875,\n",
       " 17377759.46875,\n",
       " 17128146.015625,\n",
       " 17287293.515625,\n",
       " 17254034.546875,\n",
       " 17045943.671875,\n",
       " 17109808.859375,\n",
       " 17064372.203125,\n",
       " 17020631.546875,\n",
       " 17108369.578125,\n",
       " 16963876.890625,\n",
       " 16885900.03125,\n",
       " 16849693.1875,\n",
       " 16694075.484375,\n",
       " 16832776.25,\n",
       " 16824998.40625,\n",
       " 16889342.5,\n",
       " 16833175.5625,\n",
       " 16908722.578125,\n",
       " 16552007.875,\n",
       " 16362558.203125,\n",
       " 16457245.875,\n",
       " 16740774.078125,\n",
       " 16594213.015625,\n",
       " 16556738.921875,\n",
       " 16526186.46875,\n",
       " 16386492.34375,\n",
       " 16522319.15625,\n",
       " 16237678.921875,\n",
       " 16460328.4375,\n",
       " 16368048.765625,\n",
       " 16718705.015625,\n",
       " 16447833.96875,\n",
       " 16351818.015625,\n",
       " 16331833.390625,\n",
       " 16275676.703125,\n",
       " 16125546.890625,\n",
       " 16149056.390625,\n",
       " 16421520.0625,\n",
       " 16027720.28125,\n",
       " 16106561.015625,\n",
       " 16169137.3125,\n",
       " 16098142.078125,\n",
       " 16263270.578125,\n",
       " 16083559.546875,\n",
       " 16194288.46875,\n",
       " 16117581.796875,\n",
       " 15838320.1875,\n",
       " 16095656.78125,\n",
       " 15973308.703125,\n",
       " 15779895.578125,\n",
       " 15840390.203125,\n",
       " 15740152.4375,\n",
       " 15928296.859375,\n",
       " 15596707.625,\n",
       " 15779384.5,\n",
       " 15878610.140625,\n",
       " 15884066.5,\n",
       " 15775212.96875,\n",
       " 15766647.90625,\n",
       " 15915173.28125,\n",
       " 15835988.28125,\n",
       " 15717042.09375,\n",
       " 15722937.921875,\n",
       " 15615541.328125,\n",
       " 15823981.4375,\n",
       " 15650668.984375,\n",
       " 15520837.65625,\n",
       " 15683343.65625,\n",
       " 15504314.90625,\n",
       " 15651086.40625,\n",
       " 15805455.625,\n",
       " 15526317.734375,\n",
       " 15567714.6875,\n",
       " 15698186.875,\n",
       " 15527251.046875,\n",
       " 15638334.90625,\n",
       " 15656967.59375,\n",
       " 15590921.90625,\n",
       " 15372410.609375,\n",
       " 15315437.984375,\n",
       " 15526913.78125,\n",
       " 15587966.78125,\n",
       " 15421303.71875,\n",
       " 15271175.140625,\n",
       " 15323928.015625,\n",
       " 15459858.109375,\n",
       " 15113709.53125,\n",
       " 15566973.03125,\n",
       " 15146591.828125,\n",
       " 15311925.546875,\n",
       " 15285778.578125,\n",
       " 15336573.25,\n",
       " 15315427.65625,\n",
       " 15273792.859375,\n",
       " 15472711.875,\n",
       " 15238071.5625,\n",
       " 15213245.4375,\n",
       " 15323780.015625,\n",
       " 15251134.8125,\n",
       " 15270457.75,\n",
       " 15202483.71875,\n",
       " 15395397.796875]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PMF(train=data, dim=100)\n",
    "test.train_SVI(data, ~torch.from_numpy(nan_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[ 2.  0.  2. ...  0.  2.  1.]\n",
      "  [ 2.  0.  0. ...  1.  4.  0.]\n",
      "  [ 1.  0.  0. ...  0.  4.  0.]\n",
      "  ...\n",
      "  [ 5.  0.  1. ... 17. 11.  0.]\n",
      "  [ 2.  0.  0. ...  6. 23.  0.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  3.]\n",
      "  [ 1.  0.  0. ...  1.  6.  0.]\n",
      "  ...\n",
      "  [14.  0.  0. ... 60. 24.  1.]\n",
      "  [ 1.  1.  0. ...  3.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  1.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 1.  0.  0. ...  1.  2.  0.]\n",
      "  ...\n",
      "  [ 5.  0.  0. ... 14. 13.  1.]\n",
      "  [ 5.  0.  0. ... 13. 17.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 1.  0.  0. ...  0.  3.  3.]\n",
      "  ...\n",
      "  [ 8.  0.  0. ... 19. 12.  0.]\n",
      "  [ 3.  0.  0. ...  5. 25.  0.]\n",
      "  [ 0.  0.  0. ...  2.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  1.  3.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ... 12.  3.  0.]\n",
      "  ...\n",
      "  [13.  0.  0. ... 22. 25.  1.]\n",
      "  [ 6.  0.  1. ...  6. 21.  0.]\n",
      "  [ 0.  1.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 7.  1.  3. ...  1.  2.  0.]\n",
      "  [ 1.  0.  0. ...  0.  1.  0.]\n",
      "  [ 1.  0.  0. ...  0.  2.  0.]\n",
      "  ...\n",
      "  [ 9.  0.  0. ...  4. 17.  1.]\n",
      "  [ 0.  0.  1. ...  2. 23.  0.]\n",
      "  [ 0.  0.  0. ...  1.  1.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36516\n",
      "AUC: 0.83883\n",
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " ...\n",
      " [1 0 0 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 1 1 1]\n",
      " ...\n",
      " [1 0 0 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8267106141796051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "low, high = (1,1)\n",
    "test_data = data.copy()\n",
    "test_data[test_data < low] = 0\n",
    "test_data[test_data >= high] = 1\n",
    "preds = test.get_predictions()\n",
    "preds[preds<low] = 0\n",
    "preds[preds>=high] = 1\n",
    "print(test_data.astype(int))\n",
    "print(preds.astype(int))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(), preds.astype(int).flatten(), pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_intercepts(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(0.5))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            sideeffect_intercept = pyro.sample(\"sf_int\", dist.HalfNormal(0.5))\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "       #with u2_plate:\n",
    "           \n",
    "            \n",
    "        with sideeffect_plate, u2_plate: \n",
    "            #Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T  +sideeffect_intercept.T), obs=train ) z[:, np.newaxis] + x\n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T  + (drug_intercept[:, np.newaxis] + sideeffect_intercept.T)), obs=train ) \n",
    "            return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        se_t = pyro.param(\"sef_int\", 0.25*torch.ones(self.m), constraint=constraints.positive)\n",
    "        drug_t = pyro.param(\"drug_int_p\", 0.25*torch.ones(self.n), constraint=constraints.positive)\n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "       # with u2_plate:\n",
    "          #  drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(drug_t).to_event(1))\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            UA_int = pyro.sample(\"UAint\", dist.HalfNormal(drug_t))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "            sideeffect_intercept =  pyro.sample(\"sf_int\", dist.HalfNormal(se_t))\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "\n",
    "    \n",
    "   \n",
    "test = PMF_intercepts(data, 100)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 16507036.471118927\n",
      "Elbo loss: 16882178.70968628\n",
      "Elbo loss: 16316151.067085266\n",
      "Elbo loss: 16288115.850841522\n",
      "Elbo loss: 16257655.711566925\n",
      "Elbo loss: 16270344.331485748\n",
      "Elbo loss: 16342345.294166565\n",
      "Elbo loss: 15919929.547546387\n",
      "Elbo loss: 16114426.330440521\n",
      "Elbo loss: 15449073.024482727\n",
      "Elbo loss: 15926813.614624977\n",
      "Elbo loss: 15586750.751041412\n",
      "Elbo loss: 15827920.701267242\n",
      "Elbo loss: 15714445.02986908\n",
      "Elbo loss: 15497542.100240707\n",
      "Elbo loss: 15426100.48765564\n",
      "Elbo loss: 15437820.758758545\n",
      "Elbo loss: 15585684.149702072\n",
      "Elbo loss: 15870064.738471985\n",
      "Elbo loss: 15594255.186466217\n",
      "Elbo loss: 15578450.936626434\n",
      "Elbo loss: 15589500.542766571\n",
      "Elbo loss: 15133441.503730774\n",
      "Elbo loss: 15588512.186912537\n",
      "Elbo loss: 15487589.70847702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16507036.471118927,\n",
       " 16496506.882324219,\n",
       " 16725043.243679047,\n",
       " 16757541.569824219,\n",
       " 16918150.519577026,\n",
       " 16833062.85477066,\n",
       " 16704408.156257153,\n",
       " 16910661.563728333,\n",
       " 16673162.07164669,\n",
       " 17017526.848858833,\n",
       " 16882178.70968628,\n",
       " 16528738.827140808,\n",
       " 16472368.863552094,\n",
       " 16625404.072410583,\n",
       " 16564866.971096039,\n",
       " 16570515.512786865,\n",
       " 16734607.416477203,\n",
       " 16479054.055652618,\n",
       " 16483060.28685379,\n",
       " 16532277.746879578,\n",
       " 16316151.067085266,\n",
       " 16505781.601371765,\n",
       " 16345559.011214256,\n",
       " 16548068.182533264,\n",
       " 16689426.65473175,\n",
       " 16392662.219470024,\n",
       " 16446702.082932472,\n",
       " 16294120.535728455,\n",
       " 16434014.2137146,\n",
       " 16128583.033908844,\n",
       " 16288115.850841522,\n",
       " 16416165.300584793,\n",
       " 16276428.832092285,\n",
       " 16078770.043344498,\n",
       " 16182646.042268753,\n",
       " 16126891.797328949,\n",
       " 16419918.408088684,\n",
       " 16246004.408210754,\n",
       " 16403620.063171387,\n",
       " 16164927.168022156,\n",
       " 16257655.711566925,\n",
       " 16272669.908325195,\n",
       " 15973345.710792542,\n",
       " 16108965.42982483,\n",
       " 15875432.667793274,\n",
       " 16125924.253845215,\n",
       " 16135030.776966095,\n",
       " 16107974.334237576,\n",
       " 15942221.178153992,\n",
       " 16355228.12330246,\n",
       " 16270344.331485748,\n",
       " 15908247.247271776,\n",
       " 16566857.564457417,\n",
       " 16035639.58191681,\n",
       " 16165265.658138275,\n",
       " 16022235.24751091,\n",
       " 16389654.05859375,\n",
       " 15870910.638858795,\n",
       " 15826703.494167328,\n",
       " 15789247.992897034,\n",
       " 16342345.294166565,\n",
       " 15800009.864595413,\n",
       " 15916690.908027649,\n",
       " 15872281.477426529,\n",
       " 15887774.846412659,\n",
       " 15806945.83843565,\n",
       " 15900864.505126953,\n",
       " 15922861.198984146,\n",
       " 16427988.150596619,\n",
       " 16040998.448371887,\n",
       " 15919929.547546387,\n",
       " 16145212.856880188,\n",
       " 16113568.845108032,\n",
       " 15965631.544433594,\n",
       " 16036502.577526093,\n",
       " 15876524.033576965,\n",
       " 16199060.250073433,\n",
       " 15787710.435646057,\n",
       " 16215290.012413025,\n",
       " 15845512.885177612,\n",
       " 16114426.330440521,\n",
       " 15851728.461212158,\n",
       " 15852956.857584,\n",
       " 15981298.006420135,\n",
       " 15996588.736534119,\n",
       " 15904523.166484833,\n",
       " 15854740.314037323,\n",
       " 15565596.181214333,\n",
       " 15863747.382282257,\n",
       " 15897624.66474533,\n",
       " 15449073.024482727,\n",
       " 15745224.747955322,\n",
       " 15962121.989881516,\n",
       " 16123299.185533524,\n",
       " 15954523.1722641,\n",
       " 16083808.665985107,\n",
       " 15695824.988613129,\n",
       " 15804538.444839478,\n",
       " 15774681.198669434,\n",
       " 15623505.47277069,\n",
       " 15926813.614624977,\n",
       " 15794459.025575638,\n",
       " 16039189.990596771,\n",
       " 15812220.6447258,\n",
       " 15979347.09092331,\n",
       " 15892139.569551468,\n",
       " 15909107.23928833,\n",
       " 15697212.683143616,\n",
       " 15696747.020568848,\n",
       " 16093784.409301758,\n",
       " 15586750.751041412,\n",
       " 15922860.289211273,\n",
       " 15703673.150619507,\n",
       " 15758596.512954712,\n",
       " 15525268.142921448,\n",
       " 15752755.873752594,\n",
       " 15533891.340459824,\n",
       " 15786051.196418762,\n",
       " 15790839.431808472,\n",
       " 15473518.845149994,\n",
       " 15827920.701267242,\n",
       " 15692087.269408703,\n",
       " 15881916.950001717,\n",
       " 15578236.27797699,\n",
       " 15612678.655403137,\n",
       " 15757467.661521912,\n",
       " 15756821.63548088,\n",
       " 15699529.417663574,\n",
       " 15507061.45148468,\n",
       " 15521864.8468256,\n",
       " 15714445.02986908,\n",
       " 15548554.384456635,\n",
       " 15918831.631278992,\n",
       " 15942966.532112122,\n",
       " 15598392.578323364,\n",
       " 15556424.189470291,\n",
       " 15911246.185302734,\n",
       " 15623231.820497513,\n",
       " 15832231.672298431,\n",
       " 15616468.227279663,\n",
       " 15497542.100240707,\n",
       " 15861037.333515167,\n",
       " 15814826.630729675,\n",
       " 15595810.358024597,\n",
       " 15582183.778865814,\n",
       " 15699929.984638214,\n",
       " 15423451.582389832,\n",
       " 15659506.238845825,\n",
       " 15535013.584088326,\n",
       " 15447609.678474426,\n",
       " 15426100.48765564,\n",
       " 15467400.940856934,\n",
       " 15614213.434635162,\n",
       " 15663159.639255524,\n",
       " 15981826.220062256,\n",
       " 15732062.40726471,\n",
       " 15620178.823253632,\n",
       " 15395488.611772537,\n",
       " 15407874.66674614,\n",
       " 15778531.539405823,\n",
       " 15437820.758758545,\n",
       " 15606144.192764282,\n",
       " 15375635.969688416,\n",
       " 15850202.993946075,\n",
       " 15715283.519145966,\n",
       " 15773250.584777832,\n",
       " 15547774.443572998,\n",
       " 15695929.937355042,\n",
       " 15658804.61959076,\n",
       " 15573128.764421463,\n",
       " 15585684.149702072,\n",
       " 16056379.764404297,\n",
       " 15644116.437412262,\n",
       " 15516559.358013153,\n",
       " 15284904.736356735,\n",
       " 15433077.89087677,\n",
       " 15359215.45103836,\n",
       " 15633816.929893494,\n",
       " 15360519.703567505,\n",
       " 15445539.27798462,\n",
       " 15870064.738471985,\n",
       " 15761697.168543339,\n",
       " 15535525.4204216,\n",
       " 15457702.276380539,\n",
       " 15591632.004104614,\n",
       " 15670202.07440567,\n",
       " 15707230.566642761,\n",
       " 15498551.793619156,\n",
       " 15762793.374222755,\n",
       " 15396198.079177856,\n",
       " 15594255.186466217,\n",
       " 15614017.100387573,\n",
       " 15702858.405136585,\n",
       " 15713553.678173065,\n",
       " 15470010.355819702,\n",
       " 15125391.993322372,\n",
       " 15433078.926242828,\n",
       " 15578104.041683197,\n",
       " 15420454.572498322,\n",
       " 15339997.888780117,\n",
       " 15578450.936626434,\n",
       " 15464310.712429047,\n",
       " 15517398.592485428,\n",
       " 15298581.824092865,\n",
       " 15571824.434230804,\n",
       " 15681906.826662064,\n",
       " 15595059.062042236,\n",
       " 15396553.647285461,\n",
       " 15413994.538638115,\n",
       " 15399544.866596222,\n",
       " 15589500.542766571,\n",
       " 15840623.638126373,\n",
       " 15654409.728012085,\n",
       " 15461296.721313477,\n",
       " 15666421.033527374,\n",
       " 15326031.262268066,\n",
       " 15647912.535308838,\n",
       " 15663742.470977783,\n",
       " 15282905.481372833,\n",
       " 15578183.808006287,\n",
       " 15133441.503730774,\n",
       " 15301624.379867554,\n",
       " 15385850.502857208,\n",
       " 15464946.551847458,\n",
       " 15722826.657499313,\n",
       " 15020539.123921394,\n",
       " 15481205.169636726,\n",
       " 15546262.129173279,\n",
       " 15330268.149253845,\n",
       " 15959773.814346313,\n",
       " 15588512.186912537,\n",
       " 15587294.668518066,\n",
       " 15615664.430522919,\n",
       " 15302275.819786072,\n",
       " 15512717.07917881,\n",
       " 15693877.348651886,\n",
       " 15350004.242898941,\n",
       " 15332900.496261597,\n",
       " 15412289.184181213,\n",
       " 15511709.488265991,\n",
       " 15487589.70847702,\n",
       " 15432956.576099396,\n",
       " 15472220.919204712,\n",
       " 15413297.756988525,\n",
       " 15141371.957845688,\n",
       " 15430063.763504028,\n",
       " 15226800.089057922,\n",
       " 15457198.47555542,\n",
       " 15777150.465236664,\n",
       " 15851376.319734573]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.train_SVI(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "drug_int: (1000, 1, 1127)\n",
      "sf_int: (1000, 1, 5237)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36189\n",
      "AUC: 0.84249\n",
      "[[1. 1. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing!!!\n",
    "\n",
    "n,m = data.shape\n",
    "dim=10\n",
    "alpha_u = 4\n",
    "alpha_v=5\n",
    "beta_u=1\n",
    "beta_v=1\n",
    "def model():\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", m, dim= -1) #independent items\n",
    "   \n",
    "\n",
    "        with drug_plate:\n",
    "            \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(alpha_u, beta_u).expand([dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            sideeffect_intercept = pyro.sample(\"sf_int\", dist.HalfNormal(0.5))\n",
    "\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(alpha_v, beta_v).expand([dim]).to_event(1))\n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "        with u2_plate:\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(0.5))\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson( UA@VA.T+sideeffect_intercept.T ) ) \n",
    "            return Y\n",
    "\n",
    "def guide9():\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', 5*torch.ones(n,dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.05*torch.ones(n,dim), constraint=constraints.positive)\n",
    "        # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "        # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "            #                  constraint=constraints.positive)\n",
    "        s_alpha = pyro.param('s_alpha', 5*torch.ones(m,dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.05*torch.ones(m,dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\",n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\",m, dim= -1) #independent items\n",
    "        se_t = pyro.param(\"sef_int\", 0.25*torch.ones(m), constraint=constraints.positive)\n",
    "        drug_t = pyro.param(\"drug_int_p\", 0.25*torch.ones(n), constraint=constraints.positive)\n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "        with u2_plate:\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(drug_t).to_event(1))\n",
    "\n",
    "        \n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "     \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "            sideeffect_intercept =  pyro.sample(\"sf_int\", dist.HalfNormal(se_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Trace Shapes:               \n",
      "           Param Sites:               \n",
      "          Sample Sites:               \n",
      "      drug_latents dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "sideeffect_latents dist           |   \n",
      "                  value      5237 |   \n",
      "               log_prob           |   \n",
      "               UA2 dist      1127 | 10\n",
      "                  value      1127 | 10\n",
      "               log_prob      1127 |   \n",
      "            sf_int dist      5237 |   \n",
      "                  value      5237 |   \n",
      "               log_prob      5237 |   \n",
      "               VA2 dist      5237 | 10\n",
      "                  value      5237 | 10\n",
      "               log_prob      5237 |   \n",
      "          u2_plate dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "          drug_int dist 1127    1 |   \n",
      "                  value 1127    1 |   \n",
      "               log_prob 1127    1 |   \n",
      "            target dist 1127 5237 |   \n",
      "                  value 1127 5237 |   \n",
      "               log_prob 1127 5237 |   \n",
      "          Trace Shapes:                    \n",
      "           Param Sites:                    \n",
      "                d_alpha      1127   10     \n",
      "                 d_beta      1127   10     \n",
      "                s_alpha      5237   10     \n",
      "                 s_beta      5237   10     \n",
      "                sef_int           5237     \n",
      "             drug_int_p           1127     \n",
      "          Sample Sites:                    \n",
      "      drug_latents dist              |     \n",
      "                  value      1127    |     \n",
      "               log_prob              |     \n",
      "sideeffect_latents dist              |     \n",
      "                  value      5237    |     \n",
      "               log_prob              |     \n",
      "          u2_plate dist              |     \n",
      "                  value      1127    |     \n",
      "               log_prob              |     \n",
      "          drug_int dist 1127    1    | 1127\n",
      "                  value 1127    1    | 1127\n",
      "               log_prob 1127    1    |     \n",
      "               UA2 dist      1127    |   10\n",
      "                  value      1127    |   10\n",
      "               log_prob      1127    |     \n",
      "               VA2 dist      5237    |   10\n",
      "                  value      5237    |   10\n",
      "               log_prob      5237    |     \n",
      "            sf_int dist      5237    |     \n",
      "                  value      5237    |     \n",
      "               log_prob      5237    |     \n"
     ]
    }
   ],
   "source": [
    "trace=poutine.trace(model).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())\n",
    "\n",
    "trace=poutine.trace(guide9).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1127, 5237])\n",
      "torch.Size([1127, 5237])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(n,m)\n",
    "print(a.shape)\n",
    "z = torch.ones(n)\n",
    "x = torch.ones(m)\n",
    "b = z[:, np.newaxis] + x\n",
    "print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
