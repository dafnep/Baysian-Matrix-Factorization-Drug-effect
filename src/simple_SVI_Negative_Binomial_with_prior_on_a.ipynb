{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False,  True, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False,  True, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )\n",
    "\n",
    "with open('data_train.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)\n",
    "print(data2.shape)\n",
    "\n",
    "nan_mask = np.isnan(data2) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_NB_with_drug_varying_alpha(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, data,train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = data.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "        self.predictive_svi  = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "        a = 50\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "            exposure = pyro.sample(\"exposure\", dist.Gamma(a,a))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.Poisson(exposure[:, np.newaxis]*(UA@VA.T )), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "        exp_alpha = pyro.param('exp_alpha', 10*torch.ones(self.n), constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            exposure = pyro.sample(\"exposure\", dist.Gamma(exp_alpha,exp_alpha))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=500, lr = 0.05, lrd = 1, verbose=True):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if(verbose):\n",
    "                if step % 10 == 0:\n",
    "                    print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"exposure\"].numpy()\n",
    "        self.predictive_svi = predictive_svi\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        self.predictive_svi = predictive_svi\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "\n",
    "  \n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    def rmse(self,test,masked,h):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < h] = low\n",
    "        test_data[test_data >= h] = high\n",
    "        size = masked.sum()\n",
    "        predictions = self.predictions\n",
    "        predictions[predictions < h] = low\n",
    "        predictions[predictions >= h] = high\n",
    "        print(predictions.shape)\n",
    "        print(masked.shape)\n",
    "        sqerror = abs(test_data[masked] - predictions[masked]) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/size\n",
    "        print(\"PMF  RMSE: \" , np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data[masked].astype(int).flatten(),  predictions[masked].astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    def get_predictive_svi(self):\n",
    "         return (self.predictive_svi)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 1065275266.6543274\n",
      "Elbo loss: 169799746.33642578\n",
      "Elbo loss: 58979671.5663147\n",
      "Elbo loss: 35360938.697052\n",
      "Elbo loss: 31147146.61416626\n",
      "Elbo loss: 28951434.214385986\n",
      "Elbo loss: 27969522.804779053\n",
      "Elbo loss: 26542591.08230591\n",
      "Elbo loss: 24511143.21245575\n",
      "Elbo loss: 22388412.926776886\n",
      "Elbo loss: 20552185.680530548\n",
      "Elbo loss: 19355309.5254364\n",
      "Elbo loss: 18762569.479995728\n",
      "Elbo loss: 17964894.622833252\n",
      "Elbo loss: 17523390.178359985\n",
      "Elbo loss: 17191609.505218506\n",
      "Elbo loss: 16971229.588867188\n",
      "Elbo loss: 16855621.918823242\n",
      "Elbo loss: 16449360.611114502\n",
      "Elbo loss: 16468665.700683594\n",
      "Elbo loss: 16095948.288757324\n",
      "Elbo loss: 15798037.846832275\n",
      "Elbo loss: 16012890.302490234\n",
      "Elbo loss: 15784177.328674316\n",
      "Elbo loss: 15280610.742553711\n",
      "Elbo loss: 15792921.825042725\n",
      "Elbo loss: 15382473.724273682\n",
      "Elbo loss: 15510881.202453613\n",
      "Elbo loss: 15389410.067352295\n",
      "Elbo loss: 15417605.04397583\n",
      "Elbo loss: 15437211.991821289\n",
      "Elbo loss: 15259442.893493652\n",
      "Elbo loss: 15262806.54473877\n",
      "Elbo loss: 14934635.097991943\n",
      "Elbo loss: 15187056.208435059\n",
      "Elbo loss: 14905486.906066895\n",
      "Elbo loss: 15008435.079711914\n",
      "Elbo loss: 14835912.918334961\n",
      "Elbo loss: 14887047.530090332\n",
      "Elbo loss: 14932395.252380371\n",
      "Elbo loss: 14950345.853088379\n",
      "Elbo loss: 14745767.866210938\n",
      "Elbo loss: 14874632.518493652\n",
      "Elbo loss: 14810304.431640625\n",
      "Elbo loss: 14607507.729492188\n",
      "Elbo loss: 14667185.452209473\n",
      "Elbo loss: 14907788.621643066\n",
      "Elbo loss: 14858536.946472168\n",
      "Elbo loss: 14453746.43725586\n",
      "Elbo loss: 14529098.651245117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = PMF_NB_with_drug_varying_alpha(data,data2,50)\n",
    "l = test.train_SVI(data, ~torch.from_numpy(nan_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (300, 1, 1127, 50)\n",
      "exposure: (300, 1, 1127)\n",
      "VA: (300, 1, 5237, 50)\n",
      "target: (300, 1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "print(data2[nan_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "(1127, 5237)\n",
      "PMF  RMSE:  0.3560744092446151\n",
      "AUC: 0.83054\n",
      "(1127, 5237)\n",
      "(1127, 5237)\n",
      "PMF  RMSE:  0.34841491146581494\n",
      "AUC: 0.83613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34841491146581494, 0.8361346607902966)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rmse(data, nan_mask,1)\n",
    "#train rmse\n",
    "test.rmse(data, ~nan_mask,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "(1127, 5237)\n",
      "PMF  RMSE:  0.2935781208202841\n",
      "AUC: 0.50000\n",
      "(1127, 5237)\n",
      "(1127, 5237)\n",
      "PMF  RMSE:  0.29386885556227027\n",
      "AUC: 0.50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.29386885556227027, 0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rmse(data, nan_mask,4)\n",
    "#train rmse\n",
    "test.rmse(data, ~nan_mask,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple_PMF ={}\n",
    "Simple_PMF['losses'] = l \n",
    "#Simple_PMF['predictive_score'] = d\n",
    "Simple_PMF['train_rmse'] = .34841\n",
    "Simple_PMF['test_rmse'] = 0.35607\n",
    "Simple_PMF['AUC'] = 0.838\n",
    "Simple_PMF['train_rmse_3'] = 0.2938\n",
    "Simple_PMF['test_rmse_3'] = 0.2935\n",
    "Simple_PMF['predictions'] = test.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SVI_negative_binomial_with_prior.pickle', 'wb') as handle:\n",
    "    pickle.dump(Simple_PMF, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
