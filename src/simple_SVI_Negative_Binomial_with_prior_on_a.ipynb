{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_NB_with_drug_varying_alpha(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "        a = 50\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "            exposure = pyro.sample(\"exposure\", dist.Gamma(a,a))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.Poisson(exposure[:, np.newaxis]*(UA@VA.T )), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "        exp_alpha = pyro.param('exp_alpha', 10*torch.ones(self.n), constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            exposure = pyro.sample(\"exposure\", dist.Gamma(exp_alpha,exp_alpha))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"exposure\"].numpy()\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Elbo loss: 14194447.621154785\n",
      "Elbo loss: 14130161.198669434\n",
      "Elbo loss: 14284480.731445312\n",
      "Elbo loss: 14230367.996765137\n",
      "Elbo loss: 14324177.706298828\n",
      "Elbo loss: 14331913.098388672\n",
      "Elbo loss: 14118142.445678711\n",
      "Elbo loss: 14296141.019104004\n",
      "Elbo loss: 14119174.425048828\n",
      "Elbo loss: 14156370.638671875\n",
      "Elbo loss: 14143980.662963867\n",
      "Elbo loss: 13827753.295166016\n",
      "Elbo loss: 13845488.619506836\n",
      "Elbo loss: 13972778.467041016\n",
      "Elbo loss: 13938079.723144531\n",
      "Elbo loss: 13949353.765014648\n",
      "Elbo loss: 13896417.450317383\n",
      "Elbo loss: 14047570.932373047\n",
      "Elbo loss: 14177313.704833984\n",
      "Elbo loss: 13987042.729858398\n",
      "Elbo loss: 14221438.900634766\n",
      "Elbo loss: 13900161.85144043\n",
      "Elbo loss: 13910488.899414062\n",
      "Elbo loss: 13890673.642700195\n",
      "Elbo loss: 13692674.022094727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14194447.621154785,\n",
       " 14333842.333068848,\n",
       " 14514311.205993652,\n",
       " 14218491.99243164,\n",
       " 14209397.851379395,\n",
       " 14638470.243286133,\n",
       " 14669731.4453125,\n",
       " 14691354.706176758,\n",
       " 14223818.681030273,\n",
       " 14411563.524169922,\n",
       " 14130161.198669434,\n",
       " 14446784.10180664,\n",
       " 14411112.045593262,\n",
       " 14419595.591247559,\n",
       " 14331046.775390625,\n",
       " 14350604.32421875,\n",
       " 14440236.947753906,\n",
       " 14162428.555603027,\n",
       " 14441033.882202148,\n",
       " 14288192.323608398,\n",
       " 14284480.731445312,\n",
       " 14356508.256408691,\n",
       " 14225457.04675293,\n",
       " 14095841.653015137,\n",
       " 14379981.488708496,\n",
       " 14282829.19555664,\n",
       " 14149645.112487793,\n",
       " 14194447.8984375,\n",
       " 14300100.908813477,\n",
       " 14065399.546020508,\n",
       " 14230367.996765137,\n",
       " 14098761.446350098,\n",
       " 14265725.034179688,\n",
       " 14310495.785766602,\n",
       " 14390462.949584961,\n",
       " 13881414.09741211,\n",
       " 14316394.94720459,\n",
       " 14062477.778808594,\n",
       " 14298401.50769043,\n",
       " 14286171.079711914,\n",
       " 14324177.706298828,\n",
       " 14277318.918151855,\n",
       " 14179637.600708008,\n",
       " 14048939.700012207,\n",
       " 14200867.963806152,\n",
       " 14075476.076660156,\n",
       " 13950326.0836792,\n",
       " 14219917.582824707,\n",
       " 13844610.914550781,\n",
       " 13968095.744262695,\n",
       " 14331913.098388672,\n",
       " 14058289.309936523,\n",
       " 14313453.239379883,\n",
       " 13961875.678710938,\n",
       " 14521725.129516602,\n",
       " 14298984.492675781,\n",
       " 14052462.924438477,\n",
       " 14250171.98461914,\n",
       " 14207263.457397461,\n",
       " 13992261.854370117,\n",
       " 14118142.445678711,\n",
       " 13954904.63104248,\n",
       " 13929872.043457031,\n",
       " 14223191.568725586,\n",
       " 13900776.872680664,\n",
       " 13907859.253112793,\n",
       " 14345403.182312012,\n",
       " 13971555.261047363,\n",
       " 13913787.132751465,\n",
       " 14059218.904174805,\n",
       " 14296141.019104004,\n",
       " 14373876.32598877,\n",
       " 14146073.677246094,\n",
       " 13848521.69946289,\n",
       " 14401894.552246094,\n",
       " 14038398.628112793,\n",
       " 13858165.759338379,\n",
       " 14183645.667541504,\n",
       " 14239458.155578613,\n",
       " 14272615.188598633,\n",
       " 14119174.425048828,\n",
       " 14214424.765075684,\n",
       " 14164698.314086914,\n",
       " 14062443.928283691,\n",
       " 14274125.692749023,\n",
       " 13773063.373535156,\n",
       " 13923796.1640625,\n",
       " 14107300.349060059,\n",
       " 13790868.879516602,\n",
       " 14014995.311950684,\n",
       " 14156370.638671875,\n",
       " 14122787.684020996,\n",
       " 14314716.786132812,\n",
       " 13919718.831176758,\n",
       " 14409839.646362305,\n",
       " 14096747.979187012,\n",
       " 14263468.635253906,\n",
       " 13928720.053955078,\n",
       " 14073049.205322266,\n",
       " 14496947.941955566,\n",
       " 14143980.662963867,\n",
       " 14179329.206848145,\n",
       " 14098570.59375,\n",
       " 14260680.561889648,\n",
       " 14221919.642089844,\n",
       " 13924054.07232666,\n",
       " 14173265.731323242,\n",
       " 14218815.576416016,\n",
       " 13876578.459533691,\n",
       " 14003507.678649902,\n",
       " 13827753.295166016,\n",
       " 13949165.605651855,\n",
       " 13944949.389587402,\n",
       " 14129200.518432617,\n",
       " 14259415.63470459,\n",
       " 14337796.640930176,\n",
       " 14078913.866210938,\n",
       " 14113160.203491211,\n",
       " 14183733.881835938,\n",
       " 14006053.209472656,\n",
       " 13845488.619506836,\n",
       " 14277644.258300781,\n",
       " 13930942.577636719,\n",
       " 14420523.372436523,\n",
       " 13901030.096740723,\n",
       " 14010090.914916992,\n",
       " 13861007.482299805,\n",
       " 13982688.427490234,\n",
       " 14203717.426086426,\n",
       " 14164754.510253906,\n",
       " 13972778.467041016,\n",
       " 14158391.447692871,\n",
       " 13982998.729492188,\n",
       " 14205663.60760498,\n",
       " 13857039.026245117,\n",
       " 14036753.82409668,\n",
       " 14238513.837890625,\n",
       " 14058098.063171387,\n",
       " 13967299.280395508,\n",
       " 13777729.700683594,\n",
       " 13938079.723144531,\n",
       " 13932584.649658203,\n",
       " 14069381.377563477,\n",
       " 13995894.414916992,\n",
       " 13890717.25201416,\n",
       " 13895675.625366211,\n",
       " 13671865.584594727,\n",
       " 13769095.883178711,\n",
       " 14025938.013916016,\n",
       " 14054563.155761719,\n",
       " 13949353.765014648,\n",
       " 13921233.669433594,\n",
       " 14039407.317382812,\n",
       " 14136473.379272461,\n",
       " 13957606.380737305,\n",
       " 13925352.884887695,\n",
       " 13865613.547729492,\n",
       " 13906488.893798828,\n",
       " 13987565.35534668,\n",
       " 14537011.797729492,\n",
       " 13896417.450317383,\n",
       " 13810440.313598633,\n",
       " 14024638.759277344,\n",
       " 14140360.889282227,\n",
       " 14127328.812133789,\n",
       " 13859599.918457031,\n",
       " 13977165.77722168,\n",
       " 14221380.517211914,\n",
       " 13843935.852172852,\n",
       " 14183732.616088867,\n",
       " 14047570.932373047,\n",
       " 13857099.639404297,\n",
       " 14046033.320678711,\n",
       " 13782416.25793457,\n",
       " 13880646.772338867,\n",
       " 13933154.723388672,\n",
       " 13889581.287597656,\n",
       " 14041470.305175781,\n",
       " 14135903.928955078,\n",
       " 14121869.48449707,\n",
       " 14177313.704833984,\n",
       " 13909461.989624023,\n",
       " 13956279.98840332,\n",
       " 13801985.474853516,\n",
       " 14072326.82824707,\n",
       " 13683483.944213867,\n",
       " 13910709.700439453,\n",
       " 13801609.07421875,\n",
       " 13802570.170166016,\n",
       " 14022448.875488281,\n",
       " 13987042.729858398,\n",
       " 13777785.182617188,\n",
       " 13821389.091796875,\n",
       " 13960508.115844727,\n",
       " 14340627.680786133,\n",
       " 14239428.244262695,\n",
       " 14185650.691040039,\n",
       " 14509253.128540039,\n",
       " 13793574.200317383,\n",
       " 13908268.756835938,\n",
       " 14221438.900634766,\n",
       " 13840350.971557617,\n",
       " 13857017.732543945,\n",
       " 14043749.95288086,\n",
       " 14326308.359985352,\n",
       " 13833359.745605469,\n",
       " 14193332.535766602,\n",
       " 14003450.084106445,\n",
       " 13882177.263305664,\n",
       " 14427332.301391602,\n",
       " 13900161.85144043,\n",
       " 13869820.036010742,\n",
       " 14224912.698730469,\n",
       " 13950173.462768555,\n",
       " 13754279.747924805,\n",
       " 13860892.064086914,\n",
       " 14883596.075195312,\n",
       " 14007287.373168945,\n",
       " 13982538.123535156,\n",
       " 13993769.674804688,\n",
       " 13910488.899414062,\n",
       " 14378543.592163086,\n",
       " 13885640.053100586,\n",
       " 14342832.188598633,\n",
       " 13939106.689453125,\n",
       " 14172787.6015625,\n",
       " 14175224.852539062,\n",
       " 13962340.26147461,\n",
       " 13799514.153076172,\n",
       " 13723022.510009766,\n",
       " 13890673.642700195,\n",
       " 13907565.977172852,\n",
       " 14259993.002197266,\n",
       " 13893168.361206055,\n",
       " 14266722.206665039,\n",
       " 13832562.634277344,\n",
       " 13891154.16418457,\n",
       " 13801813.671142578,\n",
       " 14199873.398925781,\n",
       " 13945193.10534668,\n",
       " 13692674.022094727,\n",
       " 13707655.694213867,\n",
       " 13968233.956176758,\n",
       " 13958928.73022461,\n",
       " 13759739.401245117,\n",
       " 13627927.086914062,\n",
       " 13858426.045288086,\n",
       " 14162172.185913086,\n",
       " 13733177.15625,\n",
       " 14184306.809692383]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )\n",
    "test = PMF_NB_with_drug_varying_alpha(train=data, dim=100)\n",
    "test.train_SVI(data, ~torch.from_numpy(nan_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "exposure: (1000, 1, 1127)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[ 1.  0.  0. ...  1.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  2.  0.]\n",
      "  ...\n",
      "  [12.  0.  0. ...  6.  7.  0.]\n",
      "  [ 3.  0.  1. ...  8. 15.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  1.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  2. ...  0.  2.  0.]\n",
      "  ...\n",
      "  [14.  0.  0. ...  6.  2.  0.]\n",
      "  [ 4.  0.  0. ...  2. 25.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 2.  0.  0. ...  0.  1.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [14.  0.  1. ... 12.  4.  0.]\n",
      "  [ 7.  0.  0. ...  7.  3.  1.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3. 12.  0.]\n",
      "  ...\n",
      "  [ 8.  0.  0. ... 21. 33.  0.]\n",
      "  [ 6.  0.  0. ...  6. 19.  1.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]]\n",
      "\n",
      " [[ 1.  1.  0. ...  1.  1.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  1.  4.  0.]\n",
      "  ...\n",
      "  [10.  0.  0. ... 13. 19.  0.]\n",
      "  [ 3.  0.  0. ...  4. 10.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 0.  0.  0. ...  1.  1.  0.]\n",
      "  ...\n",
      "  [ 3.  0.  1. ...  5. 21.  0.]\n",
      "  [ 4.  0.  0. ...  7. 39.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.33401\n",
      "AUC: 0.84041\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
