{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_zero_NB(nn.Module):\n",
    "\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "        self.alpha = 1\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "        alpha = 1\n",
    "        beta = 1\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #alpha = pyro.sample(\"alpha\", dist.Poisson(self.alpha))\n",
    "            #tendacy of people not reporting side effects\n",
    "            p = pyro.sample(\"p\", dist.Beta(alpha, beta))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "           # with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.ZeroInflatedDistribution( base_dist= dist.NegativeBinomial(alpha, UA@VA.T/( UA@VA.T+alpha)) ,gate = p[:, np.newaxis]), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "        rate_alpha = pyro.param('rate_alpha', torch.ones(self.n), constraint=constraints.positive)\n",
    "        rate_beta = pyro.param('rate_beta', torch.ones(self.n), constraint=constraints.positive)\n",
    "\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            p = pyro.sample(\"p\", dist.Beta(rate_beta,rate_alpha))\n",
    "\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Elbo loss: 6012035.456176758\n",
      "Elbo loss: 6026213.563171387\n",
      "Elbo loss: 5999806.37689209\n",
      "Elbo loss: 6007662.76953125\n",
      "Elbo loss: 5995980.518127441\n",
      "Elbo loss: 5969965.423828125\n",
      "Elbo loss: 6014862.355224609\n",
      "Elbo loss: 5978878.61340332\n",
      "Elbo loss: 5958227.224975586\n",
      "Elbo loss: 5949028.366088867\n",
      "Elbo loss: 5967524.559936523\n",
      "Elbo loss: 5937743.723571777\n",
      "Elbo loss: 5964058.8966674805\n",
      "Elbo loss: 5960032.478393555\n",
      "Elbo loss: 5957602.663635254\n",
      "Elbo loss: 5935067.991943359\n",
      "Elbo loss: 5938172.410766602\n",
      "Elbo loss: 5915344.634277344\n",
      "Elbo loss: 5933078.581726074\n",
      "Elbo loss: 5929822.35534668\n",
      "Elbo loss: 5946331.634033203\n",
      "Elbo loss: 5940296.6384887695\n",
      "Elbo loss: 5917414.670532227\n",
      "Elbo loss: 5902229.934265137\n",
      "Elbo loss: 5920493.146972656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6012035.456176758,\n",
       " 6012342.945617676,\n",
       " 6004319.902587891,\n",
       " 6017493.768127441,\n",
       " 6034775.2158203125,\n",
       " 6007978.318664551,\n",
       " 6030311.8955078125,\n",
       " 5986345.342956543,\n",
       " 6015944.429016113,\n",
       " 6018410.323974609,\n",
       " 6026213.563171387,\n",
       " 6028207.652770996,\n",
       " 6013876.738891602,\n",
       " 6020635.438964844,\n",
       " 6039289.8212890625,\n",
       " 5998328.465454102,\n",
       " 6028851.170043945,\n",
       " 5993492.186157227,\n",
       " 6026789.848510742,\n",
       " 6003249.84185791,\n",
       " 5999806.37689209,\n",
       " 6022679.270263672,\n",
       " 6039606.224121094,\n",
       " 5974590.749328613,\n",
       " 5992812.397521973,\n",
       " 6003235.42980957,\n",
       " 6026491.765380859,\n",
       " 6026796.878845215,\n",
       " 6000504.59576416,\n",
       " 5976955.481811523,\n",
       " 6007662.76953125,\n",
       " 5970413.448547363,\n",
       " 5988363.527587891,\n",
       " 5985468.2060546875,\n",
       " 5962649.883850098,\n",
       " 6008944.888000488,\n",
       " 6005564.186889648,\n",
       " 5974745.263000488,\n",
       " 5984125.41796875,\n",
       " 6015425.143432617,\n",
       " 5995980.518127441,\n",
       " 5986274.057678223,\n",
       " 5970616.791931152,\n",
       " 5985542.175231934,\n",
       " 5971055.80456543,\n",
       " 5971207.098693848,\n",
       " 5976890.8572387695,\n",
       " 5988524.072509766,\n",
       " 6006659.8359375,\n",
       " 5955468.06842041,\n",
       " 5969965.423828125,\n",
       " 5986882.206359863,\n",
       " 5989162.155639648,\n",
       " 5991813.727905273,\n",
       " 5976948.073364258,\n",
       " 5970323.7443237305,\n",
       " 6000486.051086426,\n",
       " 5974122.28326416,\n",
       " 5959504.445922852,\n",
       " 5976980.264526367,\n",
       " 6014862.355224609,\n",
       " 5983132.149291992,\n",
       " 5981735.092529297,\n",
       " 6001747.267944336,\n",
       " 5983726.092041016,\n",
       " 5988810.618652344,\n",
       " 5985008.983581543,\n",
       " 5964766.074951172,\n",
       " 5954032.092407227,\n",
       " 5985302.364624023,\n",
       " 5978878.61340332,\n",
       " 5982831.3876953125,\n",
       " 5966951.679748535,\n",
       " 5950585.236206055,\n",
       " 5975395.490844727,\n",
       " 5973199.916931152,\n",
       " 5985470.321716309,\n",
       " 5950166.637390137,\n",
       " 5946843.063720703,\n",
       " 5980596.039550781,\n",
       " 5958227.224975586,\n",
       " 5968138.903442383,\n",
       " 5977810.573669434,\n",
       " 6002096.495178223,\n",
       " 5963673.753112793,\n",
       " 5947687.0830078125,\n",
       " 5954300.892944336,\n",
       " 5954239.937988281,\n",
       " 5943115.663330078,\n",
       " 5971635.339477539,\n",
       " 5949028.366088867,\n",
       " 5939549.659851074,\n",
       " 5956260.347900391,\n",
       " 5970557.2400512695,\n",
       " 5977413.0087890625,\n",
       " 5963070.16809082,\n",
       " 5937715.61517334,\n",
       " 5959804.203063965,\n",
       " 5965693.557006836,\n",
       " 5932419.540588379,\n",
       " 5967524.559936523,\n",
       " 5945860.823364258,\n",
       " 5972727.115234375,\n",
       " 5977215.467956543,\n",
       " 5957805.066650391,\n",
       " 5944966.321777344,\n",
       " 5975933.185058594,\n",
       " 5978522.262329102,\n",
       " 5973203.892028809,\n",
       " 5958242.575256348,\n",
       " 5937743.723571777,\n",
       " 5963552.245605469,\n",
       " 5959344.259277344,\n",
       " 5970134.016418457,\n",
       " 5933943.878845215,\n",
       " 5941202.937438965,\n",
       " 5956200.424499512,\n",
       " 5949595.398132324,\n",
       " 5959300.196166992,\n",
       " 5977785.846374512,\n",
       " 5964058.8966674805,\n",
       " 5974563.420959473,\n",
       " 5945769.282775879,\n",
       " 5966930.4853515625,\n",
       " 5963188.5546875,\n",
       " 5952430.010986328,\n",
       " 5960768.261474609,\n",
       " 5941176.988586426,\n",
       " 5948590.233947754,\n",
       " 5943135.304626465,\n",
       " 5960032.478393555,\n",
       " 5963478.901733398,\n",
       " 5930974.392272949,\n",
       " 5970839.510314941,\n",
       " 5953758.660522461,\n",
       " 5931193.178405762,\n",
       " 5942461.898010254,\n",
       " 5931196.600891113,\n",
       " 5941050.930908203,\n",
       " 5961827.117431641,\n",
       " 5957602.663635254,\n",
       " 5939638.539367676,\n",
       " 5936204.577636719,\n",
       " 5937309.114624023,\n",
       " 5960298.875244141,\n",
       " 5983788.036193848,\n",
       " 5957436.669189453,\n",
       " 5948570.860473633,\n",
       " 5942010.804382324,\n",
       " 5936743.244140625,\n",
       " 5935067.991943359,\n",
       " 5937582.55871582,\n",
       " 5973050.456604004,\n",
       " 5944254.4884643555,\n",
       " 5971313.098571777,\n",
       " 5940891.223815918,\n",
       " 5961814.2421875,\n",
       " 5954472.5759887695,\n",
       " 5922964.038452148,\n",
       " 5937431.847595215,\n",
       " 5938172.410766602,\n",
       " 5942969.379455566,\n",
       " 5961425.009643555,\n",
       " 5944660.200500488,\n",
       " 5929630.270874023,\n",
       " 5936278.456665039,\n",
       " 5964964.307800293,\n",
       " 5936076.92199707,\n",
       " 5947204.498413086,\n",
       " 5952898.177429199,\n",
       " 5915344.634277344,\n",
       " 5938644.155212402,\n",
       " 5921970.953491211,\n",
       " 5930049.273803711,\n",
       " 5941459.977783203,\n",
       " 5938466.39855957,\n",
       " 5926456.29498291,\n",
       " 5940774.200683594,\n",
       " 5912872.720825195,\n",
       " 5914624.127807617,\n",
       " 5933078.581726074,\n",
       " 5941981.849609375,\n",
       " 5958152.815734863,\n",
       " 5951266.643859863,\n",
       " 5926877.00592041,\n",
       " 5935830.084716797,\n",
       " 5939381.526977539,\n",
       " 5926788.493408203,\n",
       " 5935021.9716796875,\n",
       " 5930053.993041992,\n",
       " 5929822.35534668,\n",
       " 5900785.633666992,\n",
       " 5898995.497436523,\n",
       " 5915199.233825684,\n",
       " 5939202.110961914,\n",
       " 5932826.355041504,\n",
       " 5934678.107666016,\n",
       " 5923485.973510742,\n",
       " 5931131.012939453,\n",
       " 5916406.616027832,\n",
       " 5946331.634033203,\n",
       " 5943439.299621582,\n",
       " 5941981.8416137695,\n",
       " 5944375.107543945,\n",
       " 5929062.151733398,\n",
       " 5902421.925170898,\n",
       " 5925964.497253418,\n",
       " 5907158.252685547,\n",
       " 5944367.542358398,\n",
       " 5941806.574279785,\n",
       " 5940296.6384887695,\n",
       " 5932105.598815918,\n",
       " 5927649.120422363,\n",
       " 5937451.438354492,\n",
       " 5923051.003356934,\n",
       " 5926995.12689209,\n",
       " 5939304.232299805,\n",
       " 5904083.769836426,\n",
       " 5910709.937255859,\n",
       " 5934026.994445801,\n",
       " 5917414.670532227,\n",
       " 5908483.177368164,\n",
       " 5914735.543701172,\n",
       " 5924134.338012695,\n",
       " 5901321.4728393555,\n",
       " 5915232.135070801,\n",
       " 5933779.7052612305,\n",
       " 5922940.827453613,\n",
       " 5926298.061950684,\n",
       " 5916525.661987305,\n",
       " 5902229.934265137,\n",
       " 5912839.914916992,\n",
       " 5920708.6591796875,\n",
       " 5918290.356567383,\n",
       " 5915142.637756348,\n",
       " 5914371.724609375,\n",
       " 5901327.310791016,\n",
       " 5910603.616760254,\n",
       " 5928094.186767578,\n",
       " 5899462.851135254,\n",
       " 5920493.146972656,\n",
       " 5922349.145812988,\n",
       " 5942294.368652344,\n",
       " 5934243.13269043,\n",
       " 5911132.954589844,\n",
       " 5937907.349731445,\n",
       " 5915986.329528809,\n",
       " 5926926.460876465,\n",
       " 5924002.732177734,\n",
       " 5917698.34777832]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )\n",
    "test = PMF_zero_NB(train=data, dim=100)\n",
    "test.train_SVI(data, ~torch.from_numpy(nan_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "p: (1000, 1, 1127)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  0.  3.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [25.  0.  1. ...  5. 14.  1.]\n",
      "  [ 0.  0.  0. ...  1.  6.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 3.  0.  0. ... 13.  7.  0.]\n",
      "  [ 0.  0.  0. ...  1.  3.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 2.  1.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  1.  0. ...  7.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  2.  0. ... 10. 49.  0.]\n",
      "  [12.  0.  0. ...  3. 39.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  1.  1. ...  2.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0. 13.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  3.  7.  2.]\n",
      "  [ 2.  2.  0. ...  1. 19.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  1.  0.  0.]\n",
      "  [ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  1. ...  3.  0.  1.]\n",
      "  ...\n",
      "  [35.  0.  2. ... 26.  9.  0.]\n",
      "  [ 1.  0.  0. ...  2. 45.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.34168\n",
      "AUC: 0.83550\n",
      "(array([[[ 0.,  0.,  0., ...,  0.,  3.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [25.,  0.,  1., ...,  5., 14.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  1.,  6.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  1.,  0., ...,  0.,  2.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 3.,  0.,  0., ..., 13.,  7.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  1.,  3.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 2.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0., ...,  7.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  2.,  0., ..., 10., 49.,  0.],\n",
      "        [12.,  0.,  0., ...,  3., 39.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  1.,  1., ...,  2.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  0., 13.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ...,  3.,  7.,  2.],\n",
      "        [ 2.,  2.,  0., ...,  1., 19.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [35.,  0.,  2., ..., 26.,  9.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  2., 45.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
