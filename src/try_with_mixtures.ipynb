{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from pyro import poutine\n",
    "from sklearn import metrics\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal, AutoLowRankMultivariateNormal, init_to_mean,init_to_feasible,AutoNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PMF_clusters(nn.Module):\n",
    "    #bayesian non parametrics - dirichlet process\n",
    "\n",
    "    #with multivariate gammas that are \"somehow?\" related through pyro's dependent dimension setting\n",
    "    #how to define their covariance?\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "        self.num_clusters_drugs = 5\n",
    "        self.num_clusters_se =  10\n",
    "    def mix_weights(self,beta):\n",
    "            beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "            return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "    def model(self, data):\n",
    "            alpha = 0.1\n",
    "            with pyro.plate(\"beta_drugs_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_drugs_plate\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_drugs\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(self.mix_weights(beta_drugs)))\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d], torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(self.mix_weights(beta_se)))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], torch.eye(self.dim)))\n",
    "            \n",
    "            u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "            se2_plate = pyro.plate(\"se2_plate\", self.m, dim=-1)\n",
    "\n",
    "            with se2_plate, u2_plate: \n",
    "                Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=data ) \n",
    "                return Y\n",
    "\n",
    "    def guide(self,data=None):\n",
    "            kappa = pyro.param('kappa_d', lambda: dist.Uniform(0, 2).sample([self.num_clusters_drugs-1]), constraint=constraints.positive)\n",
    "            tau = pyro.param('tau_d', lambda: dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)).sample([self.num_clusters_drugs]))\n",
    "            phi = pyro.param('phi_d', lambda: dist.Dirichlet(1/self.num_clusters_drugs * torch.ones(self.num_clusters_drugs)).sample([self.n]), constraint=constraints.simplex)\n",
    "\n",
    "            with pyro.plate(\"beta_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(torch.ones(self.num_clusters_drugs-1), kappa))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_drug\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(tau, torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_drug\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(phi))\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d], torch.eye(self.dim)))\n",
    "\n",
    "            \n",
    "            kappa_s = pyro.param('kappa_s', lambda: dist.Uniform(0, 2).sample([self.num_clusters_se-1]), constraint=constraints.positive)\n",
    "            tau_s = pyro.param('tau_s', lambda: dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)).sample([self.num_clusters_se]))\n",
    "            phi_s = pyro.param('phi_s', lambda: dist.Dirichlet(1/self.num_clusters_se * torch.ones(self.num_clusters_se)).sample([self.m]), constraint=constraints.simplex)\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(torch.ones(self.num_clusters_se-1), kappa_s))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(tau_s, torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(phi_s))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], torch.eye(self.dim)))\n",
    "\n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "                logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "                svi = SVI(self.model,\n",
    "                self.guide,\n",
    "                optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "                loss=Trace_ELBO())\n",
    "                losses = []\n",
    "                for step in range(nsteps):\n",
    "                    elbo = svi.step(torch.from_numpy(train).float())\n",
    "                    losses.append(elbo)\n",
    "                    if step % 10 == 0:\n",
    "                        print(\"Elbo loss: {}\".format(elbo))\n",
    "                self.losses = losses\n",
    "                #constrained_params = list(pyro.get_param_store().values())\n",
    "                #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "                #print(PARAMS)\n",
    "                return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'mu_plate_drug', 'beta_plate', 'data_drug'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 170333202.72097492\n",
      "Elbo loss: 171507606.7302152\n",
      "Elbo loss: 165512936.2486418\n",
      "Elbo loss: 169319632.4801597\n",
      "Elbo loss: 162791561.27348012\n",
      "Elbo loss: 164676929.1861047\n",
      "Elbo loss: 164732843.07234585\n",
      "Elbo loss: 162971541.6796273\n",
      "Elbo loss: 164328151.93174267\n",
      "Elbo loss: 159778966.43127453\n",
      "Elbo loss: 161964433.89461613\n",
      "Elbo loss: 158638836.18453467\n",
      "Elbo loss: 161577749.12965137\n",
      "Elbo loss: 162302984.18946004\n",
      "Elbo loss: 158828284.97283804\n",
      "Elbo loss: 163584730.48053694\n",
      "Elbo loss: 163630120.66321015\n",
      "Elbo loss: 158342146.59430647\n",
      "Elbo loss: 166061768.09017003\n",
      "Elbo loss: 162117679.09715545\n",
      "Elbo loss: 160387243.80076563\n",
      "Elbo loss: 164987436.0388283\n",
      "Elbo loss: 157676786.8433683\n",
      "Elbo loss: 160296463.0647326\n",
      "Elbo loss: 163174325.3161726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[170333202.72097492,\n",
       " 162292778.97869027,\n",
       " 174552258.24824154,\n",
       " 167429912.5915593,\n",
       " 175191001.1995377,\n",
       " 173403596.81074893,\n",
       " 172334883.4760805,\n",
       " 160031743.01762122,\n",
       " 168377044.31872618,\n",
       " 169331772.11819598,\n",
       " 171507606.7302152,\n",
       " 165704237.78437135,\n",
       " 169407054.28472775,\n",
       " 168554952.51679182,\n",
       " 165937697.5300961,\n",
       " 176425321.42185506,\n",
       " 169783934.69481742,\n",
       " 174450578.8925225,\n",
       " 170786236.03162226,\n",
       " 166968625.76068553,\n",
       " 165512936.2486418,\n",
       " 171885907.66150492,\n",
       " 163180210.55908933,\n",
       " 165949605.9802571,\n",
       " 164210752.69084615,\n",
       " 166332874.15098742,\n",
       " 169706746.3094123,\n",
       " 169146982.28950354,\n",
       " 171235492.6609692,\n",
       " 168086929.63003618,\n",
       " 169319632.4801597,\n",
       " 165892642.65986976,\n",
       " 164604346.3941257,\n",
       " 171689093.3460443,\n",
       " 164034149.39280748,\n",
       " 168924616.91286182,\n",
       " 173896953.26908392,\n",
       " 161910000.63772595,\n",
       " 168543931.66266608,\n",
       " 164839965.51895392,\n",
       " 162791561.27348012,\n",
       " 167677793.66685736,\n",
       " 163397423.86693367,\n",
       " 164430262.54720592,\n",
       " 164264145.5830592,\n",
       " 164890951.30644602,\n",
       " 163418107.1546222,\n",
       " 163779939.88256,\n",
       " 165549376.18399674,\n",
       " 170890703.13707542,\n",
       " 164676929.1861047,\n",
       " 159023503.69969812,\n",
       " 177633704.92731464,\n",
       " 164084133.64034802,\n",
       " 162432046.58154392,\n",
       " 161473526.9416796,\n",
       " 161351831.67852622,\n",
       " 165246348.00884145,\n",
       " 161707874.18260586,\n",
       " 163005393.59819806,\n",
       " 164732843.07234585,\n",
       " 170136966.6251644,\n",
       " 165139586.60374486,\n",
       " 158851967.53185868,\n",
       " 159430956.92593187,\n",
       " 157971960.6627041,\n",
       " 171136254.38974282,\n",
       " 161137105.73767623,\n",
       " 161310159.52885616,\n",
       " 157706543.80388957,\n",
       " 162971541.6796273,\n",
       " 161063839.7278688,\n",
       " 164530130.85695624,\n",
       " 165757805.8184732,\n",
       " 164991570.47412091,\n",
       " 169470049.61033583,\n",
       " 167136636.5923769,\n",
       " 164314795.88227737,\n",
       " 163556424.52450454,\n",
       " 165303676.353272,\n",
       " 164328151.93174267,\n",
       " 160325017.46308902,\n",
       " 158617401.45134854,\n",
       " 160775669.1921209,\n",
       " 167136817.39897826,\n",
       " 163157679.89806938,\n",
       " 160048751.50317585,\n",
       " 158668230.36202157,\n",
       " 160825992.006485,\n",
       " 162933881.62459314,\n",
       " 159778966.43127453,\n",
       " 158615939.04247153,\n",
       " 160410062.45702446,\n",
       " 163322060.7661054,\n",
       " 164493127.37750506,\n",
       " 163794431.57236177,\n",
       " 167395226.55268204,\n",
       " 166338560.17425323,\n",
       " 164071510.16845357,\n",
       " 173173310.42498738,\n",
       " 161964433.89461613,\n",
       " 163349513.76312214,\n",
       " 163862389.90361798,\n",
       " 163548060.61943555,\n",
       " 160158625.39885324,\n",
       " 165033595.25108665,\n",
       " 163332461.08999574,\n",
       " 174586809.22250262,\n",
       " 157929457.57501292,\n",
       " 160189861.14165235,\n",
       " 158638836.18453467,\n",
       " 162026595.56836355,\n",
       " 164060191.89888644,\n",
       " 162331979.83531833,\n",
       " 160616786.35369658,\n",
       " 166208532.84696805,\n",
       " 162484151.99109173,\n",
       " 163343036.8826667,\n",
       " 159384958.45307136,\n",
       " 164956513.28719872,\n",
       " 161577749.12965137,\n",
       " 159648910.21288252,\n",
       " 159245326.6148982,\n",
       " 163814801.1685763,\n",
       " 159777335.11976564,\n",
       " 165146622.81463048,\n",
       " 165066509.94566476,\n",
       " 162543844.4646603,\n",
       " 157860524.79201853,\n",
       " 154806672.4628545,\n",
       " 162302984.18946004,\n",
       " 163840121.36151123,\n",
       " 162441734.42744792,\n",
       " 160873547.22550464,\n",
       " 161739840.52665913,\n",
       " 157855937.4259007,\n",
       " 164757994.63384473,\n",
       " 164621677.66483092,\n",
       " 159579499.0279274,\n",
       " 161115442.00104177,\n",
       " 158828284.97283804,\n",
       " 157215496.58435535,\n",
       " 157556164.2332214,\n",
       " 157028832.53119397,\n",
       " 161144499.63394505,\n",
       " 158256128.69049883,\n",
       " 161819301.1625079,\n",
       " 164718503.39007467,\n",
       " 165347551.64609575,\n",
       " 161461922.73804474,\n",
       " 163584730.48053694,\n",
       " 166616246.15967295,\n",
       " 161212363.0767752,\n",
       " 157542758.9727394,\n",
       " 158149641.874079,\n",
       " 162636998.43046677,\n",
       " 159218127.42361522,\n",
       " 172247342.96032405,\n",
       " 161576071.48453093,\n",
       " 154764391.2478416,\n",
       " 163630120.66321015,\n",
       " 162014137.39528066,\n",
       " 163382165.67606926,\n",
       " 164275325.6105383,\n",
       " 163407612.52753687,\n",
       " 163516096.82978678,\n",
       " 161459669.355582,\n",
       " 160541033.1728642,\n",
       " 159917527.51077172,\n",
       " 159060530.882797,\n",
       " 158342146.59430647,\n",
       " 159422159.05474257,\n",
       " 162815823.66666484,\n",
       " 166569291.24803638,\n",
       " 163359187.369267,\n",
       " 161748250.52144158,\n",
       " 162140359.58916748,\n",
       " 163782589.46520662,\n",
       " 167222435.83046412,\n",
       " 160496024.09298408,\n",
       " 166061768.09017003,\n",
       " 160970923.9025365,\n",
       " 163546304.36397845,\n",
       " 161933251.93369842,\n",
       " 157646091.72537982,\n",
       " 159391101.4787625,\n",
       " 170583688.06589714,\n",
       " 161076627.4307388,\n",
       " 163182478.47487044,\n",
       " 157595260.06979236,\n",
       " 162117679.09715545,\n",
       " 174626927.67577678,\n",
       " 160158591.66878337,\n",
       " 163748398.8141017,\n",
       " 155340127.65013552,\n",
       " 158157578.7082497,\n",
       " 162911750.0419938,\n",
       " 162439811.4114362,\n",
       " 159726159.7313968,\n",
       " 161899605.76794052,\n",
       " 160387243.80076563,\n",
       " 159645817.81416756,\n",
       " 162972085.36550474,\n",
       " 158221283.7026688,\n",
       " 156028638.9634862,\n",
       " 159448932.473032,\n",
       " 162422673.02392828,\n",
       " 159943981.02495557,\n",
       " 163738761.30131328,\n",
       " 158739652.50253505,\n",
       " 164987436.0388283,\n",
       " 159134752.75934452,\n",
       " 161068265.8229766,\n",
       " 162570296.89121127,\n",
       " 159582526.51810706,\n",
       " 164648080.22412026,\n",
       " 163585981.0541786,\n",
       " 160596390.45502794,\n",
       " 162453284.52347916,\n",
       " 161035581.3171575,\n",
       " 157676786.8433683,\n",
       " 156773640.7483828,\n",
       " 158674655.13928306,\n",
       " 157896157.39964116,\n",
       " 161752976.00426084,\n",
       " 157247038.83942115,\n",
       " 156007904.14841557,\n",
       " 163446128.13141203,\n",
       " 162186692.41276407,\n",
       " 166872320.2974651,\n",
       " 160296463.0647326,\n",
       " 156845017.39856863,\n",
       " 163057542.2752334,\n",
       " 161687198.54633006,\n",
       " 161189411.83983177,\n",
       " 160781139.46314597,\n",
       " 162908952.533247,\n",
       " 160016834.69689733,\n",
       " 155287127.68440592,\n",
       " 162815933.8183825,\n",
       " 163174325.3161726,\n",
       " 160407700.4027793,\n",
       " 165286439.37553024,\n",
       " 158005575.31440216,\n",
       " 165688008.1948505,\n",
       " 157681442.816576,\n",
       " 157868441.2634709,\n",
       " 165340420.24856293,\n",
       " 162784508.6187892,\n",
       " 163111155.99805033]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "test = PMF_clusters(train=data, dim=100)\n",
    "test.train_SVI(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_drugs: (700, 1, 4)\n",
      "mu_drugs: (700, 1, 5, 100)\n",
      "z_drugs: (700, 1, 1127)\n",
      "UA: (700, 1, 1127, 100)\n",
      "beta_se: (700, 1, 9)\n",
      "mu_se: (700, 1, 10, 100)\n",
      "z_se: (700, 1, 5237)\n",
      "VA: (700, 1, 5237, 100)\n",
      "target: (700, 1127, 5237)\n",
      "[[[24. 14. 38. ...  4. 35. 27.]\n",
      "  [20. 27.  8. ... 10. 14.  9.]\n",
      "  [ 2.  3. 11. ...  0.  8. 16.]\n",
      "  ...\n",
      "  [ 1.  1.  4. ... 11.  4. 12.]\n",
      "  [35. 22. 30. ... 38. 15. 12.]\n",
      "  [26. 27.  0. ... 41. 13. 12.]]\n",
      "\n",
      " [[28. 44. 14. ... 13. 23. 24.]\n",
      "  [29.  2.  3. ... 16. 13. 59.]\n",
      "  [21.  2. 22. ... 14. 36.  3.]\n",
      "  ...\n",
      "  [13.  3. 26. ... 28.  4. 34.]\n",
      "  [ 8. 35. 34. ... 26. 24. 19.]\n",
      "  [28.  0. 69. ...  2. 14. 22.]]\n",
      "\n",
      " [[ 5. 12.  6. ...  8. 27.  4.]\n",
      "  [26. 52.  0. ...  9. 58. 30.]\n",
      "  [26.  3.  5. ...  5.  8. 29.]\n",
      "  ...\n",
      "  [ 0. 13.  2. ... 10.  0. 35.]\n",
      "  [ 1. 11.  5. ...  4.  7. 43.]\n",
      "  [20.  2. 11. ... 15. 23. 23.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4. 34. 58. ... 47.  7. 30.]\n",
      "  [ 6.  3. 25. ... 44. 49.  0.]\n",
      "  [ 9.  1.  2. ... 45. 15. 43.]\n",
      "  ...\n",
      "  [ 5.  7.  8. ...  4. 15. 22.]\n",
      "  [15.  5. 43. ... 24.  6.  8.]\n",
      "  [ 0. 24. 10. ... 17.  0. 24.]]\n",
      "\n",
      " [[32. 40.  5. ...  2. 20. 47.]\n",
      "  [18. 18. 20. ... 32.  6. 23.]\n",
      "  [ 6. 29.  3. ... 20. 10. 12.]\n",
      "  ...\n",
      "  [ 0.  5. 11. ... 14.  0.  9.]\n",
      "  [ 8. 10. 16. ... 22. 31. 35.]\n",
      "  [17. 30. 15. ...  6. 19.  9.]]\n",
      "\n",
      " [[12. 37. 20. ... 14.  9. 13.]\n",
      "  [10. 10.  1. ... 22. 36. 23.]\n",
      "  [15.  8.  6. ... 15.  5. 29.]\n",
      "  ...\n",
      "  [ 2. 19. 20. ... 16. 29. 35.]\n",
      "  [27. 17. 15. ... 23. 42. 22.]\n",
      "  [ 3. 52. 15. ... 18.  7. 10.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictive_svi = Predictive(test.model, guide=test.guide, num_samples=700)(None )\n",
    "for k, v in predictive_svi.items():\n",
    "    print(f\"{k}: {tuple(v.shape)}\")\n",
    "table = predictive_svi[\"target\"].numpy()\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "def model(self, data):\n",
    "            alpha = 0.1\n",
    "            with pyro.plate(\"beta_drugs_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_drugs_plate\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_drugs\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(self.mix_weights(beta_drugs)))\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d], torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(self.mix_weights(beta_se)))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], torch.eye(self.dim)))\n",
    "            \n",
    "            u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "            se2_plate = pyro.plate(\"se2_plate\", self.m, dim=-1)\n",
    "\n",
    "            with se2_plate, u2_plate: \n",
    "                Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=data ) \n",
    "                return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = np.mean(self.data, axis=1).mean()\n",
    "        self.alpha_v =  np.std(self.data, axis=1).mean()\n",
    "        \n",
    "        self.beta_u = np.mean(self.data, axis=0).mean() \n",
    "        self.beta_v =  np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Normal(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Normal(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "         \n",
    "             Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Normal(d_alpha, d_beta).to_event(1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Normal(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "    \n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None )\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    \n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 11992020.8125\n",
      "Elbo loss: 12044234.3125\n",
      "Elbo loss: 11983409.609375\n",
      "Elbo loss: 11980527.859375\n",
      "Elbo loss: 11985525.8125\n",
      "Elbo loss: 11964293.296875\n",
      "Elbo loss: 11938020.515625\n",
      "Elbo loss: 11923634.890625\n",
      "Elbo loss: 11889246.625\n",
      "Elbo loss: 11873478.9140625\n",
      "Elbo loss: 11884241.9765625\n",
      "Elbo loss: 11905652.8515625\n",
      "Elbo loss: 11870566.46875\n",
      "Elbo loss: 11875177.05859375\n",
      "Elbo loss: 11843510.703125\n",
      "Elbo loss: 11835140.0234375\n",
      "Elbo loss: 11831297.0078125\n",
      "Elbo loss: 11780705.17578125\n",
      "Elbo loss: 11779127.166015625\n",
      "Elbo loss: 11772117.734375\n",
      "Elbo loss: 11767533.673828125\n",
      "Elbo loss: 11775437.494140625\n",
      "Elbo loss: 11745992.875\n",
      "Elbo loss: 11768591.358398438\n",
      "Elbo loss: 11722052.244140625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11992020.8125,\n",
       " 12008567.4375,\n",
       " 12019911.5,\n",
       " 12021809.34375,\n",
       " 12042411.921875,\n",
       " 12043122.7890625,\n",
       " 12019932.7890625,\n",
       " 12022563.4765625,\n",
       " 12047215.4375,\n",
       " 12036885.328125,\n",
       " 12044234.3125,\n",
       " 12045118.453125,\n",
       " 12025997.5078125,\n",
       " 12062301.4296875,\n",
       " 12042643.2578125,\n",
       " 12005705.15625,\n",
       " 12015076.265625,\n",
       " 12016554.7734375,\n",
       " 12018766.203125,\n",
       " 12001827.21875,\n",
       " 11983409.609375,\n",
       " 12008835.546875,\n",
       " 12002125.0625,\n",
       " 12003066.84375,\n",
       " 11996001.84375,\n",
       " 11994370.296875,\n",
       " 12012471.53125,\n",
       " 12007147.046875,\n",
       " 11998281.1640625,\n",
       " 11991081.0,\n",
       " 11980527.859375,\n",
       " 11990359.2734375,\n",
       " 11991332.7734375,\n",
       " 11987789.7890625,\n",
       " 11989869.546875,\n",
       " 12001762.6015625,\n",
       " 11994243.28125,\n",
       " 11997264.1953125,\n",
       " 11981955.1875,\n",
       " 11967238.015625,\n",
       " 11985525.8125,\n",
       " 11970913.109375,\n",
       " 11988881.0546875,\n",
       " 11961965.5625,\n",
       " 11947875.8125,\n",
       " 11958736.6015625,\n",
       " 11962320.9921875,\n",
       " 11963257.1484375,\n",
       " 11965998.734375,\n",
       " 11948119.3203125,\n",
       " 11964293.296875,\n",
       " 11950115.4453125,\n",
       " 11963924.0625,\n",
       " 11937081.0390625,\n",
       " 11946569.828125,\n",
       " 11947193.4296875,\n",
       " 11926436.609375,\n",
       " 11945737.4765625,\n",
       " 11943234.859375,\n",
       " 11955539.8125,\n",
       " 11938020.515625,\n",
       " 11956467.2421875,\n",
       " 11949737.65625,\n",
       " 11952201.3046875,\n",
       " 11945344.859375,\n",
       " 11931302.828125,\n",
       " 11923444.15625,\n",
       " 11924238.765625,\n",
       " 11911266.0546875,\n",
       " 11929008.6875,\n",
       " 11923634.890625,\n",
       " 11940401.65625,\n",
       " 11942658.140625,\n",
       " 11915429.25,\n",
       " 11915356.34375,\n",
       " 11918590.734375,\n",
       " 11903138.5,\n",
       " 11911096.046875,\n",
       " 11918180.96875,\n",
       " 11922700.9375,\n",
       " 11889246.625,\n",
       " 11915250.6015625,\n",
       " 11911316.5859375,\n",
       " 11897160.921875,\n",
       " 11940227.328125,\n",
       " 11892693.1640625,\n",
       " 11897965.90625,\n",
       " 11889338.546875,\n",
       " 11924493.8671875,\n",
       " 11908952.2890625,\n",
       " 11873478.9140625,\n",
       " 11922079.3125,\n",
       " 11908870.296875,\n",
       " 11900487.3671875,\n",
       " 11901596.9921875,\n",
       " 11896568.0,\n",
       " 11903292.8359375,\n",
       " 11885811.96875,\n",
       " 11892950.109375,\n",
       " 11887943.234375,\n",
       " 11884241.9765625,\n",
       " 11885026.4296875,\n",
       " 11898941.1328125,\n",
       " 11901569.953125,\n",
       " 11879112.21875,\n",
       " 11923606.0625,\n",
       " 11881870.0234375,\n",
       " 11875556.65234375,\n",
       " 11881636.390625,\n",
       " 11874153.95703125,\n",
       " 11905652.8515625,\n",
       " 11869523.06640625,\n",
       " 11901131.26171875,\n",
       " 11877849.52734375,\n",
       " 11875152.19140625,\n",
       " 11843719.6328125,\n",
       " 11857079.3828125,\n",
       " 11864369.7890625,\n",
       " 11874323.23046875,\n",
       " 11901579.828125,\n",
       " 11870566.46875,\n",
       " 11863082.77734375,\n",
       " 11874869.94921875,\n",
       " 11857985.328125,\n",
       " 11856991.4609375,\n",
       " 11848579.30859375,\n",
       " 11858620.87109375,\n",
       " 11874907.06640625,\n",
       " 11893410.19921875,\n",
       " 11840575.26171875,\n",
       " 11875177.05859375,\n",
       " 11829983.89453125,\n",
       " 11856314.98046875,\n",
       " 11856594.6171875,\n",
       " 11848974.78515625,\n",
       " 11838784.37890625,\n",
       " 11837224.6015625,\n",
       " 11855673.6640625,\n",
       " 11849819.046875,\n",
       " 11858742.7578125,\n",
       " 11843510.703125,\n",
       " 11867946.9140625,\n",
       " 11841520.88671875,\n",
       " 11824018.22265625,\n",
       " 11851026.26171875,\n",
       " 11820416.38671875,\n",
       " 11821985.609375,\n",
       " 11838684.078125,\n",
       " 11865430.7578125,\n",
       " 11845159.8359375,\n",
       " 11835140.0234375,\n",
       " 11841962.984375,\n",
       " 11837634.05859375,\n",
       " 11847266.03515625,\n",
       " 11829645.27734375,\n",
       " 11820940.5859375,\n",
       " 11807347.3359375,\n",
       " 11842290.09375,\n",
       " 11824883.12890625,\n",
       " 11836458.87109375,\n",
       " 11831297.0078125,\n",
       " 11814063.45703125,\n",
       " 11833282.1328125,\n",
       " 11803942.30078125,\n",
       " 11808203.14453125,\n",
       " 11802759.5,\n",
       " 11796536.59375,\n",
       " 11819825.015625,\n",
       " 11820687.609375,\n",
       " 11815613.60546875,\n",
       " 11780705.17578125,\n",
       " 11809203.6171875,\n",
       " 11819584.02734375,\n",
       " 11840459.2421875,\n",
       " 11793483.98828125,\n",
       " 11809633.36328125,\n",
       " 11795356.203125,\n",
       " 11785850.90625,\n",
       " 11827734.3671875,\n",
       " 11808774.1875,\n",
       " 11779127.166015625,\n",
       " 11774855.548828125,\n",
       " 11792791.57421875,\n",
       " 11801864.9375,\n",
       " 11772265.81640625,\n",
       " 11784901.951171875,\n",
       " 11805954.962890625,\n",
       " 11804029.796875,\n",
       " 11787197.33984375,\n",
       " 11777977.8359375,\n",
       " 11772117.734375,\n",
       " 11779540.271484375,\n",
       " 11782346.220703125,\n",
       " 11756016.666015625,\n",
       " 11790533.900390625,\n",
       " 11796823.126953125,\n",
       " 11778889.49609375,\n",
       " 11771521.94921875,\n",
       " 11788985.41796875,\n",
       " 11773902.529296875,\n",
       " 11767533.673828125,\n",
       " 11757288.94140625,\n",
       " 11762768.09765625,\n",
       " 11772899.6796875,\n",
       " 11768783.4296875,\n",
       " 11787272.201171875,\n",
       " 11762960.396484375,\n",
       " 11766030.076171875,\n",
       " 11766698.09765625,\n",
       " 11752519.025390625,\n",
       " 11775437.494140625,\n",
       " 11758317.185546875,\n",
       " 11767265.349609375,\n",
       " 11753831.1875,\n",
       " 11764111.732421875,\n",
       " 11762423.072265625,\n",
       " 11765305.611328125,\n",
       " 11749946.587890625,\n",
       " 11747052.00390625,\n",
       " 11754987.711914062,\n",
       " 11745992.875,\n",
       " 11755089.869140625,\n",
       " 11746511.03125,\n",
       " 11733897.047851562,\n",
       " 11735161.080078125,\n",
       " 11738589.774414062,\n",
       " 11740649.83984375,\n",
       " 11765714.741210938,\n",
       " 11732318.591796875,\n",
       " 11746699.301757812,\n",
       " 11768591.358398438,\n",
       " 11738060.9609375,\n",
       " 11761300.767089844,\n",
       " 11730536.977539062,\n",
       " 11753709.979492188,\n",
       " 11733195.641601562,\n",
       " 11737340.454589844,\n",
       " 11730521.302978516,\n",
       " 11732678.458007812,\n",
       " 11736902.407226562,\n",
       " 11722052.244140625,\n",
       " 11710706.178955078,\n",
       " 11734075.722167969,\n",
       " 11727573.184814453,\n",
       " 11735253.591796875,\n",
       " 11709676.640625,\n",
       " 11711628.438110352,\n",
       " 11734225.37435913,\n",
       " 11716280.788696289,\n",
       " 11727288.416870117]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PMF(train=data, dim=100)\n",
    "test.train_SVI(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[ 6.  1.  1. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  4.  0.]\n",
      "  ...\n",
      "  [ 8.  1.  0. ... 13.  5.  0.]\n",
      "  [ 2.  0.  0. ...  1. 11.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 2.  0.  0. ...  1.  0.  4.]\n",
      "  [ 1.  0.  0. ...  0.  2.  1.]\n",
      "  [ 0.  0.  0. ...  0. 10.  0.]\n",
      "  ...\n",
      "  [10.  0.  0. ...  8.  6.  0.]\n",
      "  [ 3.  0.  0. ...  1. 22.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  1. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0.  2.  2.]\n",
      "  ...\n",
      "  [ 5.  0.  0. ... 11. 17.  0.]\n",
      "  [ 1.  0.  0. ...  2. 18.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.  1.  2. ...  1.  2.  1.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 5.  0.  0. ...  6.  8.  0.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ... 12. 13.  0.]\n",
      "  [ 1.  0.  0. ...  2. 16.  0.]\n",
      "  [ 0.  0.  1. ...  1.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  0.  3.  0.]\n",
      "  [ 2.  0.  0. ...  1.  3.  1.]\n",
      "  [ 1.  0.  1. ...  1.  6.  2.]\n",
      "  ...\n",
      "  [10.  0.  0. ...  8.  4.  0.]\n",
      "  [ 3.  0.  0. ...  1. 15.  2.]\n",
      "  [ 1.  0.  0. ...  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  1.  2.]\n",
      "  [ 0.  0.  0. ...  1.  1.  0.]\n",
      "  [ 0.  0.  0. ...  2. 13.  0.]\n",
      "  ...\n",
      "  [10.  0.  2. ... 13.  4.  0.]\n",
      "  [ 4.  0.  0. ...  3. 10.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.32909\n",
      "AUC: 0.83589\n",
      "(array([[[ 6.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  4.,  0.],\n",
      "        ...,\n",
      "        [ 8.,  1.,  0., ..., 13.,  5.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  1., 11.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 2.,  0.,  0., ...,  1.,  0.,  4.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  2.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0., 10.,  0.],\n",
      "        ...,\n",
      "        [10.,  0.,  0., ...,  8.,  6.,  0.],\n",
      "        [ 3.,  0.,  0., ...,  1., 22.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  2.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  0.,  2.,  2.],\n",
      "        ...,\n",
      "        [ 5.,  0.,  0., ..., 11., 17.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  2., 18.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 5.,  1.,  2., ...,  1.,  2.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "        [ 5.,  0.,  0., ...,  6.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 7.,  0.,  0., ..., 12., 13.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  2., 16.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  1.,  0.,  0.]],\n",
      "\n",
      "       [[ 1.,  0.,  0., ...,  0.,  3.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  1.,  3.,  1.],\n",
      "        [ 1.,  0.,  1., ...,  1.,  6.,  2.],\n",
      "        ...,\n",
      "        [10.,  0.,  0., ...,  8.,  4.,  0.],\n",
      "        [ 3.,  0.,  0., ...,  1., 15.,  2.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  1.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  1.,  2.],\n",
      "        [ 0.,  0.,  0., ...,  1.,  1.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  2., 13.,  0.],\n",
      "        ...,\n",
      "        [10.,  0.,  2., ..., 13.,  4.,  0.],\n",
      "        [ 4.,  0.,  0., ...,  3., 10.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
