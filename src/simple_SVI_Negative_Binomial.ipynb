{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self,data, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = data.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "        self.a = 50\n",
    "        self.predictive_svi = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "        a = 50\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.NegativeBinomial(a, UA@VA.T/( UA@VA.T+a) ), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=250, lr = 0.05, lrd = 1, verbose=True):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if(verbose):\n",
    "                if step % 10 == 0:\n",
    "                    print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        self.predictive_svi = predictive_svi\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "\n",
    "    def predictive_score(self,test,masked):\n",
    "        # total = test.shape[0]*test.shape[1]\n",
    "        \n",
    "        UA =  self.predictive_svi[\"UA\"]\n",
    "        VA = self.predictive_svi[\"VA\"]\n",
    "        VA = VA.mean(axis=0).reshape(self.m,self.dim)\n",
    "        UA = UA.mean(axis=0).reshape(self.n,self.dim)\n",
    "        print(UA.shape)\n",
    "        score = dist.NegativeBinomial(self.a, UA@VA.T/( UA@VA.T+self.a)).log_prob(torch.from_numpy(test))\n",
    "        mean_score = (score*masked).reshape(-1).logsumexp(-1) -np.log(test.shape[0]*test.shape[1])\n",
    "        return mean_score\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    \n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "UA: (500, 1, 1127, 1)\n",
      "VA: (500, 1, 5237, 1)\n",
      "target: (500, 1127, 5237)\n",
      "[[[  1.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  8.   0.   2. ...   2.  23.   2.]\n",
      "  ...\n",
      "  [  1.   0.   0. ...   1.   8.   2.]\n",
      "  [  1.   1.   4. ...   5.  29.   5.]\n",
      "  [  4.   0.   1. ...   1.  10.   3.]]\n",
      "\n",
      " [[  6.   0.   0. ...   1.   2.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  ...\n",
      "  [ 54.   0.   1. ...  33. 121.  20.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  7.   0.   0. ...   1.  13.   3.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  2.   1.   0. ...   2.  14.   0.]\n",
      "  [  7.   0.   0. ...   7.  14.   1.]\n",
      "  ...\n",
      "  [ 20.   0.   1. ...  16.  35.   0.]\n",
      "  [  2.   0.   0. ...   2.  15.   0.]\n",
      "  [  1.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   0.   3.   1.]\n",
      "  [ 38.   1.   3. ...  13.  37.  10.]\n",
      "  ...\n",
      "  [  1.   0.   0. ...   0.   0.   0.]\n",
      "  [  7.   0.   1. ...   4.  12.   1.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  2.   0.   0. ...   1.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  8.   0.   0. ...   1.   5.   2.]\n",
      "  ...\n",
      "  [ 27.   2.   0. ...   9.  30.   4.]\n",
      "  [  0.   0.   0. ...   2.   1.   1.]\n",
      "  [  0.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   1.   3.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   1.   1.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   0.   8.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]]\n",
      "torch.Size([1127, 1])\n",
      "UA: (500, 1, 1127, 5)\n",
      "VA: (500, 1, 5237, 5)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 2.  0.  0. ...  6. 10.  2.]\n",
      "  [ 3.  0.  0. ...  1.  8.  0.]\n",
      "  [ 2.  0.  0. ...  2.  5.  7.]\n",
      "  ...\n",
      "  [11.  1.  1. ... 13. 96.  0.]\n",
      "  [ 1.  2.  0. ...  4. 14.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  1.  1.  0.]\n",
      "  [ 1.  0.  0. ...  0.  6.  0.]\n",
      "  [ 8.  1.  0. ...  8. 16.  1.]\n",
      "  ...\n",
      "  [12.  0.  0. ...  1. 14.  0.]\n",
      "  [ 3.  0.  0. ...  1. 10.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 3.  0.  0. ...  3.  6.  0.]\n",
      "  [ 0.  0.  0. ...  1.  3.  0.]\n",
      "  [ 2.  0.  0. ...  4.  3.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  3. 10.  0.]\n",
      "  [19.  0.  0. ... 43. 36.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  2.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 5.  2.  0. ...  6.  3.  6.]\n",
      "  ...\n",
      "  [18.  1.  0. ... 13. 52.  0.]\n",
      "  [ 9.  0.  0. ...  5. 42.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  0.  1.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  1.  0. ...  2.  6.  0.]\n",
      "  ...\n",
      "  [13.  0.  0. ...  4. 46.  0.]\n",
      "  [14.  0.  0. ...  3. 31.  2.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]]\n",
      "\n",
      " [[ 0.  3.  0. ...  0.  5.  6.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  4.  0. ...  0. 28. 14.]\n",
      "  ...\n",
      "  [ 8.  1.  1. ...  1. 24. 14.]\n",
      "  [ 4.  0.  0. ...  2. 18.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]]]\n",
      "torch.Size([1127, 5])\n",
      "UA: (500, 1, 1127, 10)\n",
      "VA: (500, 1, 5237, 10)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 3.  0.  1. ...  3.  7.  2.]\n",
      "  [ 1.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  2.  1.  0.]\n",
      "  ...\n",
      "  [21.  0.  0. ...  8. 79.  3.]\n",
      "  [ 3.  0.  0. ...  5.  6.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  5.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  1. ...  1.  2.  1.]\n",
      "  ...\n",
      "  [13.  0.  2. ... 13. 95.  0.]\n",
      "  [ 3.  0.  1. ...  0.  4.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  3.  3.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [14.  0.  2. ...  3. 24.  1.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  1.  8.  0.]\n",
      "  [11.  0.  0. ... 10. 21.  0.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.  1.  0. ... 11.  9.  3.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 3.  0.  0. ...  0.  3.  2.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ...  5. 29.  0.]\n",
      "  [ 9.  0.  0. ...  3.  7.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 5.  1.  0. ...  0. 19.  5.]\n",
      "  [ 0.  0.  0. ...  0.  1.  1.]\n",
      "  [ 4.  0.  0. ...  4.  7.  0.]\n",
      "  ...\n",
      "  [23.  1.  1. ... 16. 90.  0.]\n",
      "  [ 5.  1.  0. ...  2.  3.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 3.  0.  0. ...  1.  1.  0.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 2.  0.  0. ...  3.  8.  0.]\n",
      "  ...\n",
      "  [26.  0.  0. ...  4. 33.  0.]\n",
      "  [ 1.  1.  0. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 10])\n",
      "UA: (500, 1, 1127, 20)\n",
      "VA: (500, 1, 5237, 20)\n",
      "target: (500, 1127, 5237)\n",
      "[[[  0.   0.   0. ...   0.   1.   2.]\n",
      "  [  0.   0.   0. ...   1.   0.   0.]\n",
      "  [  1.   0.   1. ...   1.   8.   0.]\n",
      "  ...\n",
      "  [ 17.   0.   0. ...   5. 202.   0.]\n",
      "  [ 34.   0.   0. ...   3.  88.   0.]\n",
      "  [  0.   0.   0. ...   1.   2.   0.]]\n",
      "\n",
      " [[  4.   0.   0. ...   0.   3.   0.]\n",
      "  [  2.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   0.   4.   0.]\n",
      "  ...\n",
      "  [ 17.   0.   0. ...   4.  28.   0.]\n",
      "  [  5.   0.   0. ...   2.   5.   1.]\n",
      "  [  0.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " [[  1.   0.   0. ...   1.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  2.   0.   2. ...   2.   4.   0.]\n",
      "  ...\n",
      "  [  3.   1.   1. ...   9.  49.   1.]\n",
      "  [  3.   0.   0. ...   3.  12.   1.]\n",
      "  [  0.   0.   1. ...   0.   1.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  1.   0.   0. ...   5.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  2.   2.   0. ...   4.   5.   0.]\n",
      "  ...\n",
      "  [ 11.   0.   0. ...   7. 197.   0.]\n",
      "  [  5.   0.   0. ...   3.  30.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  3.   0.   1. ...   4.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  7.   1.   1. ...   4.   9.   0.]\n",
      "  ...\n",
      "  [  4.   0.   2. ...   3.  18.   0.]\n",
      "  [  1.   0.   0. ...   0.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " [[  2.   0.   0. ...   3.   1.   0.]\n",
      "  [  0.   0.   0. ...   2.   1.   3.]\n",
      "  [  1.   0.   0. ...   0.   2.   0.]\n",
      "  ...\n",
      "  [  4.   0.   0. ...   5.  35.   0.]\n",
      "  [  7.   0.   0. ...   4.   5.   1.]\n",
      "  [  0.   0.   0. ...   1.   1.   0.]]]\n",
      "torch.Size([1127, 20])\n",
      "UA: (500, 1, 1127, 50)\n",
      "VA: (500, 1, 5237, 50)\n",
      "target: (500, 1127, 5237)\n",
      "[[[  0.   0.   0. ...   2.   3.  10.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   1. ...   4.   5.   0.]\n",
      "  ...\n",
      "  [  8.   0.   0. ...  12.  19.   2.]\n",
      "  [ 15.   0.   0. ...   2.  18.   1.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   3.   4.   0.]\n",
      "  ...\n",
      "  [  8.   0.   0. ...  14.   8.   1.]\n",
      "  [  3.   0.   0. ...   2.  15.   0.]\n",
      "  [  2.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " [[  1.   1.   0. ...   1.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   2.   1.]\n",
      "  [  2.   0.   0. ...   0.   3.   0.]\n",
      "  ...\n",
      "  [ 23.   0.   0. ...   7.  46.   1.]\n",
      "  [  8.   0.   0. ...   4.   5.   1.]\n",
      "  [  0.   0.   0. ...   0.   2.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  6.   0.   1. ...   4.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   2.   0.]\n",
      "  [  0.   0.   0. ...   5.   0.   2.]\n",
      "  ...\n",
      "  [ 18.   0.   0. ...  18.   2.   0.]\n",
      "  [  1.   0.   0. ...   1.  21.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  1.   0.   0. ...   0.   0.   3.]\n",
      "  [  1.   0.   0. ...   0.   0.   0.]\n",
      "  [  2.   0.   0. ...   0.   3.   0.]\n",
      "  ...\n",
      "  [ 19.   0.   1. ...   7. 119.   0.]\n",
      "  [  6.   0.   0. ...   3.  11.   5.]\n",
      "  [  0.   0.   0. ...   1.   0.   1.]]\n",
      "\n",
      " [[  2.   0.   0. ...   1.   7.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   4.   3.   0.]\n",
      "  ...\n",
      "  [ 11.   0.   0. ...   8.  31.   0.]\n",
      "  [  7.   0.   0. ...   3.   9.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]]\n",
      "torch.Size([1127, 50])\n",
      "UA: (500, 1, 1127, 75)\n",
      "VA: (500, 1, 5237, 75)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 3.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  1.  2.  0.]\n",
      "  [ 2.  0.  0. ...  0.  6.  0.]\n",
      "  ...\n",
      "  [ 9.  0.  0. ...  6. 47.  0.]\n",
      "  [ 7.  0.  0. ...  9. 17.  1.]\n",
      "  [ 0.  0.  0. ...  0.  5.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  6.  3.  1.]\n",
      "  ...\n",
      "  [26.  0.  0. ... 47. 11.  0.]\n",
      "  [ 9.  0.  0. ...  8. 14.  0.]\n",
      "  [ 1.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 1.  0.  0. ...  1.  0.  1.]\n",
      "  [ 0.  1.  1. ...  7.  2.  0.]\n",
      "  ...\n",
      "  [ 1.  0.  0. ...  2. 16.  1.]\n",
      "  [10.  0.  0. ...  3. 17.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]\n",
      "  ...\n",
      "  [ 5.  0.  0. ... 12. 16.  0.]\n",
      "  [18.  0.  0. ...  7. 29.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  2.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  2.  0.]\n",
      "  [ 1.  0.  0. ...  0.  1.  0.]\n",
      "  ...\n",
      "  [ 4.  0.  0. ...  7. 32.  0.]\n",
      "  [ 4.  0.  0. ...  0. 36.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 2.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  1.  2.  0.]\n",
      "  [ 0.  0.  0. ...  2.  2.  0.]\n",
      "  ...\n",
      "  [ 2.  0.  0. ...  6. 21.  0.]\n",
      "  [ 5.  0.  0. ...  8. 20.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 75])\n",
      "UA: (500, 1, 1127, 100)\n",
      "VA: (500, 1, 5237, 100)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 3.  0.  0. ...  1.  7.  0.]\n",
      "  [ 0.  0.  0. ...  1.  1.  0.]\n",
      "  [ 2.  0.  0. ...  5.  2.  0.]\n",
      "  ...\n",
      "  [13.  1.  0. ... 18. 11.  1.]\n",
      "  [ 3.  0.  1. ...  3. 11.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  1. ...  0. 14.  0.]\n",
      "  [ 1.  0.  0. ...  3.  1.  0.]\n",
      "  [ 1.  0.  0. ...  3.  4.  1.]\n",
      "  ...\n",
      "  [14.  0.  1. ... 18. 21.  0.]\n",
      "  [ 2.  0.  1. ...  1. 24.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 1.  1.  0. ...  0. 12.  0.]\n",
      "  [ 2.  0.  0. ...  1.  1.  0.]\n",
      "  [ 0.  1.  0. ...  5.  7.  1.]\n",
      "  ...\n",
      "  [44.  2.  1. ...  2. 15.  1.]\n",
      "  [ 0.  0.  0. ...  2.  7.  0.]\n",
      "  [ 3.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  0.  0. ...  1. 45.  0.]\n",
      "  [ 1.  0.  0. ...  0.  2.  0.]\n",
      "  [ 2.  0.  0. ... 10.  2.  1.]\n",
      "  ...\n",
      "  [ 4.  0.  1. ... 28. 22.  1.]\n",
      "  [ 6.  0.  0. ...  5. 15.  0.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  1.  1.  0.]\n",
      "  [ 0.  0.  2. ...  4.  3.  0.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ...  1. 18.  0.]\n",
      "  [ 6.  0.  1. ...  2.  9.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  3.  0.  2.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3.  2.  0.]\n",
      "  ...\n",
      "  [35.  0.  0. ... 16. 20.  0.]\n",
      "  [ 3.  0.  0. ...  1. 28.  1.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]]]\n",
      "torch.Size([1127, 100])\n",
      "UA: (500, 1, 1127, 200)\n",
      "VA: (500, 1, 5237, 200)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  3.  3.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 4.  0.  0. ...  4.  7.  0.]\n",
      "  ...\n",
      "  [19.  0.  2. ...  7. 27.  3.]\n",
      "  [ 5.  1.  0. ...  1. 17.  0.]\n",
      "  [ 0.  0.  0. ...  1.  4.  1.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  1.  2.  0.]\n",
      "  [ 1.  0.  1. ...  1.  2.  0.]\n",
      "  [ 2.  0.  0. ... 12.  5.  3.]\n",
      "  ...\n",
      "  [12.  0.  3. ... 10. 24.  0.]\n",
      "  [ 5.  0.  0. ...  4. 26.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  4.  2.  0.]\n",
      "  [ 0.  0.  0. ...  1.  2.  0.]\n",
      "  [ 1.  2.  0. ...  8. 11.  0.]\n",
      "  ...\n",
      "  [14.  1.  3. ... 17. 23.  3.]\n",
      "  [ 4.  0.  0. ...  2. 34.  0.]\n",
      "  [ 1.  0.  0. ...  0.  1.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  4.  1.  1.]\n",
      "  [ 1.  0.  0. ...  2.  5.  0.]\n",
      "  ...\n",
      "  [11.  1.  3. ...  9. 28.  0.]\n",
      "  [ 0.  1.  2. ...  3.  9.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 3.  1.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  1.  4.  0.]\n",
      "  [ 0.  0.  0. ...  4.  2.  0.]\n",
      "  ...\n",
      "  [10.  0.  0. ...  1. 33.  0.]\n",
      "  [ 3.  0.  0. ...  1. 16.  0.]\n",
      "  [ 2.  0.  0. ...  2.  2.  0.]]\n",
      "\n",
      " [[ 4.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 1.  0.  0. ...  2.  7.  0.]\n",
      "  ...\n",
      "  [ 4.  0.  0. ... 10. 71.  1.]\n",
      "  [ 7.  0.  0. ...  4. 26.  1.]\n",
      "  [ 1.  0.  0. ...  0.  1.  0.]]]\n",
      "torch.Size([1127, 200])\n",
      "UA: (500, 1, 1127, 250)\n",
      "VA: (500, 1, 5237, 250)\n",
      "target: (500, 1127, 5237)\n",
      "[[[  2.   0.   0. ...   1.   5.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   4.   2.   0.]\n",
      "  ...\n",
      "  [ 11.   0.   2. ...   9.  20.   0.]\n",
      "  [  3.   0.   1. ...   3.  12.   0.]\n",
      "  [  0.   0.   0. ...   2.   0.   0.]]\n",
      "\n",
      " [[  5.   2.   0. ...   0.   1.   1.]\n",
      "  [  1.   0.   0. ...   2.   0.   0.]\n",
      "  [  1.   0.   0. ...   3.   2.   0.]\n",
      "  ...\n",
      "  [  4.   2.   0. ...   9.   5.   0.]\n",
      "  [  0.   0.   0. ...   4.   2.   0.]\n",
      "  [  2.   0.   0. ...   3.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   1.   0.]\n",
      "  [  1.   0.   0. ...   1.   2.   0.]\n",
      "  [  0.   0.   0. ...   3.   3.   0.]\n",
      "  ...\n",
      "  [  9.   1.   0. ...  11.  19.   0.]\n",
      "  [  1.   0.   0. ...   4.  85.   0.]\n",
      "  [  1.   1.   0. ...   2.   5.   1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  6.   1.   0. ...   0.   3.   0.]\n",
      "  [  0.   0.   0. ...   1.   3.   1.]\n",
      "  [  2.   0.   0. ...   3.   5.   0.]\n",
      "  ...\n",
      "  [ 13.   0.   0. ...  13.  14.   0.]\n",
      "  [  1.   0.   0. ...   1.  16.   0.]\n",
      "  [  0.   0.   0. ...   0.   2.   0.]]\n",
      "\n",
      " [[  4.   2.   2. ...   3.   4.   0.]\n",
      "  [  0.   0.   0. ...   0.   1.   1.]\n",
      "  [  1.   2.   0. ...   1.   1.   1.]\n",
      "  ...\n",
      "  [  9.   0.   0. ...  10.  13.   1.]\n",
      "  [  3.   0.   1. ...   5.  14.   1.]\n",
      "  [  1.   0.   0. ...   1.   0.   1.]]\n",
      "\n",
      " [[  4.   1.   2. ...  10.   3.   0.]\n",
      "  [  2.   1.   0. ...   1.   4.   0.]\n",
      "  [  1.   0.   0. ...   2.  15.   0.]\n",
      "  ...\n",
      "  [  8.   2.   1. ...   9.  25.   1.]\n",
      "  [  4.   0.   0. ...   2. 151.   1.]\n",
      "  [  0.   0.   0. ...   1.   0.   0.]]]\n",
      "torch.Size([1127, 250])\n"
     ]
    }
   ],
   "source": [
    "with open('data_train.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)\n",
    "print(data2.shape)\n",
    "\n",
    "def predictive_score_for_diim_estimation(data_all, train, classname):\n",
    "    score=[]\n",
    "    for d in [1,5,10,20,50,75,100,200,250]:\n",
    "        nan_mask = np.isnan(train) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "        test = classname(data_all,train, d)  \n",
    "        pyro.clear_param_store()\n",
    "        test.train_SVI(data_all , ~torch.from_numpy(nan_mask), verbose = False)\n",
    "        test.sample_predict(500)\n",
    "        score.append(test.predictive_score(data_all,  ~torch.from_numpy(nan_mask)))\n",
    "    return score\n",
    "\n",
    "s = predictive_score_for_diim_estimation(data,data2, PMF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = [1,5,10,20,50,75,100,200,250]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d, s)\n",
    "plt.title(\"Value of the Log Predictive For different #dimensions\")\n",
    "plt.savefig(\"predictive_score_NB.png\")\n",
    "plt.show()\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 9055118.078125\n",
      "Elbo loss: 9098882.40625\n",
      "Elbo loss: 9098319.78125\n",
      "Elbo loss: 8944937.421875\n",
      "Elbo loss: 8960036.609375\n",
      "Elbo loss: 8975340.296875\n",
      "Elbo loss: 8975446.015625\n",
      "Elbo loss: 8960144.546875\n",
      "Elbo loss: 8974696.4921875\n",
      "Elbo loss: 8968002.8671875\n",
      "Elbo loss: 8966022.4765625\n",
      "Elbo loss: 8903937.1484375\n",
      "Elbo loss: 8957122.9453125\n",
      "Elbo loss: 8926410.2265625\n",
      "Elbo loss: 8925323.78125\n",
      "Elbo loss: 9011655.4296875\n",
      "Elbo loss: 8939463.015625\n",
      "Elbo loss: 8934858.796875\n",
      "Elbo loss: 8910493.421875\n",
      "Elbo loss: 8971726.765625\n",
      "Elbo loss: 8934409.6484375\n",
      "Elbo loss: 8939027.8984375\n",
      "Elbo loss: 8913324.953125\n",
      "Elbo loss: 8867438.7578125\n",
      "Elbo loss: 8900528.0390625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9055118.078125,\n",
       " 9083290.515625,\n",
       " 9042242.46875,\n",
       " 9069657.359375,\n",
       " 9041994.7109375,\n",
       " 9152475.5234375,\n",
       " 9091170.0546875,\n",
       " 9057834.6640625,\n",
       " 9054962.546875,\n",
       " 9086004.734375,\n",
       " 9098882.40625,\n",
       " 9074073.7109375,\n",
       " 9104094.953125,\n",
       " 9075988.625,\n",
       " 9122053.78125,\n",
       " 9036397.59375,\n",
       " 9031093.109375,\n",
       " 9022227.2265625,\n",
       " 9049068.015625,\n",
       " 8996837.90625,\n",
       " 9098319.78125,\n",
       " 9060713.2734375,\n",
       " 9057273.359375,\n",
       " 9011294.296875,\n",
       " 9001157.75,\n",
       " 9026720.7421875,\n",
       " 9007314.875,\n",
       " 9022993.0859375,\n",
       " 9015175.3515625,\n",
       " 9013876.984375,\n",
       " 8944937.421875,\n",
       " 9014812.75,\n",
       " 8955290.6953125,\n",
       " 9037072.84375,\n",
       " 8952280.265625,\n",
       " 8989081.21875,\n",
       " 9036661.109375,\n",
       " 9033199.5546875,\n",
       " 9005478.7421875,\n",
       " 9010961.1328125,\n",
       " 8960036.609375,\n",
       " 8925865.4921875,\n",
       " 8939705.34375,\n",
       " 8965799.1328125,\n",
       " 8971165.4140625,\n",
       " 9038159.875,\n",
       " 8981584.1640625,\n",
       " 9000537.8046875,\n",
       " 8974634.4140625,\n",
       " 8936924.3984375,\n",
       " 8975340.296875,\n",
       " 8986144.875,\n",
       " 9002850.53125,\n",
       " 8986332.9375,\n",
       " 8928115.234375,\n",
       " 8966553.3515625,\n",
       " 8958798.046875,\n",
       " 9011376.640625,\n",
       " 8944591.359375,\n",
       " 8972089.6015625,\n",
       " 8975446.015625,\n",
       " 9010541.59375,\n",
       " 8981922.5078125,\n",
       " 9028892.46875,\n",
       " 9023908.03125,\n",
       " 9008879.78125,\n",
       " 8987051.9375,\n",
       " 8961911.4609375,\n",
       " 8966441.5234375,\n",
       " 8986759.0078125,\n",
       " 8960144.546875,\n",
       " 8967889.6328125,\n",
       " 8947887.359375,\n",
       " 8899214.109375,\n",
       " 8924851.6171875,\n",
       " 8977926.8984375,\n",
       " 8960852.0625,\n",
       " 9016562.25,\n",
       " 8919710.703125,\n",
       " 9001830.5703125,\n",
       " 8974696.4921875,\n",
       " 8945111.140625,\n",
       " 9063095.796875,\n",
       " 8989195.140625,\n",
       " 8953804.8125,\n",
       " 8932457.8203125,\n",
       " 8959149.5390625,\n",
       " 8954712.703125,\n",
       " 8968868.40625,\n",
       " 8997955.1640625,\n",
       " 8968002.8671875,\n",
       " 8952237.8046875,\n",
       " 8948022.8984375,\n",
       " 9044238.765625,\n",
       " 8988614.15625,\n",
       " 8966339.171875,\n",
       " 8967846.0234375,\n",
       " 8953342.875,\n",
       " 8973029.890625,\n",
       " 8947942.53125,\n",
       " 8966022.4765625,\n",
       " 8951190.0546875,\n",
       " 8969099.078125,\n",
       " 8987479.65625,\n",
       " 8951754.21875,\n",
       " 8946350.015625,\n",
       " 8895124.5,\n",
       " 8976008.546875,\n",
       " 8968268.1640625,\n",
       " 9005385.5703125,\n",
       " 8903937.1484375,\n",
       " 8949571.4140625,\n",
       " 8997880.015625,\n",
       " 9006382.6875,\n",
       " 8986943.875,\n",
       " 8939048.4296875,\n",
       " 8920583.140625,\n",
       " 8913572.9375,\n",
       " 8953582.546875,\n",
       " 8961985.890625,\n",
       " 8957122.9453125,\n",
       " 8999585.6875,\n",
       " 8946919.90625,\n",
       " 8961261.234375,\n",
       " 8903930.9609375,\n",
       " 8954921.453125,\n",
       " 8966686.4375,\n",
       " 8940362.9375,\n",
       " 8918895.1015625,\n",
       " 8872424.1171875,\n",
       " 8926410.2265625,\n",
       " 8960096.7421875,\n",
       " 8869693.2578125,\n",
       " 8981975.9921875,\n",
       " 8964643.1171875,\n",
       " 8959518.4921875,\n",
       " 8933207.859375,\n",
       " 8937020.0859375,\n",
       " 8921666.9375,\n",
       " 8961140.78125,\n",
       " 8925323.78125,\n",
       " 8982461.453125,\n",
       " 8920776.1484375,\n",
       " 8896121.3125,\n",
       " 9001981.28125,\n",
       " 9043126.0,\n",
       " 8972755.1796875,\n",
       " 8948422.203125,\n",
       " 8910307.6796875,\n",
       " 8978098.28125,\n",
       " 9011655.4296875,\n",
       " 8935949.9609375,\n",
       " 8911313.4765625,\n",
       " 8943678.0546875,\n",
       " 8961878.7265625,\n",
       " 8936273.859375,\n",
       " 8964013.359375,\n",
       " 8904952.171875,\n",
       " 8931890.1796875,\n",
       " 8887816.40625,\n",
       " 8939463.015625,\n",
       " 8872791.9765625,\n",
       " 8908578.859375,\n",
       " 8913925.0234375,\n",
       " 8934455.3984375,\n",
       " 8919641.5625,\n",
       " 8938911.2265625,\n",
       " 8890685.5234375,\n",
       " 8965892.546875,\n",
       " 8868852.03125,\n",
       " 8934858.796875,\n",
       " 8934824.421875,\n",
       " 8970743.078125,\n",
       " 8885348.8828125,\n",
       " 8978262.9609375,\n",
       " 8891446.6484375,\n",
       " 8912529.09375,\n",
       " 8952304.2265625,\n",
       " 8948708.796875,\n",
       " 8902809.609375,\n",
       " 8910493.421875,\n",
       " 8872897.671875,\n",
       " 8932190.21875,\n",
       " 8914316.2890625,\n",
       " 8889173.1875,\n",
       " 8876430.0234375,\n",
       " 8950471.7578125,\n",
       " 8927561.140625,\n",
       " 8907930.671875,\n",
       " 8944738.703125,\n",
       " 8971726.765625,\n",
       " 8860636.3671875,\n",
       " 8899679.90625,\n",
       " 8962958.9921875,\n",
       " 8920743.734375,\n",
       " 8870383.2265625,\n",
       " 8932103.90625,\n",
       " 8966640.6171875,\n",
       " 8927245.7578125,\n",
       " 8960161.890625,\n",
       " 8934409.6484375,\n",
       " 8893685.4921875,\n",
       " 8859479.9765625,\n",
       " 8906334.984375,\n",
       " 8870889.09375,\n",
       " 8933785.0390625,\n",
       " 8894406.5,\n",
       " 8914393.28125,\n",
       " 8892568.4609375,\n",
       " 8942881.9296875,\n",
       " 8939027.8984375,\n",
       " 8957792.1015625,\n",
       " 8980545.6328125,\n",
       " 8932605.1875,\n",
       " 8865418.3125,\n",
       " 8844004.953125,\n",
       " 8920704.1015625,\n",
       " 8896878.8515625,\n",
       " 8912897.4375,\n",
       " 8891131.3984375,\n",
       " 8913324.953125,\n",
       " 8856748.5625,\n",
       " 8900982.640625,\n",
       " 8907780.1484375,\n",
       " 8862914.5234375,\n",
       " 8883921.3125,\n",
       " 8933955.3984375,\n",
       " 8929207.09375,\n",
       " 8881723.390625,\n",
       " 8837300.9296875,\n",
       " 8867438.7578125,\n",
       " 8922394.1875,\n",
       " 8925858.1953125,\n",
       " 8888639.609375,\n",
       " 8898053.3515625,\n",
       " 8945459.2578125,\n",
       " 8872551.953125,\n",
       " 8894172.8984375,\n",
       " 8925043.4296875,\n",
       " 8838642.5625,\n",
       " 8900528.0390625,\n",
       " 8962504.6328125,\n",
       " 8880968.4609375,\n",
       " 8908248.515625,\n",
       " 8892288.9609375,\n",
       " 8939345.984375,\n",
       " 8927234.7734375,\n",
       " 8872351.84375,\n",
       " 8874168.7109375,\n",
       " 8800838.3203125]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PMF(train=data, dim=100)\n",
    "test.train_SVI(data, ~torch.from_numpy(nan_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[  0.   0.   0. ...   1.   4.   0.]\n",
      "  [  0.   0.   0. ...   1.   0.   0.]\n",
      "  [  0.   4.   0. ...   1.   9.   0.]\n",
      "  ...\n",
      "  [ 12.   0.   1. ... 105.  18.   1.]\n",
      "  [  4.   0.   0. ...   9.   9.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  2.   3.   0. ...   0.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   2.   0.]\n",
      "  [  0.   0.   0. ...   1.   5.   0.]\n",
      "  ...\n",
      "  [ 33.   1.   0. ...  66.   7.   1.]\n",
      "  [  0.   0.   0. ...   5.  16.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  1.   0.   0. ...   1.   2.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  1.   0.   0. ...   1.   3.   0.]\n",
      "  ...\n",
      "  [ 15.   0.   0. ...  48.   6.   0.]\n",
      "  [  5.   0.   0. ...   4.   8.   0.]\n",
      "  [  0.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  1.   0.   0. ...   1.   1.   1.]\n",
      "  [  0.   0.   0. ...   1.   0.   0.]\n",
      "  [  1.   0.   0. ...   3.   1.   0.]\n",
      "  ...\n",
      "  [ 24.   0.   0. ...  20.  20.   0.]\n",
      "  [  2.   0.   0. ...   6.   5.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  1.   1.   0. ...   0.   0.   1.]\n",
      "  [  0.   0.   0. ...   0.   2.   0.]\n",
      "  [  2.   1.   0. ...   5.   2.   1.]\n",
      "  ...\n",
      "  [  5.   0.   0. ...  45.  20.   3.]\n",
      "  [  5.   0.   0. ...   3.  25.   0.]\n",
      "  [  0.   0.   0. ...   0.   1.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   1.   0.]\n",
      "  [  0.   0.   0. ...   2.   0.   0.]\n",
      "  [  1.   0.   0. ...   6.   2.   0.]\n",
      "  ...\n",
      "  [  2.   0.   0. ...  33.  23.   1.]\n",
      "  [  0.   0.   0. ...   4.  11.   1.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.32548\n",
      "AUC: 0.84278\n",
      "(array([[[  0.,   0.,   0., ...,   1.,   4.,   0.],\n",
      "        [  0.,   0.,   0., ...,   1.,   0.,   0.],\n",
      "        [  0.,   4.,   0., ...,   1.,   9.,   0.],\n",
      "        ...,\n",
      "        [ 12.,   0.,   1., ..., 105.,  18.,   1.],\n",
      "        [  4.,   0.,   0., ...,   9.,   9.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  2.,   3.,   0., ...,   0.,   1.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   2.,   0.],\n",
      "        [  0.,   0.,   0., ...,   1.,   5.,   0.],\n",
      "        ...,\n",
      "        [ 33.,   1.,   0., ...,  66.,   7.,   1.],\n",
      "        [  0.,   0.,   0., ...,   5.,  16.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  1.,   0.,   0., ...,   1.,   2.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
      "        [  1.,   0.,   0., ...,   1.,   3.,   0.],\n",
      "        ...,\n",
      "        [ 15.,   0.,   0., ...,  48.,   6.,   0.],\n",
      "        [  5.,   0.,   0., ...,   4.,   8.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   1.,   0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  1.,   0.,   0., ...,   1.,   1.,   1.],\n",
      "        [  0.,   0.,   0., ...,   1.,   0.,   0.],\n",
      "        [  1.,   0.,   0., ...,   3.,   1.,   0.],\n",
      "        ...,\n",
      "        [ 24.,   0.,   0., ...,  20.,  20.,   0.],\n",
      "        [  2.,   0.,   0., ...,   6.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  1.,   1.,   0., ...,   0.,   0.,   1.],\n",
      "        [  0.,   0.,   0., ...,   0.,   2.,   0.],\n",
      "        [  2.,   1.,   0., ...,   5.,   2.,   1.],\n",
      "        ...,\n",
      "        [  5.,   0.,   0., ...,  45.,  20.,   3.],\n",
      "        [  5.,   0.,   0., ...,   3.,  25.,   0.],\n",
      "        [  0.,   0.,   0., ...,   0.,   1.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   0.,   1.,   0.],\n",
      "        [  0.,   0.,   0., ...,   2.,   0.,   0.],\n",
      "        [  1.,   0.,   0., ...,   6.,   2.,   0.],\n",
      "        ...,\n",
      "        [  2.,   0.,   0., ...,  33.,  23.,   1.],\n",
      "        [  0.,   0.,   0., ...,   4.,  11.,   1.],\n",
      "        [  0.,   0.,   0., ...,   0.,   0.,   0.]]], dtype=float32), array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
