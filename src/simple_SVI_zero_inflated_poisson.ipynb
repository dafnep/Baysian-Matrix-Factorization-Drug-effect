{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)\n",
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_zero_inflated_poisson(nn.Module):\n",
    "\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self,data, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = data.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "        self.predictive_svi = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "        \n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "        self.alpha = 1\n",
    "\n",
    "\n",
    "    def model(self, train, mask):\n",
    "        alpha = 1\n",
    "        beta = 1\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #alpha = pyro.sample(\"alpha\", dist.Poisson(self.alpha))\n",
    "            p = pyro.sample(\"p\", dist.Beta(alpha, beta))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "           # with pyro.poutine.mask(mask=mask):\n",
    "             Y = pyro.sample(\"target\", dist.ZeroInflatedPoisson( rate = UA@VA.T ,gate = p[:, np.newaxis]), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "        rate_alpha = pyro.param('rate_alpha', torch.ones(self.n), constraint=constraints.positive)\n",
    "        rate_beta = pyro.param('rate_beta', torch.ones(self.n), constraint=constraints.positive)\n",
    "\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            p = pyro.sample(\"p\", dist.Beta(rate_beta,rate_alpha))\n",
    "\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,mask, nsteps=250, lr = 0.05, lrd = 1, verbose=True):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float(), mask)\n",
    "            losses.append(elbo)\n",
    "            if(verbose):\n",
    "                if step % 10 == 0:\n",
    "                    print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        unmasked =torch.ones((self.n,self.m), dtype=torch.bool)\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None , unmasked)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        self.predictive_svi = predictive_svi\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    def predictive_score(self,test,masked):\n",
    "        # total = test.shape[0]*test.shape[1]\n",
    "        \n",
    "        UA =  self.predictive_svi[\"UA\"]\n",
    "        VA = self.predictive_svi[\"VA\"]\n",
    "        p=self.predictive_svi[\"p\"].mean(axis=0).reshape(self.n)\n",
    "        VA = VA.mean(axis=0).reshape(self.m,self.dim)\n",
    "        UA = UA.mean(axis=0).reshape(self.n,self.dim)\n",
    "        print(UA.shape)\n",
    "        score =  dist.ZeroInflatedPoisson( rate = UA@VA.T ,gate = p[:, np.newaxis]).log_prob(torch.from_numpy(test))\n",
    "        mean_score = (score*masked).reshape(-1).logsumexp(-1) -np.log(test.shape[0]*test.shape[1])\n",
    "        return mean_score\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n",
      "UA: (500, 1, 1127, 1)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 1)\n",
      "target: (500, 1127, 5237)\n",
      "[[[  4.   1.   0. ...   3.   4.   3.]\n",
      "  [  5.   0.   0. ...   0.   3.   1.]\n",
      "  [ 15.   0.   0. ...   2.  18.   0.]\n",
      "  ...\n",
      "  [  7.   0.   0. ...   2.   0.   0.]\n",
      "  [ 32.   3.   0. ...   0.  49.   2.]\n",
      "  [  0.   0.   0. ...   0.  25.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   3.   0. ...   0.   0.   0.]\n",
      "  [  6.   0.   0. ...  12.   8.  29.]\n",
      "  ...\n",
      "  [  5.   2.   1. ...  10.   0.   0.]\n",
      "  [ 15.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  1.   0.   0. ...   0.   0.   1.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  ...\n",
      "  [ 18.   0.   0. ...   3.  19.  12.]\n",
      "  [  0.   0.   0. ...   0.   0.   4.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [  5.   0.   0. ...   0.   0.   8.]\n",
      "  ...\n",
      "  [  0.   0.   3. ...   9.  32.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   4.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...   0.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]\n",
      "  [ 17.   1.   0. ...   0.   0.  36.]\n",
      "  ...\n",
      "  [107.   4.   0. ...  11.  55. 193.]\n",
      "  [ 33.   2.   0. ...   0.   0.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]\n",
      "\n",
      " [[  0.   1.   0. ...  22.  10.   4.]\n",
      "  [  1.   0.   0. ...   4.   5.   0.]\n",
      "  [ 15.   1.   0. ...  23.   0.   8.]\n",
      "  ...\n",
      "  [  0.   0.   0. ...   0.   2.   0.]\n",
      "  [  1.   0.   0. ...   2.   1.   0.]\n",
      "  [  0.   0.   0. ...   0.   0.   0.]]]\n",
      "torch.Size([1127, 1])\n",
      "UA: (500, 1, 1127, 5)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 5)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]\n",
      "  ...\n",
      "  [14.  0.  0. ...  0. 16.  3.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [17.  0.  0. ...  0.  0. 22.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  1. 40.  1.]\n",
      "  [17.  2.  0. ... 20. 96.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3.  3.  2.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  4.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  1.  1. ...  3. 25.  5.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0. ...  1.  3. 10.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0. 21.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  1.]\n",
      "  ...\n",
      "  [ 1.  1.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 5])\n",
      "UA: (500, 1, 1127, 10)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 10)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 2.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  8.  5.  6.]\n",
      "  [10.  0.  0. ...  6. 16.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  1.  2.  1.]\n",
      "  [ 4.  0.  0. ...  3.  5.  1.]\n",
      "  ...\n",
      "  [15.  0.  3. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0. ...  2.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  4.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0. 79.  0.]\n",
      "  [ 0.  0.  2. ...  0.  0.  2.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 9.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  2.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 5.  0.  0. ...  1.  6.  0.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ...  0.  0.  1.]\n",
      "  [ 0.  0.  3. ...  0. 12.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 8.  0.  0. ...  6.  6.  3.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 3.  0.  1. ...  4.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 10])\n",
      "UA: (500, 1, 1127, 20)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 20)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 2.  0.  0. ...  0.  0.  0.]\n",
      "  [ 6.  3.  0. ...  6. 19.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]]\n",
      "\n",
      " [[ 3.  0.  0. ...  1.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  1.  2.  1.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  8.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  4.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3.  7.  4.]\n",
      "  ...\n",
      "  [ 9.  0.  1. ... 14.  4.  1.]\n",
      "  [ 3.  0.  0. ...  1.  3.  0.]\n",
      "  [ 1.  0.  1. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  3. 17.  2.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 6.  0.  0. ...  0.  8.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 4.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  1.  0. ...  1.  2.  0.]\n",
      "  ...\n",
      "  [ 6.  0.  1. ...  0. 21.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  4.  9.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 20])\n",
      "UA: (500, 1, 1127, 50)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 50)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 5.  0.  0. ...  3.  0.  2.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  7.  0.  1.]\n",
      "  ...\n",
      "  [13.  0.  0. ... 10. 41.  1.]\n",
      "  [ 0.  0.  0. ...  6. 32.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  2.]\n",
      "  ...\n",
      "  [ 5.  0.  0. ...  0.  0.  0.]\n",
      "  [ 8.  0.  0. ... 10. 21.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [12.  0.  1. ...  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  1.  2.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]\n",
      "  [ 0.  1.  0. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 18.  0.  0.]\n",
      "  [ 5.  0.  0. ...  0. 33.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  1. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 1.  0.  1. ... 11. 19.  1.]\n",
      "  [ 2.  0.  0. ...  7.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  3.  2. ...  3.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 50])\n",
      "UA: (500, 1, 1127, 75)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 75)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 0.  0.  1. ...  2.  0.  0.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ... 11.  0.  6.]\n",
      "  [ 6.  0.  2. ...  4. 36.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 1.  0.  1. ...  1.  6.  2.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 5.  0.  1. ...  3. 46.  0.]\n",
      "  [ 0.  0.  1. ...  0.  0.  9.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  1. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  2. ... 20.  0.  2.]\n",
      "  [ 0.  0.  0. ...  0. 32.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3.  0.  4.]\n",
      "  ...\n",
      "  [12.  0.  1. ... 10. 11.  0.]\n",
      "  [ 0.  0.  0. ...  5.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2. 10.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  3.  0. ...  3.  4.  3.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [10.  0.  0. ...  0.  0.  7.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 75])\n",
      "UA: (500, 1, 1127, 100)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 100)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  1. ...  0.  3.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  3.  3.  2.]\n",
      "  ...\n",
      "  [ 0.  0.  2. ...  4. 11.  1.]\n",
      "  [ 2.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  1. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 4.  0.  1. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 3.  0.  0. ...  1.  7.  0.]\n",
      "  [ 3.  0.  0. ...  1.  7.  0.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ... 19. 12.  4.]\n",
      "  [ 7.  0.  0. ...  3. 24.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  2.]\n",
      "  ...\n",
      "  [15.  0.  3. ... 23. 39.  3.]\n",
      "  [ 0.  0.  0. ...  3. 42.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  1.  0.]\n",
      "  [ 3.  1.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [12.  0.  0. ...  1.  7.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  1.  0.  0.]\n",
      "  [ 2.  0.  0. ...  3.  3.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  2.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 100])\n",
      "UA: (500, 1, 1127, 200)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 200)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  1. ...  2.  0.  0.]\n",
      "  [ 0.  0.  0. ...  3.  0.  2.]\n",
      "  [ 3.  1.  0. ...  3.  3.  1.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  4.  6.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  3.  8.  0.]\n",
      "  ...\n",
      "  [10.  2.  0. ...  0.  0.  0.]\n",
      "  [ 5.  1.  0. ...  5. 21.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0. 11.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [11.  1.  4. ...  9. 28.  2.]\n",
      "  [ 4.  1.  0. ...  4.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  3.  0. ...  4.  0.  0.]\n",
      "  [ 0.  1.  3. ...  3.  4.  0.]\n",
      "  [ 0.  0.  0. ...  0. 10.  2.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  5.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  4.]\n",
      "  [ 0.  1.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0. 21.  3.]\n",
      "  [ 4.  0.  0. ...  1.  3.  6.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  2.  7.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  1.  0. ... 11. 14.  5.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 200])\n",
      "UA: (500, 1, 1127, 250)\n",
      "p: (500, 1, 1127)\n",
      "VA: (500, 1, 5237, 250)\n",
      "target: (500, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  3.  2.  0.]\n",
      "  [ 0.  0.  2. ...  0.  7.  1.]\n",
      "  [ 0.  0.  0. ...  0. 11.  0.]\n",
      "  ...\n",
      "  [ 0.  1.  0. ...  0.  0.  0.]\n",
      "  [ 3.  0.  1. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 6.  0.  0. ...  0. 10.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  3.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0. 13.  7.]\n",
      "  [ 2.  1.  0. ...  5.  0.  6.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  0. ...  0. 10.  2.]\n",
      "  [ 0.  0.  0. ...  6.  0.  0.]\n",
      "  [ 1.  2.  1. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [13.  3.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0. 20.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  3.  0.]\n",
      "  [ 2.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  7.  0.  3.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "torch.Size([1127, 250])\n"
     ]
    }
   ],
   "source": [
    "with open('data_train.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)\n",
    "print(data2.shape)\n",
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "def predictive_score_for_diim_estimation(data_all, train, classname):\n",
    "    score=[]\n",
    "    for d in [1,5,10,20,50,75,100,200,250]:\n",
    "        nan_mask = np.isnan(train) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "        test = classname(data_all,train, d)  \n",
    "        pyro.clear_param_store()\n",
    "        test.train_SVI(data_all , ~torch.from_numpy(nan_mask), verbose = False)\n",
    "        test.sample_predict(500)\n",
    "        score.append(test.predictive_score(data_all,  ~torch.from_numpy(nan_mask)))\n",
    "    return score\n",
    "\n",
    "s = predictive_score_for_diim_estimation(data,data2, PMF_zero_inflated_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = [1,5,10,20,50,75,100,200,250]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d, s)\n",
    "plt.title(\"Value of the Log Predictive For different #dimensions\")\n",
    "plt.savefig(\"predictive_score_zip.png\")\n",
    "plt.show()\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Elbo loss: 13729418.012771606\n",
      "Elbo loss: 13750145.610977173\n",
      "Elbo loss: 13962415.76576233\n",
      "Elbo loss: 14119793.30834961\n",
      "Elbo loss: 13824654.43333435\n",
      "Elbo loss: 13529111.021270752\n",
      "Elbo loss: 13652855.801116943\n",
      "Elbo loss: 13721328.9821167\n",
      "Elbo loss: 13713437.802825928\n",
      "Elbo loss: 13583459.632843018\n",
      "Elbo loss: 13578454.516143799\n",
      "Elbo loss: 13874178.841888428\n",
      "Elbo loss: 13529643.261825562\n",
      "Elbo loss: 13496243.551498413\n",
      "Elbo loss: 13694373.06930542\n",
      "Elbo loss: 14108100.281860352\n",
      "Elbo loss: 13625978.810073853\n",
      "Elbo loss: 13809180.250991821\n",
      "Elbo loss: 13647418.549407959\n",
      "Elbo loss: 13414881.601287842\n",
      "Elbo loss: 13374836.144683838\n",
      "Elbo loss: 13600664.84361267\n",
      "Elbo loss: 13400532.42930603\n",
      "Elbo loss: 13844526.649917603\n",
      "Elbo loss: 13689517.901565552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13729418.012771606,\n",
       " 13799094.6040802,\n",
       " 13937064.166641235,\n",
       " 14044982.368469238,\n",
       " 13740619.588027954,\n",
       " 14102335.373184204,\n",
       " 14144757.285995483,\n",
       " 14303679.13168335,\n",
       " 13957817.211029053,\n",
       " 14330843.800842285,\n",
       " 13750145.610977173,\n",
       " 14096368.707519531,\n",
       " 13901555.47517395,\n",
       " 14066655.321548462,\n",
       " 14226695.234725952,\n",
       " 13725984.370407104,\n",
       " 14066136.482330322,\n",
       " 13839212.206588745,\n",
       " 13854251.875823975,\n",
       " 13762393.408065796,\n",
       " 13962415.76576233,\n",
       " 14064696.379089355,\n",
       " 13823601.69203186,\n",
       " 13776417.682678223,\n",
       " 13716088.710235596,\n",
       " 13696205.110061646,\n",
       " 13693988.414520264,\n",
       " 13681650.319534302,\n",
       " 13648156.417098999,\n",
       " 13508108.145874023,\n",
       " 14119793.30834961,\n",
       " 13991413.649398804,\n",
       " 13794762.69897461,\n",
       " 13966015.728988647,\n",
       " 13651513.499816895,\n",
       " 14044038.64138794,\n",
       " 13633606.217758179,\n",
       " 13745714.428619385,\n",
       " 14126495.49293518,\n",
       " 14070257.738983154,\n",
       " 13824654.43333435,\n",
       " 13906832.114593506,\n",
       " 13913919.809814453,\n",
       " 13824604.572677612,\n",
       " 14103393.58883667,\n",
       " 13857544.905853271,\n",
       " 13991888.443603516,\n",
       " 13700721.345794678,\n",
       " 13793225.238800049,\n",
       " 13525100.225204468,\n",
       " 13529111.021270752,\n",
       " 13623236.04623413,\n",
       " 13847462.816070557,\n",
       " 13623978.28112793,\n",
       " 13680006.478683472,\n",
       " 13559410.892181396,\n",
       " 13737167.333129883,\n",
       " 13598294.677566528,\n",
       " 13431056.555389404,\n",
       " 13583312.256881714,\n",
       " 13652855.801116943,\n",
       " 13754870.826431274,\n",
       " 13894403.723098755,\n",
       " 13704693.23892212,\n",
       " 14243216.929626465,\n",
       " 13580083.903060913,\n",
       " 13998854.29750061,\n",
       " 13618909.575759888,\n",
       " 13643159.56552124,\n",
       " 13724620.031616211,\n",
       " 13721328.9821167,\n",
       " 13737178.832214355,\n",
       " 13636632.961257935,\n",
       " 13592303.459899902,\n",
       " 13628786.24130249,\n",
       " 13787359.337554932,\n",
       " 13519107.79953003,\n",
       " 14025359.223007202,\n",
       " 14014988.356292725,\n",
       " 13575294.263778687,\n",
       " 13713437.802825928,\n",
       " 13690423.216468811,\n",
       " 13597895.20928955,\n",
       " 13354111.753814697,\n",
       " 13898174.996963501,\n",
       " 13611293.487304688,\n",
       " 14066966.639221191,\n",
       " 13779971.907623291,\n",
       " 13413227.907608032,\n",
       " 13448140.626617432,\n",
       " 13583459.632843018,\n",
       " 13483678.874389648,\n",
       " 13722391.728652954,\n",
       " 13382150.498779297,\n",
       " 13996598.710571289,\n",
       " 13755467.281906128,\n",
       " 13850652.186279297,\n",
       " 13476744.79852295,\n",
       " 13462769.10482788,\n",
       " 13711182.94935608,\n",
       " 13578454.516143799,\n",
       " 13920373.706512451,\n",
       " 13875879.532180786,\n",
       " 13707157.538406372,\n",
       " 13698511.1796875,\n",
       " 13591791.520690918,\n",
       " 13899444.239807129,\n",
       " 13797231.930084229,\n",
       " 14082574.578338623,\n",
       " 13721235.628173828,\n",
       " 13874178.841888428,\n",
       " 13823634.45237732,\n",
       " 13799525.06564331,\n",
       " 13916041.459762573,\n",
       " 13747256.175613403,\n",
       " 13458239.838470459,\n",
       " 13736003.624450684,\n",
       " 13986653.620376587,\n",
       " 13513947.411239624,\n",
       " 13657121.526641846,\n",
       " 13529643.261825562,\n",
       " 13700439.79081726,\n",
       " 13954294.744003296,\n",
       " 13609472.732345581,\n",
       " 13939223.263259888,\n",
       " 13627482.794487,\n",
       " 13549329.063171387,\n",
       " 13623460.827919006,\n",
       " 13592679.202194214,\n",
       " 13836691.443939209,\n",
       " 13496243.551498413,\n",
       " 13666813.666687012,\n",
       " 13756109.817138672,\n",
       " 13919711.709243774,\n",
       " 13940361.817382812,\n",
       " 13473045.154434204,\n",
       " 13599435.095581055,\n",
       " 13784041.64187622,\n",
       " 13654306.625152588,\n",
       " 13607304.616790771,\n",
       " 13694373.06930542,\n",
       " 13877518.685592651,\n",
       " 13622657.510543823,\n",
       " 13783372.393173218,\n",
       " 13654865.122650146,\n",
       " 13284781.93510437,\n",
       " 13855441.467338562,\n",
       " 13572560.54977417,\n",
       " 13620378.083068848,\n",
       " 13816598.405670166,\n",
       " 14108100.281860352,\n",
       " 13556998.828475952,\n",
       " 13460751.376113892,\n",
       " 13677591.436599731,\n",
       " 13748131.21736145,\n",
       " 13913519.280151367,\n",
       " 13722049.856170654,\n",
       " 13787097.776641846,\n",
       " 13337036.198348999,\n",
       " 13768114.28414917,\n",
       " 13625978.810073853,\n",
       " 13943926.467910767,\n",
       " 13701403.931427002,\n",
       " 13653269.398757935,\n",
       " 13453749.915176392,\n",
       " 13510178.417953491,\n",
       " 13780023.31376648,\n",
       " 13445981.152160645,\n",
       " 13458894.027954102,\n",
       " 13325532.001586914,\n",
       " 13809180.250991821,\n",
       " 13423336.095916748,\n",
       " 13579563.300964355,\n",
       " 13696509.66532898,\n",
       " 13566879.718780518,\n",
       " 13397531.40560913,\n",
       " 13732226.652420044,\n",
       " 13728568.715621948,\n",
       " 13760106.383865356,\n",
       " 13968774.848937988,\n",
       " 13647418.549407959,\n",
       " 13222553.479553223,\n",
       " 13313057.532577515,\n",
       " 13834914.661193848,\n",
       " 13741282.903640747,\n",
       " 13491357.133865356,\n",
       " 13461724.745483398,\n",
       " 13375391.79460144,\n",
       " 13679206.253433228,\n",
       " 13468374.443695068,\n",
       " 13414881.601287842,\n",
       " 13400413.369766235,\n",
       " 13429203.673065186,\n",
       " 13436822.683448792,\n",
       " 13322227.133728027,\n",
       " 13598609.221633911,\n",
       " 13706395.301605225,\n",
       " 13483045.776870728,\n",
       " 13698571.545181274,\n",
       " 13298936.241790771,\n",
       " 13374836.144683838,\n",
       " 13506045.235351562,\n",
       " 13678767.032745361,\n",
       " 13660140.295318604,\n",
       " 13352235.955352783,\n",
       " 13613911.450942993,\n",
       " 13543243.744110107,\n",
       " 13945738.955413818,\n",
       " 13620636.242080688,\n",
       " 13487962.581756592,\n",
       " 13600664.84361267,\n",
       " 13708810.613586426,\n",
       " 13766530.82611084,\n",
       " 13624515.041015625,\n",
       " 13704473.329673767,\n",
       " 13797845.139602661,\n",
       " 13788514.435302734,\n",
       " 13605724.02772522,\n",
       " 13407350.798675537,\n",
       " 13854589.354660034,\n",
       " 13400532.42930603,\n",
       " 13298533.769317627,\n",
       " 13630428.904586792,\n",
       " 13919280.353302002,\n",
       " 13760868.953109741,\n",
       " 13578366.779769897,\n",
       " 13585050.56576538,\n",
       " 13484257.095809937,\n",
       " 13538856.76071167,\n",
       " 13928270.899353027,\n",
       " 13844526.649917603,\n",
       " 13832901.685958862,\n",
       " 13645212.723831177,\n",
       " 13348279.601760864,\n",
       " 13533801.770706177,\n",
       " 13535077.74168396,\n",
       " 13461996.464736938,\n",
       " 13496208.256347656,\n",
       " 13396904.181350708,\n",
       " 13793013.01437378,\n",
       " 13689517.901565552,\n",
       " 13778460.791519165,\n",
       " 13375319.671417236,\n",
       " 13600082.685012817,\n",
       " 13452810.718009949,\n",
       " 13374204.224243164,\n",
       " 13318523.851776123,\n",
       " 13647800.164100647,\n",
       " 13407624.740646362,\n",
       " 13629577.192718506]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nan_mask = np.isnan(data) #when calculating the train/test set to \"nan\" all the examples that are for testing so that you do not train on them \n",
    "print(torch.from_numpy(nan_mask) )\n",
    "test = PMF_zero_inflated_poisson(train=data, dim=100)\n",
    "test.train_SVI(data, ~torch.from_numpy(nan_mask))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1127, 100)\n",
      "p: (1000, 1, 1127)\n",
      "VA: (1000, 1, 5237, 100)\n",
      "target: (1000, 1127, 5237)\n",
      "[[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  2.  0. ...  0.  0.  0.]\n",
      "  [ 2.  1.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  2.  1. ...  0.  0.  1.]\n",
      "  [ 5.  0.  0. ...  0. 30.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  1.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]\n",
      "  ...\n",
      "  [16.  1.  0. ... 13. 17.  0.]\n",
      "  [ 2.  0.  0. ...  4. 20.  3.]\n",
      "  [ 0.  1.  0. ...  3.  1.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 1.  0.  0. ...  4.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ...  6.  0.  0.]\n",
      "  [ 3.  0.  1. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0.  7.  1.]\n",
      "  ...\n",
      "  [12.  1.  2. ...  2.  0.  1.]\n",
      "  [ 3.  1.  0. ...  9. 29.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  1.]\n",
      "  ...\n",
      "  [31.  0.  0. ... 15.  0.  0.]\n",
      "  [ 2.  0.  0. ...  0. 19.  0.]\n",
      "  [ 1.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]\n",
      "  [ 3.  0.  0. ...  2. 11.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  2. ... 10. 26.  0.]\n",
      "  [ 0.  1.  0. ...  0. 42.  0.]\n",
      "  [ 0.  0.  0. ...  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36273\n",
      "AUC: 0.81252\n",
      "(array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  2.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  2.,  1., ...,  0.,  0.,  1.],\n",
      "        [ 5.,  0.,  0., ...,  0., 30.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [16.,  1.,  0., ..., 13., 17.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  4., 20.,  3.],\n",
      "        [ 0.,  1.,  0., ...,  3.,  1.,  1.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  4.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ...,  6.,  0.,  0.],\n",
      "        [ 3.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 3.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  0.,  7.,  1.],\n",
      "        ...,\n",
      "        [12.,  1.,  2., ...,  2.,  0.,  1.],\n",
      "        [ 3.,  1.,  0., ...,  9., 29.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
      "        ...,\n",
      "        [31.,  0.,  0., ..., 15.,  0.,  0.],\n",
      "        [ 2.,  0.,  0., ...,  0., 19.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 3.,  0.,  0., ...,  2., 11.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  2., ..., 10., 26.,  0.],\n",
      "        [ 0.,  1.,  0., ...,  0., 42.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [1., 0., 0., ..., 1., 1., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
