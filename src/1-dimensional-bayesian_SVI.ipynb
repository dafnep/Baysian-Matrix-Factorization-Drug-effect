{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_Bayesian(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.mean_u = (np.mean(self.data, axis=1).mean()) \n",
    "        self.mean_v = (np.mean(self.data, axis=0).mean())\n",
    "\n",
    "        self.std_u =  np.std(self.data, axis=1).mean()\n",
    "        self.std_v =  np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self,  train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.HalfNormal(self.std_u).expand([self.dim]).to_event(1)) \n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.HalfNormal(self.std_v).expand([self.dim]).to_event(1))\n",
    "        U_alpha_prior = pyro.sample(\"U_alpha_prior\", dist.HalfNormal(self.mean_u).expand([self.dim]).to_event(1)) \n",
    "        V_alpha_prior = pyro.sample(\"V_alpha_prior\", dist.HalfNormal(self.mean_v, ).expand([self.dim]).to_event(1))\n",
    "        \n",
    "\n",
    "\n",
    "        with drug_plate:\n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(U_alpha_prior, U_beta_prior).to_event(1))\n",
    "        \n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(V_alpha_prior, V_beta_prior).to_event(1))    \n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\",self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T), obs= train ) \n",
    "            return Y\n",
    "            \n",
    "    def guide(self, train=None):\n",
    "\n",
    "        d_mean_a = pyro.param('d_alpha_mean', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_std_a = pyro.param('d_alpha_std', 5*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        d_mean_b = pyro.param('d_beta_mean', 1*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_std_b = pyro.param('d_beta_std', 5*torch.ones(self.dim), constraint=constraints.positive)\n",
    "\n",
    "        s_mean_a = pyro.param('s_alpha_mean', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        s_std_a = pyro.param('s_alpha_std', 5*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        s_mean_b = pyro.param('s_beta_mean', 1*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        s_std_b = pyro.param('s_beta_std', 5*torch.ones(self.dim), constraint=constraints.positive)\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        U_alpha_prior = pyro.sample(\"U_alpha_prior\", dist.HalfNormal(d_std_a).to_event(1))\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.HalfNormal( d_std_b).to_event(1))\n",
    "        V_alpha_prior = pyro.sample(\"V_alpha_prior\", dist.HalfNormal( s_std_a).to_event(1))\n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.HalfNormal(s_std_b).to_event(1))\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(U_alpha_prior, U_beta_prior).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "       \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(V_alpha_prior, V_beta_prior).to_event(1))\n",
    "\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.01, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_Bayesian(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.mean_u = (np.mean(self.data, axis=1).mean()) \n",
    "        self.mean_v = (np.mean(self.data, axis=0).mean())\n",
    "\n",
    "        self.std_u =  np.std(self.data, axis=1).mean()\n",
    "        self.std_v =  np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.Beta(self.std_u,self.std_u ).expand([self.dim]).to_event(1)) \n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.Beta(self.std_v,self.std_v ).expand([self.dim]).to_event(1))\n",
    "        U_alpha_prior = pyro.sample(\"U_alpha_prior\", dist.Beta(self.mean_u, self.mean_u).expand([self.dim]).to_event(1)) \n",
    "        V_alpha_prior = pyro.sample(\"V_alpha_prior\", dist.Beta(self.mean_v,self.mean_v).expand([self.dim]).to_event(1))\n",
    "        drug_code = np.arange(self.n)\n",
    "        se_code =np.arange(self.m)\n",
    "\n",
    "\n",
    "        with drug_plate:\n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(U_alpha_prior, U_beta_prior).to_event(1))\n",
    "        \n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(V_alpha_prior, V_beta_prior).to_event(1))    \n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\",self.n, dim=-2)\n",
    "\n",
    "        lamda = UA[drug_code]@VA[se_code].T\n",
    "\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(lamda), obs= train ) \n",
    "            return Y\n",
    "            \n",
    "    def guide(self, train=None):\n",
    "\n",
    "        d_a_a = pyro.param('drug_alpha_a', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_b_a = pyro.param('drug_beta_a', 2*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        d_a_b = pyro.param('drug_alpha_b', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_b_b = pyro.param('d_beta_b', 2*torch.ones(self.dim), constraint=constraints.positive)\n",
    "\n",
    "        s_a_a = pyro.param('se_alpha_a', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        s_b_a = pyro.param('se_beta_a', 2*torch.ones(self.dim), constraint=constraints.positive)\n",
    "        s_a_b = pyro.param('se_alpha_b', 2*torch.ones(self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        s_b_b = pyro.param('se_beta_b', 2*torch.ones(self.dim), constraint=constraints.positive)\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "        U_alpha_prior = pyro.sample(\"U_alpha_prior\", dist.Beta(d_a_a,d_a_b).to_event(1))\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.Beta( d_b_a,d_b_b).to_event(1))\n",
    "        V_alpha_prior = pyro.sample(\"V_alpha_prior\", dist.Beta( s_a_a,s_b_a).to_event(1))\n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.Beta(s_a_b,s_b_b).to_event(1))\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(U_alpha_prior, U_beta_prior).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "       \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(V_alpha_prior, V_beta_prior).to_event(1))\n",
    "\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.01, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(table)\n",
    "        print(predictive_svi[\"U_alpha_prior\"].numpy())\n",
    "        print(predictive_svi[\"U_beta_prior\"].numpy())\n",
    "        print( predictive_svi[\"V_alpha_prior\"].numpy())\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 909411945.7628222\n",
      "Elbo loss: 677729547.2455454\n",
      "Elbo loss: 413242472.5426874\n",
      "Elbo loss: 339509699.4800358\n",
      "Elbo loss: 297990274.35983086\n",
      "Elbo loss: 159784602.772295\n",
      "Elbo loss: 119652360.37707901\n",
      "Elbo loss: 113732923.43795013\n",
      "Elbo loss: 113010929.30049515\n",
      "Elbo loss: 113883015.76681519\n",
      "Elbo loss: 114579550.16135406\n",
      "Elbo loss: 114494968.47083282\n",
      "Elbo loss: 113500180.44535828\n",
      "Elbo loss: 112489309.34720612\n",
      "Elbo loss: 112256228.9376831\n",
      "Elbo loss: 113792579.14980316\n",
      "Elbo loss: 112744600.5335083\n",
      "Elbo loss: 113056794.51698685\n",
      "Elbo loss: 112866655.37303925\n",
      "Elbo loss: 112416042.63575363\n",
      "Elbo loss: 112656111.58013153\n",
      "Elbo loss: 113512506.59054565\n",
      "Elbo loss: 111529762.31521606\n",
      "Elbo loss: 111611655.36561584\n",
      "Elbo loss: 112723501.77404404\n",
      "U_beta_prior: (50, 1, 1, 100)\n",
      "V_beta_prior: (50, 1, 1, 100)\n",
      "U_alpha_prior: (50, 1, 1, 100)\n",
      "V_alpha_prior: (50, 1, 1, 100)\n",
      "UA2: (50, 1, 1127, 100)\n",
      "VA2: (50, 1, 5237, 100)\n",
      "target: (50, 1127, 5237)\n",
      "[[[ 1.  1.  3. ...  3.  2.  6.]\n",
      "  [ 6.  2.  7. ... 10.  6.  5.]\n",
      "  [ 4.  5. 18. ... 11.  4.  1.]\n",
      "  ...\n",
      "  [11.  4. 17. ...  7.  6.  6.]\n",
      "  [ 7.  4. 13. ...  8.  3.  5.]\n",
      "  [ 6.  3. 16. ...  8. 11.  8.]]\n",
      "\n",
      " [[ 3.  0.  0. ...  3.  0.  0.]\n",
      "  [ 3.  3.  2. ...  5.  0.  4.]\n",
      "  [ 3.  6.  0. ...  3.  1.  4.]\n",
      "  ...\n",
      "  [ 4.  1.  4. ...  3.  2.  2.]\n",
      "  [ 6.  2.  4. ... 13.  5.  3.]\n",
      "  [ 1.  4.  3. ...  5.  8.  6.]]\n",
      "\n",
      " [[27. 14. 14. ...  1.  8.  9.]\n",
      "  [ 2.  7. 10. ...  2.  5.  5.]\n",
      "  [ 4.  8.  2. ...  4.  7. 10.]\n",
      "  ...\n",
      "  [ 4.  5.  3. ... 12.  3.  8.]\n",
      "  [ 1.  1.  1. ...  4. 12. 14.]\n",
      "  [20.  5.  9. ...  5.  6.  5.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.  5.  6. ...  1.  1.  2.]\n",
      "  [ 5.  2.  4. ...  7.  6.  2.]\n",
      "  [ 7. 11.  6. ... 18.  0.  0.]\n",
      "  ...\n",
      "  [ 4. 13.  2. ...  3.  1. 11.]\n",
      "  [ 4.  5.  9. ... 10.  4.  3.]\n",
      "  [ 1.  2.  3. ...  9.  8.  8.]]\n",
      "\n",
      " [[ 3.  3.  3. ...  2.  3. 13.]\n",
      "  [ 2.  4.  6. ...  2.  6.  3.]\n",
      "  [ 6.  1.  3. ...  2. 16.  1.]\n",
      "  ...\n",
      "  [ 2.  3.  3. ...  2.  5.  5.]\n",
      "  [ 6.  7.  7. ...  1. 10. 15.]\n",
      "  [ 2.  2.  0. ...  2.  8.  0.]]\n",
      "\n",
      " [[ 8.  2.  5. ...  3.  7.  5.]\n",
      "  [ 4.  5.  4. ...  4.  6.  1.]\n",
      "  [ 2.  9.  4. ...  7.  4.  1.]\n",
      "  ...\n",
      "  [ 4.  3.  7. ...  7.  3.  2.]\n",
      "  [ 1. 11.  8. ...  3.  4.  2.]\n",
      "  [ 1.  9.  5. ...  2.  2.  0.]]]\n",
      "[[[[0.08021879 0.20587401 0.15511465 ... 0.04868581 0.36500928\n",
      "    0.00562498]]]\n",
      "\n",
      "\n",
      " [[[0.13727787 0.15903096 0.0046147  ... 0.19747135 0.49777275\n",
      "    0.3101259 ]]]\n",
      "\n",
      "\n",
      " [[[0.13485585 0.5937568  0.06825656 ... 0.06488497 0.0912824\n",
      "    0.22552228]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.23300454 0.17356086 0.19387066 ... 0.4549307  0.3272274\n",
      "    0.5271564 ]]]\n",
      "\n",
      "\n",
      " [[[0.08993197 0.1832426  0.12467036 ... 0.37392193 0.63201904\n",
      "    0.05229864]]]\n",
      "\n",
      "\n",
      " [[[0.04356844 0.0940433  0.06788856 ... 0.31642428 0.06415822\n",
      "    0.3625507 ]]]]\n",
      "[[[[0.8653465  0.98177177 0.9999949  ... 0.963329   0.99803215\n",
      "    0.79022586]]]\n",
      "\n",
      "\n",
      " [[[0.82120115 0.91635305 0.9120221  ... 0.99974746 0.85389394\n",
      "    0.9240881 ]]]\n",
      "\n",
      "\n",
      " [[[0.951789   0.95058596 0.96238214 ... 0.96540433 0.8425811\n",
      "    0.8365599 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.9125392  0.9130141  0.8492683  ... 0.8993883  0.83657676\n",
      "    0.8774476 ]]]\n",
      "\n",
      "\n",
      " [[[0.8661424  0.6763977  0.9986816  ... 0.5692894  0.7730085\n",
      "    0.9494667 ]]]\n",
      "\n",
      "\n",
      " [[[0.9666515  0.99115384 0.99542403 ... 0.82250744 0.9855621\n",
      "    0.9321059 ]]]]\n",
      "[[[[0.09634766 0.00288661 0.5594165  ... 0.19069724 0.15921593\n",
      "    0.4675882 ]]]\n",
      "\n",
      "\n",
      " [[[0.41407245 0.18221453 0.3186371  ... 0.01478894 0.09259902\n",
      "    0.12342736]]]\n",
      "\n",
      "\n",
      " [[[0.16523504 0.09556979 0.449068   ... 0.25914314 0.39451453\n",
      "    0.3199256 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.05093047 0.23244368 0.00814943 ... 0.12887904 0.11862116\n",
      "    0.06422076]]]\n",
      "\n",
      "\n",
      " [[[0.03031162 0.29849306 0.40589705 ... 0.10937203 0.29041338\n",
      "    0.12054853]]]\n",
      "\n",
      "\n",
      " [[[0.28387418 0.2824039  0.11724168 ... 0.25552487 0.00599257\n",
      "    0.06117127]]]]\n",
      "PMF MAP training RMSE: 0.89472\n",
      "AUC: 0.50000\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test = PMF_Bayesian(train=data, dim=100)\n",
    "\n",
    "test.train_SVI(data)\n",
    "test.sample_predict(50)\n",
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing!!!\n",
    "\n",
    "n,m = data.shape\n",
    "dim=10\n",
    "mean_u = 4\n",
    "mean_v=5\n",
    "std_v=1\n",
    "std_u=1\n",
    "drug_code = np.arange(n)\n",
    "se_code =np.arange(m)\n",
    "def model0():\n",
    "        drug_code = np.arange(n)\n",
    "        se_code =np.arange(m)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\",m, dim= -1) #independent items\n",
    "        U_beta_prior = pyro.sample(\"U_beta_prior\", dist.HalfNormal(std_u).expand([dim]).to_event(1)) \n",
    "        V_beta_prior = pyro.sample(\"V_beta_prior\", dist.HalfNormal(std_v).expand([dim]).to_event(1))\n",
    "        U_alpha_prior = pyro.sample(\"U_alpha_prior\", dist.HalfNormal(mean_u).expand([dim]).to_event(1)) \n",
    "        V_alpha_prior = pyro.sample(\"V_alpha_prior\", dist.HalfNormal(mean_v, ).expand([dim]).to_event(1))\n",
    "        \n",
    "\n",
    "\n",
    "        with drug_plate:\n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(U_alpha_prior, U_beta_prior).to_event(1))\n",
    "        \n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(V_alpha_prior, V_beta_prior).to_event(1))    \n",
    "        \n",
    "        u2_plate = pyro.plate(\"u2_plate\",n, dim=-2)\n",
    "\n",
    "        lamda = UA[drug_code]@VA[se_code].T\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(lamda) ) \n",
    "            return Y\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA@VA.T) ) \n",
    "     \n",
    "            return VA\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "      \n",
    "\n",
    "def guide9():\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', 5*torch.ones(n,dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.05*torch.ones(n,dim), constraint=constraints.positive)\n",
    "        # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "        # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "            #                  constraint=constraints.positive)\n",
    "        s_alpha = pyro.param('s_alpha', 5*torch.ones(m,dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.05*torch.ones(m,dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\",n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\",m, dim= -1) #independent items\n",
    "        se_t = pyro.param(\"sef_int\", 0.25*torch.ones(m), constraint=constraints.positive)\n",
    "        drug_t = pyro.param(\"drug_int_p\", 0.25*torch.ones(n), constraint=constraints.positive)\n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "        with u2_plate:\n",
    "            drug_intercept = pyro.sample(\"drug_int\", dist.HalfNormal(drug_t).to_event(1))\n",
    "\n",
    "        \n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA2\", dist.Gamma(d_alpha, d_beta).to_event(1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "     \n",
    "        \n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA2\", dist.Gamma(s_alpha, s_beta).to_event(1))\n",
    "            sideeffect_intercept =  pyro.sample(\"sf_int\", dist.HalfNormal(se_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Trace Shapes:               \n",
      "           Param Sites:               \n",
      "          Sample Sites:               \n",
      "      drug_latents dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "sideeffect_latents dist           |   \n",
      "                  value      5237 |   \n",
      "               log_prob           |   \n",
      "      U_beta_prior dist           | 10\n",
      "                  value           | 10\n",
      "               log_prob           |   \n",
      "      V_beta_prior dist           | 10\n",
      "                  value           | 10\n",
      "               log_prob           |   \n",
      "     U_alpha_prior dist           | 10\n",
      "                  value           | 10\n",
      "               log_prob           |   \n",
      "     V_alpha_prior dist           | 10\n",
      "                  value           | 10\n",
      "               log_prob           |   \n",
      "               UA2 dist      1127 | 10\n",
      "                  value      1127 | 10\n",
      "               log_prob      1127 |   \n",
      "               VA2 dist      5237 | 10\n",
      "                  value      5237 | 10\n",
      "               log_prob      5237 |   \n",
      "          u2_plate dist           |   \n",
      "                  value      1127 |   \n",
      "               log_prob           |   \n",
      "            target dist 1127 5237 |   \n",
      "                  value 1127 5237 |   \n",
      "               log_prob 1127 5237 |   \n"
     ]
    }
   ],
   "source": [
    "trace=poutine.trace(model0).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
