{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from pyro import poutine\n",
    "from sklearn import metrics\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal, AutoLowRankMultivariateNormal, init_to_mean,init_to_feasible,AutoNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PMF_clusters(nn.Module):\n",
    "    #bayesian non parametrics - dirichlet process\n",
    "\n",
    "    #with multivariate gammas that are \"somehow?\" related through pyro's dependent dimension setting\n",
    "    #how to define their covariance?\n",
    "    def __init__(self, train, dim,p1,p2):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.t_drug = p1[0]\n",
    "        self.phi_drug = p1[1]\n",
    "        self.t_s = p2[0]\n",
    "        self.phi_s = p2[1]\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "        self.num_clusters_drugs = 73\n",
    "        self.num_clusters_se =  77\n",
    "    def mix_weights(self,beta):\n",
    "            beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "            return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "    def model(self, data):\n",
    "            alpha = 10\n",
    "            with pyro.plate(\"beta_drugs_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_drugs_plate\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(torch.zeros(self.dim), 0.1 * torch.eye(self.dim)))\n",
    "            #     cov = pyro.sample(\"cov\", dist.Gamma(torch.ones(1), 2*torch.ones(1)).expand([self.dim]).to_event(1) )\n",
    "\n",
    "            # cov_matrix = torch.ones(self.num_clusters_drugs,self.dim,self.dim)\n",
    "            # for i in range(0,self.num_clusters_drugs):\n",
    "            #     cov_matrix[i] = cov[i]*torch.eye(self.dim)\n",
    "\n",
    "            with pyro.plate(\"data_drugs\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(self.mix_weights(beta_drugs)))\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d],  0.05*torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(torch.zeros(self.dim), 0.1 * torch.eye(self.dim)))\n",
    "            #     cov2 = pyro.sample(\"cov2\", dist.Gamma(torch.ones(1), 2*torch.ones(1)).expand([self.dim]).to_event(1) )\n",
    "\n",
    "            # cov_matrix2 = torch.ones(self.num_clusters_se,self.dim,self.dim)\n",
    "            # for i in range(0,self.num_clusters_se):\n",
    "            #     cov_matrix2[i] = cov2[i]*torch.eye(self.dim)\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(self.mix_weights(beta_se)))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], 0.05*torch.eye(self.dim)))#cov2[z_se]))\n",
    "            \n",
    "            u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "            se2_plate = pyro.plate(\"se2_plate\", self.m, dim=-1)\n",
    "\n",
    "            with se2_plate, u2_plate: \n",
    "                Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=data ) \n",
    "                return Y\n",
    "\n",
    "    def guide(self,data=None):\n",
    "            kappa = pyro.param('kappa_d', lambda: dist.Uniform(0, 2).sample([self.num_clusters_drugs-1]), constraint=constraints.positive)\n",
    "            tau = pyro.param('tau_d', self.t_drug)\n",
    "            phi = pyro.param('phi_d', self.phi_drug, constraint=constraints.simplex)\n",
    "            # d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "            # d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "\n",
    "\n",
    "            with pyro.plate(\"beta_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(torch.ones(self.num_clusters_drugs-1), kappa))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_drug\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(tau, 0.01*torch.eye(self.dim)))\n",
    "                \n",
    "\n",
    "            with pyro.plate(\"data_drug\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(phi))\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d], 0.1*torch.eye(self.dim)))\n",
    "\n",
    "            \n",
    "            kappa_s = pyro.param('kappa_s', lambda: dist.Uniform(0, 2).sample([self.num_clusters_se-1]), constraint=constraints.positive)\n",
    "            tau_s = pyro.param('tau_s', self.t_s)\n",
    "            phi_s = pyro.param('phi_s', self.phi_s, constraint=constraints.simplex)\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(torch.ones(self.num_clusters_se-1), kappa_s))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(tau_s, 0.01*torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(phi_s))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], 0.1*torch.eye(self.dim)))\n",
    "\n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "                logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "                svi = SVI(self.model,\n",
    "                self.guide,\n",
    "                optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "                loss=Trace_ELBO())\n",
    "                losses = []\n",
    "                for step in range(nsteps):\n",
    "                    elbo = svi.step(torch.from_numpy(train).float())\n",
    "                    losses.append(elbo)\n",
    "                    if step % 10 == 0:\n",
    "                        print(\"Elbo loss: {}\".format(elbo))\n",
    "                self.losses = losses\n",
    "                #constrained_params = list(pyro.get_param_store().values())\n",
    "                #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "                #print(PARAMS)\n",
    "                return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'mu_plate_drug', 'data_drug', 'beta_plate'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 123953260.4874115\n",
      "Elbo loss: 134619347.82818985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures copy.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      param_se \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(handle)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m test \u001b[39m=\u001b[39m PMF_clusters(train\u001b[39m=\u001b[39mdata, dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, p1\u001b[39m=\u001b[39mparam_drugs, p2\u001b[39m=\u001b[39mparam_se)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test\u001b[39m.\u001b[39;49mtrain_SVI(data)\n",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures copy.ipynb Cell 4\u001b[0m in \u001b[0;36mPMF_clusters.train_SVI\u001b[0;34m(self, train, nsteps, lr, lrd)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nsteps):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     elbo \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(torch\u001b[39m.\u001b[39;49mfrom_numpy(train)\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(elbo)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures%20copy.ipynb#W3sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/trace_elbo.py:157\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mif\u001b[39;00m trainable_params \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[1;32m    154\u001b[0m         surrogate_loss_particle, \u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         surrogate_loss_particle \u001b[39m=\u001b[39m surrogate_loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n\u001b[0;32m--> 157\u001b[0m         surrogate_loss_particle\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretain_graph)\n\u001b[1;32m    158\u001b[0m warn_if_nan(loss, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/util.py:84\u001b[0m, in \u001b[0;36mwarn_if_nan.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         lineno \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_lineno\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(value) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m     83\u001b[0m     value\u001b[39m.\u001b[39mregister_hook(\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mlambda\u001b[39;00m x: warn_if_nan(\n\u001b[1;32m     85\u001b[0m             x, \u001b[39m\"\u001b[39m\u001b[39mbackward \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg, filename\u001b[39m=\u001b[39mfilename, lineno\u001b[39m=\u001b[39mlineno\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m torch_isnan(value):\n\u001b[1;32m     90\u001b[0m     warnings\u001b[39m.\u001b[39mwarn_explicit(\n\u001b[1;32m     91\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncountered NaN\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg \u001b[39mif\u001b[39;00m msg \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     92\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m         filename,\n\u001b[1;32m     94\u001b[0m         lineno,\n\u001b[1;32m     95\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "with open('drug_param.pickle', 'rb') as handle:\n",
    "     param_drugs = pickle.load(handle)\n",
    "\n",
    "with open('se_param.pickle', 'rb') as handle:\n",
    "     param_se = pickle.load(handle)\n",
    "\n",
    "test = PMF_clusters(train=data, dim=100, p1=param_drugs, p2=param_se)\n",
    "test.train_SVI(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_drugs: (700, 1, 72)\n",
      "mu_drugs: (700, 1, 73, 100)\n",
      "z_drugs: (700, 1, 1127)\n",
      "UA: (700, 1, 1127, 100)\n",
      "beta_se: (700, 1, 76)\n",
      "mu_se: (700, 1, 77, 100)\n",
      "z_se: (700, 1, 5237)\n",
      "VA: (700, 1, 5237, 100)\n",
      "target: (700, 1127, 5237)\n",
      "[[[ 8.  7.  4. ...  1. 31.  6.]\n",
      "  [10. 11.  9. ... 12. 20.  2.]\n",
      "  [22. 14. 18. ... 30.  0. 21.]\n",
      "  ...\n",
      "  [ 0.  1.  3. ... 10.  7.  8.]\n",
      "  [ 0.  0.  2. ...  4.  9.  5.]\n",
      "  [13.  7.  1. ... 17. 11.  6.]]\n",
      "\n",
      " [[ 2.  6.  3. ...  7.  2.  3.]\n",
      "  [ 5.  6.  3. ...  9.  3.  8.]\n",
      "  [ 9.  4.  4. ...  7. 11.  1.]\n",
      "  ...\n",
      "  [24. 14.  6. ...  5.  0. 14.]\n",
      "  [ 3.  9. 40. ...  6.  0. 11.]\n",
      "  [ 7.  2. 25. ... 22.  3. 13.]]\n",
      "\n",
      " [[14. 16. 26. ...  1.  9.  9.]\n",
      "  [28. 10.  2. ... 14.  6.  4.]\n",
      "  [ 5.  0. 10. ... 22. 15. 40.]\n",
      "  ...\n",
      "  [ 0.  1. 12. ...  0.  9. 16.]\n",
      "  [14.  0.  6. ...  7.  1. 13.]\n",
      "  [14.  4.  3. ... 26.  6. 19.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[20.  2.  9. ... 15.  6.  6.]\n",
      "  [15. 19.  2. ... 15.  7. 15.]\n",
      "  [ 9.  3. 13. ... 14. 10. 20.]\n",
      "  ...\n",
      "  [ 4. 14. 21. ... 17.  2. 19.]\n",
      "  [ 1.  9. 15. ...  4.  7.  5.]\n",
      "  [18.  7.  5. ... 11.  6. 10.]]\n",
      "\n",
      " [[ 7.  0.  2. ...  6.  2.  5.]\n",
      "  [ 5. 10.  8. ...  7.  6.  2.]\n",
      "  [12. 11.  3. ... 15.  3. 22.]\n",
      "  ...\n",
      "  [ 4.  9.  4. ... 14.  5. 33.]\n",
      "  [ 5.  0.  7. ... 16.  7.  3.]\n",
      "  [ 8.  8.  6. ... 11.  5.  6.]]\n",
      "\n",
      " [[ 8.  2. 16. ...  6. 40.  6.]\n",
      "  [ 6.  6.  6. ... 24.  9. 24.]\n",
      "  [30. 11.  7. ...  2. 17. 24.]\n",
      "  ...\n",
      "  [ 3. 16.  9. ...  7.  5. 13.]\n",
      "  [ 2.  8. 23. ...  7. 30. 21.]\n",
      "  [19. 20. 27. ... 11. 32.  7.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictive_svi = Predictive(test.model, guide=test.guide, num_samples=700)(None )\n",
    "for k, v in predictive_svi.items():\n",
    "    print(f\"{k}: {tuple(v.shape)}\")\n",
    "table = predictive_svi[\"target\"].numpy()\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.28535977  0.5407753  -0.11483517 ...  0.75336343  1.2187921\n",
      "    -1.168079  ]\n",
      "   [ 0.27519417  0.6142986  -0.06168953 ... -0.5462328   1.0791954\n",
      "    -1.0290871 ]\n",
      "   [-2.520281    0.49413767  1.2901305  ...  1.2930528  -0.40262035\n",
      "    -0.7137808 ]\n",
      "   ...\n",
      "   [ 1.1134045   2.2058878  -0.10623908 ...  2.0770118  -1.7445196\n",
      "    -0.13941166]\n",
      "   [ 0.7838261   1.2989461  -1.6670617  ...  1.0509782  -0.63851213\n",
      "    -1.2264577 ]\n",
      "   [-2.2912352  -0.24184676  1.016104   ...  0.6750027   0.00472934\n",
      "    -0.5812001 ]]]\n",
      "\n",
      "\n",
      " [[[-0.90443933 -0.8370635  -0.6256679  ...  1.0380534   0.35315022\n",
      "    -0.15691854]\n",
      "   [-0.79911983  0.4583026   0.43753034 ... -2.6858876   0.54812634\n",
      "     0.34935674]\n",
      "   [ 1.8308849  -0.90615886 -0.8976115  ...  0.7617015   0.5277555\n",
      "     0.78012705]\n",
      "   ...\n",
      "   [ 1.0805224   1.0855103   0.46282822 ... -0.17598367 -1.0061806\n",
      "    -0.9500762 ]\n",
      "   [-1.1788591  -1.5199696   0.0466184  ...  2.2012267   2.1054943\n",
      "     1.5023819 ]\n",
      "   [-0.6371386   0.69335437  0.45942116 ... -1.665205    0.69373447\n",
      "     0.8705045 ]]]\n",
      "\n",
      "\n",
      " [[[-1.927718   -1.6189137   0.20918572 ...  0.560152   -0.37966982\n",
      "     1.1112638 ]\n",
      "   [ 0.5540794   1.0874618  -0.8192301  ... -1.5330015  -1.933758\n",
      "     0.31753427]\n",
      "   [-0.69265366  1.3905065  -1.3681358  ... -0.10478562  1.4670875\n",
      "    -0.47401184]\n",
      "   ...\n",
      "   [-0.6195801  -0.22948042  2.2053516  ... -0.12639487  0.12035477\n",
      "    -0.16733572]\n",
      "   [ 0.42045248  1.7531446   1.5691725  ...  0.19776055 -1.710426\n",
      "    -1.0813628 ]\n",
      "   [ 1.2470459   0.8088881   2.062429   ...  0.44857666  1.21269\n",
      "     0.24949284]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.3036914   0.20207648  0.14952964 ...  0.11540014 -1.0461485\n",
      "    -0.9973643 ]\n",
      "   [ 1.2591996   0.96715724  1.1645185  ... -1.5417813   1.6967204\n",
      "    -1.0328374 ]\n",
      "   [-0.16490269 -0.21238755  0.70065844 ...  0.7695341  -2.8679626\n",
      "     0.8643826 ]\n",
      "   ...\n",
      "   [ 1.4874008  -0.8130229  -0.9290041  ...  1.6913651  -0.512822\n",
      "    -2.7027252 ]\n",
      "   [-0.21808428 -0.50007457 -1.9990044  ...  1.7230246   0.18638152\n",
      "    -2.1585677 ]\n",
      "   [-3.7742863  -1.4196014   0.3482596  ... -0.2592708  -0.31169635\n",
      "     0.21825397]]]\n",
      "\n",
      "\n",
      " [[[ 0.53151023 -0.39503905 -0.68268025 ...  1.1717932  -1.1893533\n",
      "    -0.95745826]\n",
      "   [-0.68510675 -0.8674612  -0.01974887 ... -0.15310201 -0.3826838\n",
      "    -1.2540662 ]\n",
      "   [-0.5709597  -1.2157495   0.7514817  ...  0.6000891   1.3838768\n",
      "    -2.1365256 ]\n",
      "   ...\n",
      "   [-1.376275   -0.00620717 -0.11187963 ...  1.77038    -0.49583045\n",
      "    -0.46733242]\n",
      "   [ 0.38327512  0.605423    0.67741764 ...  0.9498171  -1.119231\n",
      "    -2.191109  ]\n",
      "   [ 1.5794029   0.2045312  -1.4959632  ... -0.7528666  -0.11687607\n",
      "     0.3373338 ]]]\n",
      "\n",
      "\n",
      " [[[ 2.5248914   0.29667598  2.2981536  ... -0.6315019  -0.8014126\n",
      "     1.6056815 ]\n",
      "   [ 0.28997907  0.34159714 -0.57338655 ...  0.9086013  -1.4872411\n",
      "     2.5193973 ]\n",
      "   [-0.41422963 -2.1698692   0.74356246 ... -2.1346145   1.5135417\n",
      "     0.06666708]\n",
      "   ...\n",
      "   [-0.15410593  0.5811652  -1.5119765  ... -1.3476195  -0.74115014\n",
      "     0.16585398]\n",
      "   [ 0.6106049   1.019159   -0.0549747  ...  0.5848923  -0.07685447\n",
      "     0.6370778 ]\n",
      "   [ 1.7710257  -0.48846027  0.11443102 ... -0.06256366 -0.74187446\n",
      "     0.3443221 ]]]]\n"
     ]
    }
   ],
   "source": [
    "table2 = predictive_svi[\"UA\"].numpy()\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PM_test_normals(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "        self.returned = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = np.mean(self.data, axis=1).mean()\n",
    "        self.alpha_v =  np.std(self.data, axis=1).mean()\n",
    "        \n",
    "        self.beta_u = np.mean(self.data, axis=0).mean() \n",
    "        self.beta_v =  np.std(self.data, axis=0).mean()\n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self, train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Normal(self.alpha_u, self.beta_u).expand([self.dim]).to_event(1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with sideeffect_plate:\n",
    "            VA = pyro.sample(\"VA\", dist.Normal(self.alpha_v, self.beta_v).expand([self.dim]).to_event(1))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "         \n",
    "             Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=train ) \n",
    "             return Y\n",
    "        \n",
    "\n",
    "    def guide(self, train=None, mask=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.n,self.dim), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.n,self.dim), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.m,self.dim), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones(self.m,self.dim), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        with drug_plate: \n",
    "            UA = pyro.sample(\"UA\", dist.Normal(d_alpha, d_beta).to_event(1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        with sideeffect_plate: \n",
    "            VA = pyro.sample(\"VA\", dist.Normal(s_alpha, s_beta).to_event(1))\n",
    "    \n",
    "    def train_SVI(self,train,nsteps=250, lr = 0.05, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "    \n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)(None )\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        print(predictive_svi[\"UA\"].numpy())\n",
    "        print(table)\n",
    "        self.returned = table\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return (self.returned,self.predictions)\n",
    "\n",
    "    \n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 591432476.8125\n",
      "Elbo loss: 239103504.328125\n",
      "Elbo loss: 116336450.234375\n",
      "Elbo loss: 71069838.8984375\n",
      "Elbo loss: 54330414.9921875\n",
      "Elbo loss: 48362075.265625\n",
      "Elbo loss: 45127749.2421875\n",
      "Elbo loss: 43086197.15625\n",
      "Elbo loss: 41732170.1171875\n",
      "Elbo loss: 40314587.0625\n",
      "Elbo loss: 39100278.40234375\n",
      "Elbo loss: 37828989.0625\n",
      "Elbo loss: 36709630.87890625\n",
      "Elbo loss: 35421977.07421875\n",
      "Elbo loss: 34185446.689453125\n",
      "Elbo loss: 32923683.490234375\n",
      "Elbo loss: 31648543.49609375\n",
      "Elbo loss: 30293576.508789062\n",
      "Elbo loss: 28964532.186523438\n",
      "Elbo loss: 27587156.774902344\n",
      "Elbo loss: 26430231.645263672\n",
      "Elbo loss: 25193279.890625\n",
      "Elbo loss: 24073525.458007812\n",
      "Elbo loss: 23086155.828125\n",
      "Elbo loss: 22172239.625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[591432476.8125,\n",
       " 538834471.9375,\n",
       " 488149915.3125,\n",
       " 445523456.9765625,\n",
       " 405506890.4765625,\n",
       " 370707173.2578125,\n",
       " 339093177.0390625,\n",
       " 309681960.4375,\n",
       " 284761439.375,\n",
       " 260882675.9921875,\n",
       " 239103504.328125,\n",
       " 220628402.0234375,\n",
       " 203509699.3671875,\n",
       " 188415758.09375,\n",
       " 173408269.0859375,\n",
       " 161949297.359375,\n",
       " 151487045.09375,\n",
       " 140488381.3671875,\n",
       " 131264792.8125,\n",
       " 123462614.265625,\n",
       " 116336450.234375,\n",
       " 109566729.765625,\n",
       " 102879449.4140625,\n",
       " 97921070.40625,\n",
       " 92545796.765625,\n",
       " 87987672.2734375,\n",
       " 83922075.40625,\n",
       " 79997450.0625,\n",
       " 76707045.796875,\n",
       " 73702940.015625,\n",
       " 71069838.8984375,\n",
       " 68147953.3828125,\n",
       " 66099763.75,\n",
       " 64343995.2890625,\n",
       " 62471817.765625,\n",
       " 60501447.90625,\n",
       " 59014716.46875,\n",
       " 57949754.40625,\n",
       " 56490802.9140625,\n",
       " 55351322.5625,\n",
       " 54330414.9921875,\n",
       " 53132290.3828125,\n",
       " 52497240.875,\n",
       " 51740164.78125,\n",
       " 51044806.859375,\n",
       " 50319237.0859375,\n",
       " 49870891.40625,\n",
       " 49192331.0859375,\n",
       " 48854842.734375,\n",
       " 48421415.71875,\n",
       " 48362075.265625,\n",
       " 47505831.703125,\n",
       " 47250801.5,\n",
       " 47188658.3671875,\n",
       " 46754873.3515625,\n",
       " 46533637.1328125,\n",
       " 46185060.75,\n",
       " 45709660.125,\n",
       " 45604022.421875,\n",
       " 45444567.703125,\n",
       " 45127749.2421875,\n",
       " 44900971.0078125,\n",
       " 44501661.171875,\n",
       " 44461648.2578125,\n",
       " 44328777.171875,\n",
       " 44077256.296875,\n",
       " 44015169.578125,\n",
       " 43762691.59375,\n",
       " 43492913.28125,\n",
       " 43459387.0390625,\n",
       " 43086197.15625,\n",
       " 43037785.59375,\n",
       " 42758180.171875,\n",
       " 42752842.171875,\n",
       " 42419175.0390625,\n",
       " 42421798.453125,\n",
       " 42149455.0703125,\n",
       " 42165148.0078125,\n",
       " 42109155.078125,\n",
       " 41800112.9453125,\n",
       " 41732170.1171875,\n",
       " 41612769.26171875,\n",
       " 41389465.734375,\n",
       " 41423651.17578125,\n",
       " 41050543.68359375,\n",
       " 40919656.09375,\n",
       " 40917410.6953125,\n",
       " 40832863.015625,\n",
       " 40612770.69140625,\n",
       " 40517415.15625,\n",
       " 40314587.0625,\n",
       " 40329703.265625,\n",
       " 40177794.78515625,\n",
       " 40036975.26953125,\n",
       " 39699290.578125,\n",
       " 39669952.16796875,\n",
       " 39669963.05859375,\n",
       " 39370631.7578125,\n",
       " 39392826.62890625,\n",
       " 39216174.03515625,\n",
       " 39100278.40234375,\n",
       " 39026588.95703125,\n",
       " 38808861.40625,\n",
       " 38761717.0078125,\n",
       " 38472137.43359375,\n",
       " 38553452.32421875,\n",
       " 38286201.25390625,\n",
       " 38257768.98046875,\n",
       " 38084974.7109375,\n",
       " 37842515.1796875,\n",
       " 37828989.0625,\n",
       " 37733106.99609375,\n",
       " 37528415.4375,\n",
       " 37499243.56640625,\n",
       " 37322848.09375,\n",
       " 37221317.76171875,\n",
       " 37193174.83984375,\n",
       " 37053326.8125,\n",
       " 36880929.390625,\n",
       " 36718763.859375,\n",
       " 36709630.87890625,\n",
       " 36415212.58203125,\n",
       " 36470341.5859375,\n",
       " 36278756.0546875,\n",
       " 36244891.671875,\n",
       " 36114595.31640625,\n",
       " 35971526.703125,\n",
       " 35853304.5390625,\n",
       " 35755892.48828125,\n",
       " 35514901.36328125,\n",
       " 35421977.07421875,\n",
       " 35250454.69921875,\n",
       " 35205232.92578125,\n",
       " 35077763.51953125,\n",
       " 34973362.0625,\n",
       " 34888402.8515625,\n",
       " 34770106.0,\n",
       " 34623712.69140625,\n",
       " 34448396.607421875,\n",
       " 34398987.845703125,\n",
       " 34185446.689453125,\n",
       " 34097255.498046875,\n",
       " 33892741.54296875,\n",
       " 33905112.66015625,\n",
       " 33727943.599609375,\n",
       " 33528395.537109375,\n",
       " 33447259.90625,\n",
       " 33384642.419921875,\n",
       " 33209760.009765625,\n",
       " 32955137.634765625,\n",
       " 32923683.490234375,\n",
       " 32909483.369140625,\n",
       " 32668522.890625,\n",
       " 32603192.005859375,\n",
       " 32418183.9453125,\n",
       " 32330220.62109375,\n",
       " 32155887.0234375,\n",
       " 32023708.08984375,\n",
       " 31928610.12109375,\n",
       " 31857210.05078125,\n",
       " 31648543.49609375,\n",
       " 31561354.81640625,\n",
       " 31430375.609375,\n",
       " 31273015.57421875,\n",
       " 31141741.515625,\n",
       " 31019121.333984375,\n",
       " 30971881.10546875,\n",
       " 30684994.51953125,\n",
       " 30665135.751953125,\n",
       " 30435775.801757812,\n",
       " 30293576.508789062,\n",
       " 30229231.041992188,\n",
       " 30114637.990234375,\n",
       " 29955846.669921875,\n",
       " 29782955.220703125,\n",
       " 29605466.86328125,\n",
       " 29509436.376953125,\n",
       " 29370314.0625,\n",
       " 29298332.06640625,\n",
       " 29124511.025390625,\n",
       " 28964532.186523438,\n",
       " 28856625.349609375,\n",
       " 28658886.934570312,\n",
       " 28503194.721679688,\n",
       " 28506779.405273438,\n",
       " 28326193.495117188,\n",
       " 28104279.10498047,\n",
       " 28013526.661621094,\n",
       " 27870069.075195312,\n",
       " 27742965.607177734,\n",
       " 27587156.774902344,\n",
       " 27509945.632080078,\n",
       " 27270200.396972656,\n",
       " 27192389.088012695,\n",
       " 27136818.498291016,\n",
       " 27051290.82952881,\n",
       " 26854549.469207764,\n",
       " 26702233.68109131,\n",
       " 26583366.123657227,\n",
       " 26505969.26220703,\n",
       " 26430231.645263672,\n",
       " 26204610.889648438,\n",
       " 26103971.641845703,\n",
       " 26044110.213378906,\n",
       " 25880471.07763672,\n",
       " 25768243.612304688,\n",
       " 25676929.928222656,\n",
       " 25567755.458496094,\n",
       " 25426976.853515625,\n",
       " 25347539.234375,\n",
       " 25193279.890625,\n",
       " 25091048.859375,\n",
       " 24997644.80810547,\n",
       " 24822934.564941406,\n",
       " 24751053.05419922,\n",
       " 24587417.009918213,\n",
       " 24460481.778076172,\n",
       " 24430646.16845703,\n",
       " 24306095.747070312,\n",
       " 24264311.869140625,\n",
       " 24073525.458007812,\n",
       " 23929894.94921875,\n",
       " 23876165.225585938,\n",
       " 23763509.3125,\n",
       " 23724413.357421875,\n",
       " 23595750.0390625,\n",
       " 23482722.2890625,\n",
       " 23401551.751953125,\n",
       " 23292769.748046875,\n",
       " 23286637.353515625,\n",
       " 23086155.828125,\n",
       " 23036386.99609375,\n",
       " 22959222.47265625,\n",
       " 22850602.93359375,\n",
       " 22763594.2578125,\n",
       " 22634408.265625,\n",
       " 22579249.03125,\n",
       " 22477017.294921875,\n",
       " 22399887.65234375,\n",
       " 22271302.34765625,\n",
       " 22172239.625,\n",
       " 22114194.5703125,\n",
       " 22043709.87109375,\n",
       " 21936296.4140625,\n",
       " 21877645.578125,\n",
       " 21825636.38671875,\n",
       " 21733387.697265625,\n",
       " 21676920.025390625,\n",
       " 21557283.18359375,\n",
       " 21530754.99609375]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PM_test_normals(train=data, dim=100)\n",
    "test.train_SVI(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (500, 1, 1127, 100)\n",
      "VA: (500, 1, 5237, 100)\n",
      "target: (500, 1127, 5237)\n",
      "[[[[ 6.40348867e-02 -4.75348890e-01 -7.94213340e-02 ... -2.59275168e-01\n",
      "    -1.20288119e-01 -1.15572318e-01]\n",
      "   [ 1.50117487e-01  1.90185070e-01  1.92879945e-01 ... -8.30131471e-02\n",
      "     1.13322705e-01 -1.53372899e-01]\n",
      "   [-1.21509857e-01 -1.11562379e-01  1.96243718e-01 ...  1.07064366e-01\n",
      "     8.40026513e-02 -3.93198356e-02]\n",
      "   ...\n",
      "   [-6.50865138e-02 -2.03364015e-01  1.97081864e-01 ...  2.16839805e-01\n",
      "    -1.65045746e-02 -1.98119804e-01]\n",
      "   [ 9.77682173e-02  9.53350216e-02 -5.48548065e-03 ...  1.16732687e-01\n",
      "     2.93995813e-03  3.96088883e-02]\n",
      "   [-6.41719177e-02  1.12862371e-01 -4.03884985e-02 ... -5.06552532e-02\n",
      "     1.90641165e-01 -8.10519084e-02]]]\n",
      "\n",
      "\n",
      " [[[ 9.96897370e-03  1.70645386e-01 -4.58481945e-02 ...  1.15541600e-01\n",
      "     3.68814558e-01 -1.71744451e-01]\n",
      "   [ 3.07305992e-01 -9.03509706e-02 -6.04870729e-05 ...  2.50956416e-02\n",
      "    -1.87679842e-01  9.78012979e-02]\n",
      "   [ 5.49563289e-01  2.13760942e-01 -9.42850411e-01 ... -2.07331046e-01\n",
      "     3.28886248e-02  6.90900609e-02]\n",
      "   ...\n",
      "   [ 1.35066450e-01  2.66236752e-01 -6.96322024e-02 ...  3.90363365e-01\n",
      "     4.31307033e-02  6.89768016e-01]\n",
      "   [-1.75088719e-01  5.59313968e-03  3.22511084e-02 ...  2.48341173e-01\n",
      "    -2.25083344e-02  3.21807340e-02]\n",
      "   [-1.88488699e-02  1.46547239e-02  1.16836019e-01 ...  1.55955330e-01\n",
      "    -2.18078792e-01 -2.14686990e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.47190350e-02 -2.05128700e-01  1.59824431e-01 ... -1.48188369e-02\n",
      "     1.49098992e-01  3.09818685e-01]\n",
      "   [ 3.71820144e-02  1.35287821e-01 -5.70173413e-02 ... -7.58109093e-02\n",
      "     9.05412585e-02  2.49990653e-02]\n",
      "   [-1.77030906e-01 -3.73138517e-01 -4.13254976e-01 ... -5.31944484e-02\n",
      "    -1.80972233e-01  5.76870255e-02]\n",
      "   ...\n",
      "   [ 8.32416788e-02  2.90550888e-02  5.33011734e-01 ...  1.22614019e-01\n",
      "     2.22847536e-01 -5.53696603e-02]\n",
      "   [ 2.42547095e-01  3.12358588e-01 -2.33235769e-02 ...  2.76679993e-01\n",
      "    -2.11134963e-02  1.05833359e-01]\n",
      "   [ 9.24515501e-02  4.63140011e-02 -1.79549843e-01 ...  7.52828792e-02\n",
      "    -1.79235116e-01  1.81896240e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-1.05853878e-01  3.34064126e-01 -2.82641947e-01 ... -1.17424214e-02\n",
      "    -1.88962981e-01  9.13235992e-02]\n",
      "   [ 1.94783151e-01  1.12359330e-01 -1.71766907e-01 ...  4.11548316e-02\n",
      "     5.77272177e-02  1.13152899e-01]\n",
      "   [ 2.16443926e-01 -1.27415536e-02 -2.77384996e-01 ... -4.72225621e-02\n",
      "    -1.11428931e-01 -4.40584682e-02]\n",
      "   ...\n",
      "   [ 7.47953728e-02 -6.55049384e-02  1.44283473e-01 ...  1.82171509e-01\n",
      "    -8.61658752e-02  4.07862186e-01]\n",
      "   [-1.22842319e-01  6.53837681e-01 -5.93500733e-02 ...  1.45203561e-01\n",
      "    -1.05600595e-01  2.65346728e-02]\n",
      "   [ 1.40455842e-01 -7.81018138e-02 -1.17695570e-01 ...  1.30327605e-02\n",
      "     4.46025610e-01  2.08119210e-03]]]\n",
      "\n",
      "\n",
      " [[[-1.15158252e-01  1.64750963e-01 -6.38724416e-02 ...  1.62551165e-01\n",
      "    -3.38365346e-01 -1.82893962e-01]\n",
      "   [ 5.88591993e-02 -9.08531845e-02 -1.98170871e-01 ...  1.87703725e-02\n",
      "    -1.41730413e-01 -1.51854560e-01]\n",
      "   [ 7.72504285e-02  2.20212132e-01  9.64126587e-02 ...  3.43003809e-01\n",
      "    -1.71084180e-01  1.64269567e-01]\n",
      "   ...\n",
      "   [ 1.30386695e-01 -1.07528716e-01 -5.44509366e-02 ...  3.02354187e-01\n",
      "     2.92270854e-02 -1.00107491e-02]\n",
      "   [-9.50302556e-03  8.78009945e-03  2.05290884e-01 ...  1.51377216e-01\n",
      "     7.79774636e-02  4.71439697e-02]\n",
      "   [-2.43482925e-02  1.92607090e-01 -1.06403857e-01 ...  4.60687950e-02\n",
      "    -2.12340448e-02 -1.12682119e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.22235231e-01 -1.14082329e-01 -2.04377428e-01 ...  8.05718750e-02\n",
      "     6.84072375e-02 -1.38103580e-02]\n",
      "   [-9.18009132e-02  6.82851225e-02 -6.73965365e-02 ... -3.94269638e-02\n",
      "     1.03575075e-02 -3.17696389e-03]\n",
      "   [ 5.27028441e-02 -2.91046470e-01  4.93648231e-01 ... -4.99698371e-02\n",
      "     5.18662147e-02 -5.11782281e-02]\n",
      "   ...\n",
      "   [-1.81392848e-01  2.66206443e-01  4.91105765e-01 ...  1.94610387e-01\n",
      "    -4.19745237e-01  3.70408058e-01]\n",
      "   [ 1.04858153e-01  4.80405837e-02  4.51252125e-02 ...  1.87753260e-01\n",
      "     2.90987939e-01 -6.62243739e-03]\n",
      "   [ 3.21102068e-02  6.66511133e-02 -4.57534790e-02 ... -6.71391636e-02\n",
      "     2.50861615e-01 -1.68357313e-01]]]]\n",
      "[[[ 0.  2.  0. ...  1.  4.  2.]\n",
      "  [ 4.  1.  1. ...  3.  7.  9.]\n",
      "  [ 1.  0.  0. ...  0.  7.  6.]\n",
      "  ...\n",
      "  [ 7.  0.  0. ...  2. 26.  0.]\n",
      "  [ 1.  1.  0. ...  9. 20.  5.]\n",
      "  [ 3.  0.  0. ...  1.  1.  0.]]\n",
      "\n",
      " [[ 5.  1.  0. ...  1.  0.  1.]\n",
      "  [ 2.  1.  0. ...  1. 19.  5.]\n",
      "  [ 2.  1.  1. ...  2.  5.  5.]\n",
      "  ...\n",
      "  [12.  1.  0. ...  4. 32.  2.]\n",
      "  [12.  1.  0. ...  8.  8.  6.]\n",
      "  [ 1.  0.  0. ...  0.  3.  2.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  0.  2.  0.]\n",
      "  [ 1.  1.  0. ...  0.  5.  5.]\n",
      "  [ 1.  0.  2. ...  9. 10.  0.]\n",
      "  ...\n",
      "  [17.  0.  0. ... 14. 20.  3.]\n",
      "  [ 6.  0.  1. ...  4. 41.  3.]\n",
      "  [ 1.  0.  0. ...  0.  7.  3.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.  1.  0. ...  2.  3.  2.]\n",
      "  [ 0.  1.  0. ...  1.  5.  0.]\n",
      "  [ 8.  0.  1. ...  4.  8.  0.]\n",
      "  ...\n",
      "  [12.  0.  1. ...  0. 22.  2.]\n",
      "  [ 5.  1.  0. ...  6. 16.  2.]\n",
      "  [ 0.  0.  0. ...  3.  0.  1.]]\n",
      "\n",
      " [[ 2.  0.  0. ...  1.  9.  2.]\n",
      "  [ 3.  1.  0. ...  1. 10.  1.]\n",
      "  [ 2.  0.  0. ...  5.  6.  4.]\n",
      "  ...\n",
      "  [13.  2.  1. ...  5. 42.  3.]\n",
      "  [ 4.  0.  1. ...  1. 32.  1.]\n",
      "  [ 2.  1.  0. ...  0.  2.  1.]]\n",
      "\n",
      " [[ 2.  3.  0. ...  4.  2.  0.]\n",
      "  [ 0.  0.  1. ...  1.  2.  3.]\n",
      "  [ 1.  0.  3. ...  2. 13.  0.]\n",
      "  ...\n",
      "  [10.  0.  0. ...  5.  8.  8.]\n",
      "  [ 3.  1.  1. ...  1. 33. 11.]\n",
      "  [ 2.  0.  0. ...  3. 10.  2.]]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.46792\n",
      "AUC: 0.80388\n",
      "(array([[[ 0.,  2.,  0., ...,  1.,  4.,  2.],\n",
      "        [ 4.,  1.,  1., ...,  3.,  7.,  9.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  7.,  6.],\n",
      "        ...,\n",
      "        [ 7.,  0.,  0., ...,  2., 26.,  0.],\n",
      "        [ 1.,  1.,  0., ...,  9., 20.,  5.],\n",
      "        [ 3.,  0.,  0., ...,  1.,  1.,  0.]],\n",
      "\n",
      "       [[ 5.,  1.,  0., ...,  1.,  0.,  1.],\n",
      "        [ 2.,  1.,  0., ...,  1., 19.,  5.],\n",
      "        [ 2.,  1.,  1., ...,  2.,  5.,  5.],\n",
      "        ...,\n",
      "        [12.,  1.,  0., ...,  4., 32.,  2.],\n",
      "        [12.,  1.,  0., ...,  8.,  8.,  6.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  3.,  2.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  0.,  2.,  0.],\n",
      "        [ 1.,  1.,  0., ...,  0.,  5.,  5.],\n",
      "        [ 1.,  0.,  2., ...,  9., 10.,  0.],\n",
      "        ...,\n",
      "        [17.,  0.,  0., ..., 14., 20.,  3.],\n",
      "        [ 6.,  0.,  1., ...,  4., 41.,  3.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  7.,  3.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 2.,  1.,  0., ...,  2.,  3.,  2.],\n",
      "        [ 0.,  1.,  0., ...,  1.,  5.,  0.],\n",
      "        [ 8.,  0.,  1., ...,  4.,  8.,  0.],\n",
      "        ...,\n",
      "        [12.,  0.,  1., ...,  0., 22.,  2.],\n",
      "        [ 5.,  1.,  0., ...,  6., 16.,  2.],\n",
      "        [ 0.,  0.,  0., ...,  3.,  0.,  1.]],\n",
      "\n",
      "       [[ 2.,  0.,  0., ...,  1.,  9.,  2.],\n",
      "        [ 3.,  1.,  0., ...,  1., 10.,  1.],\n",
      "        [ 2.,  0.,  0., ...,  5.,  6.,  4.],\n",
      "        ...,\n",
      "        [13.,  2.,  1., ...,  5., 42.,  3.],\n",
      "        [ 4.,  0.,  1., ...,  1., 32.,  1.],\n",
      "        [ 2.,  1.,  0., ...,  0.,  2.,  1.]],\n",
      "\n",
      "       [[ 2.,  3.,  0., ...,  4.,  2.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  1.,  2.,  3.],\n",
      "        [ 1.,  0.,  3., ...,  2., 13.,  0.],\n",
      "        ...,\n",
      "        [10.,  0.,  0., ...,  5.,  8.,  8.],\n",
      "        [ 3.,  1.,  1., ...,  1., 33., 11.],\n",
      "        [ 2.,  0.,  0., ...,  3., 10.,  2.]]], dtype=float32), array([[1., 0., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 1., 1., 1.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 1., 1., 1.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "test.rmse(data)\n",
    "print(test.get_predictions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PMF_clusters_try_LJK_prior_on_covariance(nn.Module):\n",
    "    #bayesian non parametrics - dirichlet process\n",
    "\n",
    "    #with multivariate gammas that are \"somehow?\" related through pyro's dependent dimension setting\n",
    "    #how to define their covariance?\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "        self.num_clusters_drugs = 1000\n",
    "        self.num_clusters_se =  5000\n",
    "    def mix_weights(self,beta):\n",
    "            beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "            return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "    def model(self, data):\n",
    "            alpha = 0.1\n",
    "            with pyro.plate(\"beta_drugs_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_drugs_plate\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "                theta = pyro.sample(\"theta\", dist.HalfCauchy(torch.ones( self.dim)).to_event(1))\n",
    "                # Lower cholesky factor of a correlation matrix\n",
    "                concentration = torch.ones(\n",
    "                    (),\n",
    "                )  # Implies a uniform distribution over correlation matrices\n",
    "                L_omega = pyro.sample(\"L_omega\", dist.LKJCholesky( self.dim, concentration))\n",
    "            # Lower cholesky factor of the covariance matrix\n",
    "                \n",
    "    # For inference with SVI, one might prefer to use torch.bmm(theta.sqrt().diag_embed(), L_omega)\n",
    "            with pyro.plate(\"data_drugs\",  self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical( self.mix_weights(beta_drugs)))\n",
    "                L_Omega = torch.bmm(theta[z_d].sqrt().diag_embed(), L_omega[z_d])# torch.mm(torch.diag(theta.sqrt()), L_omega)\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d], scale_tril=L_Omega))\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(1, alpha))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(self.mix_weights(beta_se)))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], torch.eye(self.dim)))\n",
    "            \n",
    "            u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "            se2_plate = pyro.plate(\"se2_plate\", self.m, dim=-1)\n",
    "\n",
    "            with se2_plate, u2_plate: \n",
    "                Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA@VA.T)), obs=data ) \n",
    "                return Y\n",
    "\n",
    "    def guide(self,data=None):\n",
    "            kappa = pyro.param('kappa_d', lambda: dist.Uniform(0, 2).sample([self.num_clusters_drugs-1]), constraint=constraints.positive)\n",
    "            tau = pyro.param('tau_d', lambda: dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)).sample([self.num_clusters_drugs]))\n",
    "            phi = pyro.param('phi_d', lambda: dist.Dirichlet(1/self.num_clusters_drugs * torch.ones(self.num_clusters_drugs)).sample([self.n]), constraint=constraints.simplex)\n",
    "            cov1 =  pyro.param('cov1', 10*torch.ones(self.num_clusters_drugs,self.dim), constraint=constraints.positive)\n",
    "\n",
    "            with pyro.plate(\"beta_plate\", self.num_clusters_drugs-1):\n",
    "                beta_drugs = pyro.sample(\"beta_drugs\", dist.Beta(torch.ones(self.num_clusters_drugs-1), kappa))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_drug\", self.num_clusters_drugs):\n",
    "                mu_drugs = pyro.sample(\"mu_drugs\", dist.MultivariateNormal(tau, torch.eye(self.dim)))\n",
    "                theta = pyro.sample(\"theta\", dist.HalfCauchy(cov1).to_event(1))\n",
    "            # Lower cholesky factor of a correlation matrix\n",
    "                concentration = torch.ones(\n",
    "                (),\n",
    "            )  # Implies a uniform distribution over correlation matrices\n",
    "                L_omega = pyro.sample(\"L_omega\", dist.LKJCholesky( self.dim, concentration))\n",
    "            with pyro.plate(\"data_drug\", self.n):\n",
    "                z_d = pyro.sample(\"z_drugs\", dist.Categorical(phi))\n",
    "                L_Omega = torch.bmm(theta[z_d].sqrt().diag_embed(), L_omega[z_d])\n",
    "\n",
    "                UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_drugs[z_d],scale_tril= L_Omega))\n",
    "\n",
    "            \n",
    "            kappa_s = pyro.param('kappa_s', lambda: dist.Uniform(0, 2).sample([self.num_clusters_se-1]), constraint=constraints.positive)\n",
    "            tau_s = pyro.param('tau_s', lambda: dist.MultivariateNormal(torch.zeros(self.dim), 0.5 * torch.eye(self.dim)).sample([self.num_clusters_se]))\n",
    "            phi_s = pyro.param('phi_s', lambda: dist.Dirichlet(1/self.num_clusters_se * torch.ones(self.num_clusters_se)).sample([self.m]), constraint=constraints.simplex)\n",
    "\n",
    "            with pyro.plate(\"beta_se_plate\", self.num_clusters_se-1):\n",
    "                beta_se = pyro.sample(\"beta_se\", dist.Beta(torch.ones(self.num_clusters_se-1), kappa_s))\n",
    "\n",
    "            with pyro.plate(\"mu_plate_se\", self.num_clusters_se):\n",
    "                mu_se = pyro.sample(\"mu_se\", dist.MultivariateNormal(tau_s, torch.eye(self.dim)))\n",
    "\n",
    "            with pyro.plate(\"data_sideeffects\", self.m):\n",
    "                z_se = pyro.sample(\"z_se\", dist.Categorical(phi_s))\n",
    "                VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_se[z_se], torch.eye(self.dim)))\n",
    "\n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.05, lrd = 1):\n",
    "                logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "                svi = SVI(self.model,\n",
    "                self.guide,\n",
    "                optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "                loss=Trace_ELBO())\n",
    "                losses = []\n",
    "                for step in range(nsteps):\n",
    "                    elbo = svi.step(torch.from_numpy(train).float())\n",
    "                    losses.append(elbo)\n",
    "                    if step % 10 == 0:\n",
    "                        print(\"Elbo loss: {}\".format(elbo))\n",
    "                self.losses = losses\n",
    "                #constrained_params = list(pyro.get_param_store().values())\n",
    "                #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "                #print(PARAMS)\n",
    "                return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'beta_plate', 'data_drug', 'mu_plate_drug'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 522898932.63165283\n",
      "Elbo loss: 472267225.5957184\n",
      "Elbo loss: 394533633.65270996\n",
      "Elbo loss: 369998733.354126\n",
      "Elbo loss: 336892462.5012207\n",
      "Elbo loss: 311479740.1257324\n",
      "Elbo loss: 287125368.5058594\n",
      "Elbo loss: 270561637.4732666\n",
      "Elbo loss: 255268516.51623535\n",
      "Elbo loss: 254280572.35302734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(handle)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test \u001b[39m=\u001b[39m PMF_clusters2(train\u001b[39m=\u001b[39mdata, dim\u001b[39m=\u001b[39m\u001b[39m99\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test\u001b[39m.\u001b[39;49mtrain_SVI(data)\n",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb Cell 12\u001b[0m in \u001b[0;36mPMF_clusters2.train_SVI\u001b[0;34m(self, train, nsteps, lr, lrd)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nsteps):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     elbo \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(torch\u001b[39m.\u001b[39;49mfrom_numpy(train)\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(elbo)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X16sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/trace_elbo.py:157\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mif\u001b[39;00m trainable_params \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[1;32m    154\u001b[0m         surrogate_loss_particle, \u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         surrogate_loss_particle \u001b[39m=\u001b[39m surrogate_loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n\u001b[0;32m--> 157\u001b[0m         surrogate_loss_particle\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretain_graph)\n\u001b[1;32m    158\u001b[0m warn_if_nan(loss, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/util.py:84\u001b[0m, in \u001b[0;36mwarn_if_nan.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         lineno \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_lineno\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(value) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m     83\u001b[0m     value\u001b[39m.\u001b[39mregister_hook(\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mlambda\u001b[39;00m x: warn_if_nan(\n\u001b[1;32m     85\u001b[0m             x, \u001b[39m\"\u001b[39m\u001b[39mbackward \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg, filename\u001b[39m=\u001b[39mfilename, lineno\u001b[39m=\u001b[39mlineno\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m torch_isnan(value):\n\u001b[1;32m     90\u001b[0m     warnings\u001b[39m.\u001b[39mwarn_explicit(\n\u001b[1;32m     91\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncountered NaN\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg \u001b[39mif\u001b[39;00m msg \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     92\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m         filename,\n\u001b[1;32m     94\u001b[0m         lineno,\n\u001b[1;32m     95\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "test = PMF_clusters2(train=data, dim=99)\n",
    "test.train_SVI(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Predictive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictive_svi \u001b[39m=\u001b[39m Predictive(test\u001b[39m.\u001b[39mmodel, guide\u001b[39m=\u001b[39mtest\u001b[39m.\u001b[39mguide, num_samples\u001b[39m=\u001b[39m\u001b[39m700\u001b[39m)(\u001b[39mNone\u001b[39;00m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m predictive_svi\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/try_with_mixtures.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(v\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Predictive' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predictive_svi = Predictive(test.model, guide=test.guide, num_samples=700)(None )\n",
    "for k, v in predictive_svi.items():\n",
    "    print(f\"{k}: {tuple(v.shape)}\")\n",
    "table = predictive_svi[\"target\"].numpy()\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
