{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Predictive\n",
    "import seaborn as sns\n",
    "from pyro import poutine\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 5237)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data_all.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_Bayesian(nn.Module):\n",
    "\n",
    "    #with multivariate gammas that are \"somehow?\" related through pyro's dependent dimension setting\n",
    "    #how to define their covariance?\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self,  train):\n",
    "\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "        UA = pyro.sample(\"UA\", dist.Gamma(self.alpha_u, self.beta_u).expand([self.dim,self.n]).to_event(2))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        \n",
    "        VA = pyro.sample(\"VA\", dist.Gamma(self.alpha_v, self.beta_v).expand([self.dim,self.m]).to_event(2))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(UA.T@VA), obs = train) \n",
    "            return Y\n",
    "            \n",
    "    def guide(self, train=None):\n",
    "\n",
    "        d_alpha = pyro.param('d_alpha', torch.ones(self.dim,self.n), constraint=constraints.positive)#*self.user_mean)\n",
    "        d_beta = pyro.param('d_beta', 0.5*torch.ones(self.dim,self.n), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        s_alpha = pyro.param('s_alpha', torch.ones(self.dim,self.m), constraint=constraints.positive)#*self.item_mean)\n",
    "        s_beta = pyro.param('s_beta', 0.5*torch.ones (self.dim,self.m), constraint=constraints.positive)\n",
    "        drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items)\n",
    "\n",
    "       \n",
    "        UA = pyro.sample(\"UA\", dist.Gamma(d_alpha, d_beta).to_event(2))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        \n",
    "        VA = pyro.sample(\"VA\", dist.Gamma(s_alpha, s_beta).to_event(2))\n",
    "\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=250, lr = 0.01, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 15783411.265625\n",
      "Elbo loss: 15663015.265625\n",
      "Elbo loss: 16145332.765625\n",
      "Elbo loss: 15826587.921875\n",
      "Elbo loss: 15719802.25\n",
      "Elbo loss: 15592114.84375\n",
      "Elbo loss: 16002269.5625\n",
      "Elbo loss: 15610041.640625\n",
      "Elbo loss: 15560336.8125\n",
      "Elbo loss: 15778299.484375\n",
      "Elbo loss: 15540349.015625\n",
      "Elbo loss: 15444293.75\n",
      "Elbo loss: 15495942.046875\n",
      "Elbo loss: 15487900.578125\n",
      "Elbo loss: 15396425.5\n",
      "Elbo loss: 15226229.21875\n",
      "Elbo loss: 15339010.9375\n",
      "Elbo loss: 15327952.0\n",
      "Elbo loss: 15188313.953125\n",
      "Elbo loss: 15354570.0\n",
      "Elbo loss: 15365459.0625\n",
      "Elbo loss: 15043918.90625\n",
      "Elbo loss: 15205022.578125\n",
      "Elbo loss: 15365884.71875\n",
      "Elbo loss: 15196678.84375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15783411.265625,\n",
       " 15982159.515625,\n",
       " 15858975.078125,\n",
       " 15929883.609375,\n",
       " 16119493.796875,\n",
       " 15810800.484375,\n",
       " 16048108.4375,\n",
       " 15962100.484375,\n",
       " 15937342.078125,\n",
       " 15806775.75,\n",
       " 15663015.265625,\n",
       " 15990829.375,\n",
       " 15851723.671875,\n",
       " 15867087.625,\n",
       " 15815056.046875,\n",
       " 15978717.75,\n",
       " 15919643.703125,\n",
       " 15788299.546875,\n",
       " 15660207.359375,\n",
       " 15762928.828125,\n",
       " 16145332.765625,\n",
       " 15920802.90625,\n",
       " 16016311.21875,\n",
       " 15984159.96875,\n",
       " 15796621.125,\n",
       " 15644638.65625,\n",
       " 15806779.578125,\n",
       " 15928478.21875,\n",
       " 15983178.71875,\n",
       " 15844046.15625,\n",
       " 15826587.921875,\n",
       " 15793722.109375,\n",
       " 15708210.421875,\n",
       " 15622728.5625,\n",
       " 15751240.828125,\n",
       " 15913168.875,\n",
       " 15851111.0625,\n",
       " 15580053.75,\n",
       " 15758030.65625,\n",
       " 15696492.1875,\n",
       " 15719802.25,\n",
       " 15613640.3125,\n",
       " 15740376.546875,\n",
       " 15998692.515625,\n",
       " 15668583.15625,\n",
       " 15841526.90625,\n",
       " 15768233.75,\n",
       " 15596485.8125,\n",
       " 15699927.5,\n",
       " 15769493.234375,\n",
       " 15592114.84375,\n",
       " 15720412.875,\n",
       " 15645728.109375,\n",
       " 15468635.5,\n",
       " 15542452.796875,\n",
       " 15514051.15625,\n",
       " 15546926.09375,\n",
       " 15690490.90625,\n",
       " 15488243.84375,\n",
       " 15644363.671875,\n",
       " 16002269.5625,\n",
       " 15676983.546875,\n",
       " 15718307.625,\n",
       " 15560332.671875,\n",
       " 15627325.53125,\n",
       " 15727152.3125,\n",
       " 15765503.484375,\n",
       " 15617546.65625,\n",
       " 15774417.125,\n",
       " 15840510.0,\n",
       " 15610041.640625,\n",
       " 15587622.203125,\n",
       " 15695340.015625,\n",
       " 15727259.453125,\n",
       " 15785483.171875,\n",
       " 15621808.5625,\n",
       " 15557687.515625,\n",
       " 15668050.46875,\n",
       " 15540533.140625,\n",
       " 15613359.734375,\n",
       " 15560336.8125,\n",
       " 15806384.890625,\n",
       " 15418748.0625,\n",
       " 15554076.484375,\n",
       " 15648043.59375,\n",
       " 15642290.515625,\n",
       " 15535514.75,\n",
       " 15885461.921875,\n",
       " 15578793.15625,\n",
       " 15491746.8125,\n",
       " 15778299.484375,\n",
       " 15561770.546875,\n",
       " 15532199.421875,\n",
       " 15588910.765625,\n",
       " 15502840.5625,\n",
       " 15380854.90625,\n",
       " 15468208.625,\n",
       " 15467186.0,\n",
       " 15620267.625,\n",
       " 15807129.078125,\n",
       " 15540349.015625,\n",
       " 15473159.90625,\n",
       " 15432371.46875,\n",
       " 15397248.625,\n",
       " 15524392.40625,\n",
       " 15546937.28125,\n",
       " 15388050.65625,\n",
       " 15378823.234375,\n",
       " 15580157.421875,\n",
       " 15507395.1875,\n",
       " 15444293.75,\n",
       " 15437747.875,\n",
       " 15524504.625,\n",
       " 15723236.90625,\n",
       " 15538150.28125,\n",
       " 15305866.921875,\n",
       " 15493390.96875,\n",
       " 15365777.53125,\n",
       " 15595236.8125,\n",
       " 15361007.0,\n",
       " 15495942.046875,\n",
       " 15438706.5625,\n",
       " 15492385.71875,\n",
       " 15472890.90625,\n",
       " 15584385.0625,\n",
       " 15304759.0,\n",
       " 15492864.921875,\n",
       " 15545825.109375,\n",
       " 15305531.859375,\n",
       " 15666660.546875,\n",
       " 15487900.578125,\n",
       " 15574910.5625,\n",
       " 15432116.9375,\n",
       " 15461633.078125,\n",
       " 15410057.15625,\n",
       " 15478443.875,\n",
       " 15212997.640625,\n",
       " 15245910.59375,\n",
       " 15360959.703125,\n",
       " 15400507.9375,\n",
       " 15396425.5,\n",
       " 15397957.484375,\n",
       " 15189710.5,\n",
       " 15373961.859375,\n",
       " 15353968.484375,\n",
       " 15411639.84375,\n",
       " 15327235.265625,\n",
       " 15428621.859375,\n",
       " 15305217.890625,\n",
       " 15244272.765625,\n",
       " 15226229.21875,\n",
       " 15239896.296875,\n",
       " 15316432.453125,\n",
       " 15424497.359375,\n",
       " 15323404.75,\n",
       " 15216068.546875,\n",
       " 15417589.453125,\n",
       " 15396164.96875,\n",
       " 15229365.0625,\n",
       " 15385865.96875,\n",
       " 15339010.9375,\n",
       " 15213150.625,\n",
       " 15379434.53125,\n",
       " 15495879.953125,\n",
       " 15160740.15625,\n",
       " 15366586.03125,\n",
       " 15626122.6875,\n",
       " 15328829.921875,\n",
       " 15368075.359375,\n",
       " 15177711.421875,\n",
       " 15327952.0,\n",
       " 15108559.859375,\n",
       " 15467836.015625,\n",
       " 15245634.0625,\n",
       " 15355660.859375,\n",
       " 15296093.28125,\n",
       " 15266035.609375,\n",
       " 15202856.65625,\n",
       " 15348249.234375,\n",
       " 15307633.78125,\n",
       " 15188313.953125,\n",
       " 15208838.40625,\n",
       " 15284913.265625,\n",
       " 15259150.359375,\n",
       " 15344801.09375,\n",
       " 15246316.828125,\n",
       " 15095736.0,\n",
       " 15101569.75,\n",
       " 15461006.28125,\n",
       " 15019172.4375,\n",
       " 15354570.0,\n",
       " 15238298.46875,\n",
       " 15365310.9375,\n",
       " 15243005.84375,\n",
       " 15358956.421875,\n",
       " 15217812.546875,\n",
       " 15180828.546875,\n",
       " 15172569.59375,\n",
       " 15181350.078125,\n",
       " 15134028.578125,\n",
       " 15365459.0625,\n",
       " 15034830.25,\n",
       " 15239308.453125,\n",
       " 15379253.90625,\n",
       " 15162224.875,\n",
       " 14925196.21875,\n",
       " 15294238.0,\n",
       " 15193825.375,\n",
       " 15194989.484375,\n",
       " 15261003.453125,\n",
       " 15043918.90625,\n",
       " 15139511.15625,\n",
       " 15172341.28125,\n",
       " 15171442.578125,\n",
       " 15387829.421875,\n",
       " 15133840.984375,\n",
       " 15183071.640625,\n",
       " 15061620.5,\n",
       " 15018417.625,\n",
       " 14909113.03125,\n",
       " 15205022.578125,\n",
       " 15307746.0,\n",
       " 15043890.5,\n",
       " 15489199.484375,\n",
       " 15243108.15625,\n",
       " 15062029.75,\n",
       " 15256813.796875,\n",
       " 15103051.890625,\n",
       " 15143392.921875,\n",
       " 15093634.765625,\n",
       " 15365884.71875,\n",
       " 15209806.78125,\n",
       " 15182788.640625,\n",
       " 15177110.25,\n",
       " 14994338.0625,\n",
       " 15339193.84375,\n",
       " 15223112.0,\n",
       " 15340119.1875,\n",
       " 15245603.984375,\n",
       " 15227503.9375,\n",
       " 15196678.84375,\n",
       " 15070093.96875,\n",
       " 15199802.40625,\n",
       " 14950194.234375,\n",
       " 14929458.21875,\n",
       " 15089522.78125,\n",
       " 15112123.125,\n",
       " 14940923.671875,\n",
       " 15161374.375,\n",
       " 15230310.1875]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PMF_Bayesian(train=data, dim=100)\n",
    "test.train_SVI(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UA: (1000, 1, 1, 100, 1127)\n",
      "VA: (1000, 1, 1, 100, 5237)\n",
      "target: (1000, 1127, 5237)\n",
      "PMF MAP training RMSE: 0.36233\n",
      "AUC: 0.84131\n",
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 1  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  1  8  0]\n",
      " ...\n",
      " [ 8  0  0 ... 10 12  0]\n",
      " [ 1  0  0 ...  4 25  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "test.sample_predict(1000)\n",
    "test.rmse(data)\n",
    "print(test.get_predictions())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF MAP training RMSE: 0.36233\n",
      "AUC: 0.84131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36233013243166723, 0.841312632158804)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rmse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_Bayesian2(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, train, dim):\n",
    "        super().__init__()\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim   \n",
    "        self.data = train.copy()\n",
    "        self.n, self.m = self.data.shape\n",
    "        self.map = None\n",
    "        self.bounds = (0,1)\n",
    "        self.losses = None\n",
    "        self.predictions = None\n",
    "\n",
    "\n",
    "        # Perform mean value imputation\n",
    "    \n",
    "        \n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = (np.mean(self.data, axis=1).mean())**2 / np.std(self.data, axis=1).mean()\n",
    "        self.alpha_v = (np.mean(self.data, axis=0).mean())**2 / np.std(self.data, axis=0).mean()\n",
    "\n",
    "        self.beta_u = (np.mean(self.data, axis=1).mean()) / np.std(self.data, axis=1).mean()\n",
    "        self.beta_v = (np.mean(self.data, axis=0).mean()) / np.std(self.data, axis=0).mean()\n",
    "       \n",
    "        self.bias = self.data.mean()\n",
    "\n",
    "\n",
    "    def model(self,train):\n",
    "            m_10 = torch.zeros(self.n)\n",
    "            cov_w1 = torch.eye(self.n)\n",
    "            cov_1 = pyro.sample(\"cov1\", dist.Wishart(covariance_matrix= cov_w1, df = torch.Tensor([2*self.n])))\n",
    "            mu_1 = pyro.sample(\"mu_1\", dist.MultivariateNormal(m_10, precision_matrix = cov_1))\n",
    "            m_20 = torch.zeros(self.m)\n",
    "            cov_w2 = torch.eye(self.m)\n",
    "            cov_2 = pyro.sample(\"cov2\", dist.Wishart(covariance_matrix= cov_w2, df = torch.Tensor([2*self.m])))\n",
    "            mu_2 = pyro.sample(\"mu_2\", dist.MultivariateNormal(m_20, precision_matrix = cov_2))\n",
    "            print(torch.det(cov_1))\n",
    "\n",
    "            \n",
    "            drug_plate = pyro.plate(\"drug_latents\", self.n, dim= -1) #independent users\n",
    "            sideeffect_plate = pyro.plate(\"sideeffect_latents\", self.m, dim= -1) #independent items\n",
    "\n",
    "            UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_1, precision_matrix= cov_1))\n",
    "                #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "            \n",
    "            \n",
    "            VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_2, precision_matrix =cov_2))\n",
    "                #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "        \n",
    "            u2_plate = pyro.plate(\"u2_plate\", self.n, dim=-2)\n",
    "\n",
    "            with sideeffect_plate, u2_plate: \n",
    "                Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA.T@VA)), obs = train) \n",
    "                return Y\n",
    "\n",
    "    def guide( self,train=None, mask=None):\n",
    "\n",
    "            mu_10= pyro.param('mu_10', torch.zeros(self.n))#*self.user_mean)\n",
    "            cov_w1 = pyro.param('d_beta', torch.eye(self.n), constraint=constraints.positive_definite)\n",
    "            mu_20= pyro.param('s_alpha', torch.zeros(self.m))\n",
    "            cov_w2 = pyro.param('s_beta', torch.eye(self.m), constraint=constraints.positive_definite)\n",
    "            cov_1 = pyro.sample(\"cov1\", dist.Wishart(covariance_matrix= cov_w1, df = torch.Tensor([2*self.n])))\n",
    "            cov_2 = pyro.sample(\"cov2\", dist.Wishart(covariance_matrix= cov_w2, df = torch.Tensor([2*self.m])))\n",
    "            mu_1 = pyro.sample(\"mu_1\", dist.MultivariateNormal(mu_10, precision_matrix = cov_1))\n",
    "            mu_2 =  pyro.sample(\"mu_2\", dist.MultivariateNormal(mu_20, precision_matrix = cov_2))\n",
    "\n",
    "\n",
    "            UA =  pyro.sample(\"UA\", dist.MultivariateNormal(mu_1, precision_matrix= cov_1))\n",
    "            # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "            \n",
    "            VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_2, precision_matrix =  cov_2))\n",
    "\n",
    "    \n",
    "    def train_SVI(self,train, nsteps=25, lr = 0.01, lrd = 1):\n",
    "        logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "        svi = SVI(self.model,\n",
    "        self.guide,\n",
    "        optim.ClippedAdam({\"lr\": lr, \"lrd\": lrd}),\n",
    "        loss=Trace_ELBO())\n",
    "        losses = []\n",
    "        for step in range(nsteps):\n",
    "            elbo = svi.step(torch.from_numpy(train).float())\n",
    "            losses.append(elbo)\n",
    "            if step % 10 == 0:\n",
    "                print(\"Elbo loss: {}\".format(elbo))\n",
    "        self.losses = losses\n",
    "        #constrained_params = list(pyro.get_param_store().values())\n",
    "        #PARAMS = [p.unconstrained() for p in constrained_params]\n",
    "        #print(PARAMS)\n",
    "        return losses\n",
    "    \n",
    "    def sample_predict(self, nsamples=500 , verbose=True):\n",
    "        predictive_svi = Predictive(self.model, guide=self.guide, num_samples=nsamples)( None)\n",
    "        if (verbose):\n",
    "            for k, v in predictive_svi.items():\n",
    "                print(f\"{k}: {tuple(v.shape)}\")\n",
    "        table = predictive_svi[\"target\"].numpy()\n",
    "        mc_table = table.mean(axis = 0)\n",
    "        mc_table_std = table.std(axis = 0)\n",
    "        mc_table[mc_table < self.bounds[1]] = self.bounds[0]\n",
    "        mc_table[mc_table >= self.bounds[1]] = self.bounds[1]\n",
    "        self.predictions = mc_table\n",
    "        \n",
    "    \n",
    "    def rmse(self,test):\n",
    "        low, high = self.bounds\n",
    "        test_data = test.copy()\n",
    "        test_data[test_data < high] = low\n",
    "        test_data[test_data >= high] = high\n",
    "        sqerror = abs(test_data - self.predictions) ** 2  # squared error array\n",
    "        mse = sqerror.sum()/(test_data.shape[0]*test_data.shape[1])\n",
    "        print(\"PMF MAP training RMSE: %.5f\" % np.sqrt(mse))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_data.astype(int).flatten(),  self.predictions.astype(int).flatten(), pos_label=1)\n",
    "        metrics.auc(fpr, tpr)\n",
    "        print(\"AUC: %.5f\" % metrics.auc(fpr, tpr))\n",
    "        return np.sqrt(mse) , metrics.auc(fpr, tpr)\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dafnep/Library/Python/3.8/lib/python/site-packages/torch/distributions/wishart.py:231: UserWarning: Singular sample detected.\n",
      "  warnings.warn(\"Singular sample detected.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([inf], grad_fn=<DetLuBasedHelperBackward0>)\n",
      "Elbo loss: 178107808.0\n",
      "tensor([inf], grad_fn=<DetLuBasedHelperBackward0>)\n",
      "tensor([inf], grad_fn=<DetLuBasedHelperBackward0>)\n",
      "tensor([inf], grad_fn=<DetLuBasedHelperBackward0>)\n"
     ]
    },
    {
     "ename": "_LinAlgError",
     "evalue": "torch.linalg_cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 2228 is not positive-definite).\nTrace Shapes:                    \n Param Sites:                    \n        mu_10      1127          \n       d_beta 1127 1127          \n      s_alpha      2890          \n       s_beta 2890 2890          \nSample Sites:                    \n    cov1 dist    1    | 1127 1127\n        value    1    | 1127 1127",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI multivariate appproach.ipynb Cell 7\u001b[0m in \u001b[0;36mPMF_Bayesian2.guide\u001b[0;34m(self, train, mask)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m cov_1 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mcov1\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mWishart(covariance_matrix\u001b[39m=\u001b[39m cov_w1, df \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn])))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m cov_2 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mcov2\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39;49mWishart(covariance_matrix\u001b[39m=\u001b[39;49m cov_w2, df \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mTensor([\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm])))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m mu_1 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mmu_1\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mMultivariateNormal(mu_10, precision_matrix \u001b[39m=\u001b[39m cov_1))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/distributions/distribution.py:18\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 18\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/distributions/wishart.py:102\u001b[0m, in \u001b[0;36mWishart.__init__\u001b[0;34m(self, df, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39melif\u001b[39;00m covariance_matrix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mcholesky(covariance_matrix)\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# precision_matrix is not None\u001b[39;00m\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: torch.linalg_cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 2228 is not positive-definite).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI multivariate appproach.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data2 \u001b[39m=\u001b[39m data[:,\u001b[39m0\u001b[39m:\u001b[39m2890\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test2 \u001b[39m=\u001b[39m PMF_Bayesian2(train\u001b[39m=\u001b[39mdata2, dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test2\u001b[39m.\u001b[39;49mtrain_SVI(data2)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test2\u001b[39m.\u001b[39msample_predict(\u001b[39m500\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test2\u001b[39m.\u001b[39mrmse(data2)\n",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI multivariate appproach.ipynb Cell 7\u001b[0m in \u001b[0;36mPMF_Bayesian2.train_SVI\u001b[0;34m(self, train, nsteps, lr, lrd)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nsteps):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     elbo \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(torch\u001b[39m.\u001b[39;49mfrom_numpy(train)\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(elbo)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[39m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfor\u001b[39;00m model_trace, guide_trace \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/elbo.py:182\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles):\n\u001b[0;32m--> 182\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_trace(model, guide, args, kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_trace\u001b[39m(\u001b[39mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m get_importance_trace(\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mflat\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/infer/enum.py:60\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     58\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m unwrapped_guide\u001b[39m.\u001b[39mget_traces()\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     guide_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(guide, graph_type\u001b[39m=\u001b[39;49mgraph_type)\u001b[39m.\u001b[39;49mget_trace(\n\u001b[1;32m     61\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[39m.\u001b[39mdetach_()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "\u001b[1;32m/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI multivariate appproach.ipynb Cell 7\u001b[0m in \u001b[0;36mPMF_Bayesian2.guide\u001b[0;34m(self, train, mask)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m cov_w2 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39ms_beta\u001b[39m\u001b[39m'\u001b[39m, torch\u001b[39m.\u001b[39meye(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm), constraint\u001b[39m=\u001b[39mconstraints\u001b[39m.\u001b[39mpositive_definite)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m cov_1 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mcov1\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mWishart(covariance_matrix\u001b[39m=\u001b[39m cov_w1, df \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn])))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m cov_2 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mcov2\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39;49mWishart(covariance_matrix\u001b[39m=\u001b[39;49m cov_w2, df \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mTensor([\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm])))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m mu_1 \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mmu_1\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mMultivariateNormal(mu_10, precision_matrix \u001b[39m=\u001b[39m cov_1))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dafnep/Documents/GitHub/Baysian-Matrix-Factorization-Drug-effect/src/bayesian_SVI%20multivariate%20appproach.ipynb#X12sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m mu_2 \u001b[39m=\u001b[39m  pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mmu_2\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mMultivariateNormal(mu_20, precision_matrix \u001b[39m=\u001b[39m cov_2))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyro/distributions/distribution.py:18\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 18\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/distributions/wishart.py:102\u001b[0m, in \u001b[0;36mWishart.__init__\u001b[0;34m(self, df, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m scale_tril\n\u001b[1;32m    101\u001b[0m \u001b[39melif\u001b[39;00m covariance_matrix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mcholesky(covariance_matrix)\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# precision_matrix is not None\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m _precision_to_scale_tril(precision_matrix)\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: torch.linalg_cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 2228 is not positive-definite).\nTrace Shapes:                    \n Param Sites:                    \n        mu_10      1127          \n       d_beta 1127 1127          \n      s_alpha      2890          \n       s_beta 2890 2890          \nSample Sites:                    \n    cov1 dist    1    | 1127 1127\n        value    1    | 1127 1127"
     ]
    }
   ],
   "source": [
    "data2 = data[:,0:2890]\n",
    "test2 = PMF_Bayesian2(train=data2, dim=100)\n",
    "test2.train_SVI(data2)\n",
    "test2.sample_predict(500)\n",
    "test2.rmse(data2)\n",
    "print(test2.get_predictions())\n",
    "print(data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing!!!\n",
    "\n",
    "n,m = data.shape\n",
    "dim=10\n",
    "mean_u = 4\n",
    "mean_v=5\n",
    "std_v=1\n",
    "std_u=1\n",
    "dim=10\n",
    "alpha_u = 4\n",
    "alpha_v=5\n",
    "beta_u=1\n",
    "beta_v=1\n",
    "m=3000\n",
    "drug_code = np.arange(n)\n",
    "se_code =np.arange(m)\n",
    "def model():\n",
    "        m_10 = torch.zeros(n)\n",
    "        cov_w1 = torch.eye(n)\n",
    "        cov_1 = pyro.sample(\"cov1\", dist.Wishart(scale_tril= cov_w1, df = torch.Tensor([2*n])))\n",
    "        mu_1 = pyro.sample(\"mu_1\", dist.MultivariateNormal(m_10, precision_matrix = cov_1))\n",
    "        m_20 = torch.zeros(m)\n",
    "        cov_w2 = torch.eye(m)\n",
    "        cov_2 = pyro.sample(\"cov2\", dist.Wishart(scale_tril= cov_w2, df = torch.Tensor([2*m])))\n",
    "        mu_2 = pyro.sample(\"mu_2\", dist.MultivariateNormal(m_20, precision_matrix = cov_2))\n",
    "        print(cov_1)\n",
    "\n",
    "        \n",
    "        drug_plate = pyro.plate(\"drug_latents\", n, dim= -1) #independent users\n",
    "        sideeffect_plate = pyro.plate(\"sideeffect_latents\", m, dim= -1) #independent items\n",
    "\n",
    "        UA = pyro.sample(\"UA\", dist.MultivariateNormal(mu_1, cov_1))\n",
    "            #UA_int = pyro.sample(\"UAint\", dist.Normal(0., 1.))\n",
    "        \n",
    "        \n",
    "        VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_2, cov_2))\n",
    "            #possibly add intercepts VA_int = pyro.sample(\"VA\", dist.Normal(0., 1.).to_event(1))\n",
    "       \n",
    "        u2_plate = pyro.plate(\"u2_plate\", n, dim=-2)\n",
    "\n",
    "        with sideeffect_plate, u2_plate: \n",
    "            Y = pyro.sample(\"target\", dist.Poisson(torch.abs(UA.T@VA))) \n",
    "            return Y\n",
    "\n",
    "def guide( train=None, mask=None):\n",
    "\n",
    "        mu_1= pyro.param('d_alpha', torch.zeros(n))#*self.user_mean)\n",
    "        cov_w1 = pyro.param('d_beta', torch.eye(n), constraint=constraints.positive)\n",
    "       # int_mean = pyro.param('int_mean', torch.tensor(1.)*self.user_mean)\n",
    "       # mov_cov = pyro.param('mov_cov', torch.tensor(1.)*0.1,\n",
    "          #                  constraint=constraints.positive)\n",
    "\n",
    "        mu_2= pyro.param('s_alpha', torch.zeros(m))\n",
    "        cov_w2 = pyro.param('s_beta', torch.eye(m), constraint=constraints.positive)\n",
    "        \n",
    "        cov_1 = pyro.sample(\"cov1\", dist.Wishart(scale_tril= cov_w1, df = torch.Tensor([2*n])))\n",
    "        cov_2 = pyro.sample(\"cov2\", dist.Wishart(scale_tril= cov_w2, df = torch.Tensor([2*m])))\n",
    "\n",
    "\n",
    "        UA =  pyro.sample(\"UA\", dist.MultivariateNormal(mu_1, cov_1))\n",
    "           # UA_int = pyro.sample(\"UAint\", dist.Normal(int_mean, mov_cov).to_event(1))\n",
    "        \n",
    "        VA = pyro.sample(\"VA\", dist.MultivariateNormal(mu_2, cov_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:                    \n",
      " Param Sites:                    \n",
      "      d_alpha      1127          \n",
      "       d_beta 1127 1127          \n",
      "      s_alpha      2800          \n",
      "       s_beta 2800 2800          \n",
      "Sample Sites:                    \n",
      "    cov1 dist    1    | 1127 1127\n",
      "        value    1    | 1127 1127\n",
      "     log_prob    1    |          \n",
      "    cov2 dist    1    | 2800 2800\n",
      "        value    1    | 2800 2800\n",
      "     log_prob    1    |          \n",
      "      UA dist    1    | 1127     \n",
      "        value    1    | 1127     \n",
      "     log_prob    1    |          \n",
      "      VA dist    1    | 2800     \n",
      "        value    1    | 2800     \n",
      "     log_prob    1    |          \n",
      "tensor([[[ 2.2811e+03,  1.6974e+01,  1.2097e+01,  ..., -9.2563e+01,\n",
      "          -8.4243e+00, -5.2117e+01],\n",
      "         [ 1.6974e+01,  2.2396e+03, -3.9046e+01,  ..., -1.7212e-01,\n",
      "          -1.8317e+01, -2.2925e+01],\n",
      "         [ 1.2097e+01, -3.9046e+01,  2.4201e+03,  ...,  7.1174e+01,\n",
      "           6.4328e+01,  5.0572e+00],\n",
      "         ...,\n",
      "         [-9.2563e+01, -1.7212e-01,  7.1174e+01,  ...,  2.1841e+03,\n",
      "           4.8997e+01,  3.6800e+01],\n",
      "         [-8.4243e+00, -1.8317e+01,  6.4328e+01,  ...,  4.8997e+01,\n",
      "           2.2199e+03, -7.5516e+01],\n",
      "         [-5.2117e+01, -2.2925e+01,  5.0572e+00,  ...,  3.6800e+01,\n",
      "          -7.5516e+01,  2.3557e+03]]])\n",
      "          Trace Shapes:                      \n",
      "           Param Sites:                      \n",
      "          Sample Sites:                      \n",
      "              cov1 dist         1 | 1127 1127\n",
      "                  value         1 | 1127 1127\n",
      "               log_prob         1 |          \n",
      "              mu_1 dist         1 | 1127     \n",
      "                  value         1 | 1127     \n",
      "               log_prob         1 |          \n",
      "              cov2 dist         1 | 3000 3000\n",
      "                  value         1 | 3000 3000\n",
      "               log_prob         1 |          \n",
      "              mu_2 dist         1 | 3000     \n",
      "                  value         1 | 3000     \n",
      "               log_prob         1 |          \n",
      "      drug_latents dist           |          \n",
      "                  value      1127 |          \n",
      "               log_prob           |          \n",
      "sideeffect_latents dist           |          \n",
      "                  value      3000 |          \n",
      "               log_prob           |          \n",
      "                UA dist         1 | 1127     \n",
      "                  value         1 | 1127     \n",
      "               log_prob         1 |          \n",
      "                VA dist         1 | 3000     \n",
      "                  value         1 | 3000     \n",
      "               log_prob         1 |          \n",
      "          u2_plate dist           |          \n",
      "                  value      1127 |          \n",
      "               log_prob           |          \n",
      "            target dist 1127 3000 |          \n",
      "                  value 1127 3000 |          \n",
      "               log_prob 1127 3000 |          \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trace=poutine.trace(guide).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())\n",
    "\n",
    "trace=poutine.trace(model).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
